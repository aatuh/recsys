{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"RecSys suite documentation","text":"<p>Welcome. This documentation is intended to start running the suite, integrate it into an application, and operate it safely.</p> <p>You can access this documentation in several ways:</p> <ul> <li>Visit <code>https://recsys.app</code>.</li> <li>Visit <code>https://github.com/aatuh/recsys</code>.</li> <li>Run <code>make docs-serve</code> and open <code>http://localhost:8001</code>.</li> <li>Browse the files in the repository under <code>/docs</code>.</li> </ul> <p>Browse the source repository on GitHub: <code>github.com/aatuh/recsys</code>.</p>"},{"location":"#need-guided-help","title":"Need guided help?","text":"<ul> <li>RecSys Copilot for docs/tech/business Q&amp;A: <code>chatgpt.com/g/.../recsys-copilot</code>.</li> </ul>"},{"location":"#what-is-the-suite","title":"What is the suite?","text":"<p>The suite is four modules that form an end-to-end recommendation system loop:</p> <ul> <li>recsys-service: low-latency recommendation API (auth, tenancy, limits, caching, observability, exposure logging).</li> <li>recsys-algo: deterministic ranking logic (candidate merge, scoring, constraints, rules, diversity).</li> <li>recsys-pipelines: offline/stream processing that turns events into versioned artifacts the service consumes.</li> <li>recsys-eval: offline regression + online experiment analysis that decides what to ship.</li> </ul> <p>If you're evaluating this as a product (rather than integrating it right now), start with:</p> <ul> <li>Stakeholder overview: <code>start-here/what-is-recsys.md</code></li> </ul>"},{"location":"#where-to-start","title":"Where to start","text":"<ol> <li>Tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>Integrate: <code>how-to/integrate-recsys-service.md</code></li> <li>Operate: <code>how-to/operate-pipelines.md</code></li> <li>Evaluate: <code>how-to/run-eval-and-ship.md</code></li> <li>Deploy: <code>how-to/deploy-helm.md</code></li> </ol>"},{"location":"#reference","title":"Reference","text":"<ul> <li>REST API: <code>reference/api/openapi.yaml</code></li> <li>Admin API: <code>reference/api/admin.md</code></li> <li>Contracts: <code>reference/data-contracts/index.md</code></li> <li>Config: <code>reference/config/index.md</code></li> <li>CLI: <code>reference/cli/index.md</code></li> <li>Database: <code>reference/database/index.md</code></li> </ul> <p>Note:</p> <ul> <li>Admin endpoints are documented in <code>reference/api/admin.md</code></li> </ul>"},{"location":"#concepts","title":"Concepts","text":"<ul> <li><code>explanation/suite-architecture.md</code></li> <li><code>explanation/candidate-vs-ranking.md</code></li> <li><code>explanation/exposure-logging-and-attribution.md</code></li> <li><code>explanation/surface-namespaces.md</code></li> <li><code>explanation/data-modes.md</code></li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>Run tests per module (e.g., <code>cd recsys-eval &amp;&amp; go test ./...</code>).</li> <li>Each module is versioned/released independently; tags are module-prefixed (e.g., <code>recsys-eval/v0.2.0</code>).</li> </ul>"},{"location":"#operations","title":"Operations","text":"<ul> <li><code>operations/runbooks/service-not-ready.md</code></li> <li><code>operations/runbooks/empty-recs.md</code></li> <li><code>operations/runbooks/rollback-config-rules.md</code></li> <li><code>operations/performance-and-capacity.md</code></li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li><code>project/docs-style.md</code></li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/","title":"Artifacts and manifest lifecycle (pipelines \u2192 service)","text":""},{"location":"explanation/artifacts-and-manifest-lifecycle/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Lead developers and platform engineers designing a safe \u201cship/rollback\u201d process</li> <li>SRE/on-call who need a concrete mental model for freshness and rollback incidents</li> <li>Data engineers operating <code>recsys-pipelines</code></li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#what-you-will-get","title":"What you will get","text":"<ul> <li>What an artifact is (and why it should be immutable)</li> <li>What the manifest is (and why it is the thing you \u201cship\u201d and \u201croll back\u201d)</li> <li>Where state lives (Postgres vs object store) and what to monitor</li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#key-terms","title":"Key terms","text":"<ul> <li>Artifact: an immutable, version-addressed blob that contains a computed signal (popularity, co-visitation, etc.).</li> <li>Manifest: a small JSON document that maps artifact types \u2192 artifact URIs for a <code>(tenant, surface)</code> pair.</li> <li>\u201cCurrent\u201d pointer: the object-store location the service reads as \u201cthe current manifest\u201d.</li> </ul> <p>In artifact/manifest mode, you do not \u201cdeploy a model\u201d to the service. You deploy a manifest pointer update.</p>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#where-things-live","title":"Where things live","text":"<p>In the RecSys suite, state is intentionally split:</p> <ul> <li>Postgres</li> <li>tenants, config, rules</li> <li>item metadata such as <code>item_tags</code> (still used in artifact mode)</li> <li>Object store</li> <li>artifacts (immutable)</li> <li>the \u201ccurrent\u201d manifest pointer (mutable, but small)</li> <li>Logs</li> <li>exposures and outcomes for evaluation and debugging</li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#lifecycle-overview","title":"Lifecycle overview","text":"<p>```mermaid flowchart LR   C[Client] --&gt;|/v1/recommend| S[recsys-service]   S --&gt; DB[(Postgres)]   S --&gt;|load manifest + artifacts| OS[(Object store)]</p> <p>E[Interaction events] --&gt; P[recsys-pipelines]   P --&gt;|publish artifacts (immutable)| OS   P --&gt;|swap current manifest (pointer)| OS ```</p>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#publish-and-reload-sequence-pipelines-current-manifest-service","title":"Publish and reload sequence (pipelines \u2192 current manifest \u2192 service)","text":"<p>```mermaid sequenceDiagram   participant Scheduler   participant Pipelines as recsys-pipelines   participant Store as Object store   participant Service as recsys-service   participant Operator</p> <p>Scheduler-&gt;&gt;Pipelines: Run job (tenant,surface,window)   Pipelines-&gt;&gt;Store: Write artifacts (immutable URIs)   Pipelines-&gt;&gt;Store: Write manifest (tenant,surface)   Pipelines-&gt;&gt;Store: Update current manifest pointer   Note over Service: On request or TTL expiry   Service-&gt;&gt;Store: Fetch current manifest   Service-&gt;&gt;Store: Fetch artifacts by URI   Operator-&gt;&gt;Service: (Optional) cache invalidate ```</p>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#ship-and-rollback-in-practice","title":"\u201cShip\u201d and \u201crollback\u201d in practice","text":""},{"location":"explanation/artifacts-and-manifest-lifecycle/#shipping","title":"Shipping","text":"<p>Shipping in artifact mode means:</p> <ol> <li>pipelines publish new artifact versions (new URIs)</li> <li>pipelines update the manifest\u2019s <code>current{}</code> map to point at those URIs</li> <li>pipelines write the updated manifest to the \u201ccurrent\u201d pointer location</li> </ol> <p>The service then observes the new manifest after:</p> <ul> <li>the manifest TTL expires, or</li> <li>an operator invalidates caches via an admin endpoint (if enabled and permitted)</li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#rolling-back","title":"Rolling back","text":"<p>Rollback means restoring the previous manifest content at the \u201ccurrent\u201d pointer location.</p> <p>Operationally:</p> <ul> <li>keep a copy of the previous manifest (or write manifests to a versioned path in your CI before updating \u201ccurrent\u201d)</li> <li>swapping back is fast because artifacts are immutable and already present in object storage</li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#what-to-monitor-minimum","title":"What to monitor (minimum)","text":"<ul> <li>Empty recommendations rate (per surface): a fast signal that a shipped manifest is missing artifacts or is empty</li> <li>Artifact freshness: the age of the manifest\u2019s <code>updated_at</code> per <code>(tenant, surface)</code></li> <li>Service logs: look for <code>artifact manifest loaded</code> and error logs fetching artifacts</li> </ul>"},{"location":"explanation/artifacts-and-manifest-lifecycle/#read-next","title":"Read next","text":"<ul> <li>Tutorial (ship + rollback): <code>tutorials/production-like-run.md</code></li> <li>Data modes (DB-only vs artifact/manifest): <code>explanation/data-modes.md</code></li> <li>Pipelines rollback guide: <code>recsys-pipelines/docs/how-to/rollback-manifest.md</code></li> </ul>"},{"location":"explanation/candidate-vs-ranking/","title":"Candidate generation vs ranking","text":""},{"location":"explanation/candidate-vs-ranking/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers integrating <code>recsys-service</code> who want predictable behavior</li> <li>Recommendation engineers explaining \u201cwhy did we show this?\u201d</li> <li>Operators debugging empty or surprising results</li> </ul>"},{"location":"explanation/candidate-vs-ranking/#what-you-will-get","title":"What you will get","text":"<ul> <li>A mental model for how a request becomes a ranked top-K list</li> <li>The difference between candidate generation (recall) and ranking (precision)</li> <li>How overrides, constraints, and rules interact (and in what order)</li> <li>A small worked example you can reason about</li> </ul>"},{"location":"explanation/candidate-vs-ranking/#mental-model-end-to-end","title":"Mental model (end-to-end)","text":"<p>Serving is a pipeline. Each stage has a different job:</p> <ol> <li>Candidate generation: build a high-recall pool (many plausible items).</li> <li>Ranking: score candidates and pick the best top-K.</li> <li>Policy and controls: apply constraints and business rules.</li> <li>Response: return items + metadata + warnings for debugging.</li> </ol>"},{"location":"explanation/candidate-vs-ranking/#candidate-generation-high-recall","title":"Candidate generation (high recall)","text":"<p>Candidate generation answers: \u201cWhat items should we even consider?\u201d</p> <p>This suite supports multiple candidate sources. Some sources may be unavailable depending on your data mode and which signals you have built; the service returns warnings like <code>SIGNAL_UNAVAILABLE</code> or <code>SIGNAL_PARTIAL</code> when a signal cannot contribute.</p>"},{"location":"explanation/candidate-vs-ranking/#candidate-sources-used-in-this-suite-conceptually","title":"Candidate sources used in this suite (conceptually)","text":"<ul> <li>Popularity (always available in DB-only mode; great baseline)</li> <li>\u201cWhat\u2019s trending / frequently interacted with in this surface/namespace?\u201d</li> <li>Co-visitation (requires interaction history)</li> <li>\u201cUsers who engaged with X also engaged with Y.\u201d</li> <li>Similarity signals (optional; depends on what stores/signals you provide)</li> <li>collaborative (\u201cpeople like you\u201d), content/tag similarity, and session-based similarity</li> </ul>"},{"location":"explanation/candidate-vs-ranking/#anchors-how-you-seed-candidates","title":"Anchors: how you \u201cseed\u201d candidates","text":"<p>Some candidate sources need one or more \u201canchor items\u201d (for example: co-visitation).</p> <p>In this API you can provide anchors explicitly:</p> <ul> <li><code>anchors.item_ids</code> (explicit seed items)</li> </ul> <p>In addition, <code>candidates.include_ids</code> is treated as an anchor source internally (useful when you want to force the engine to consider a specific set of items).</p>"},{"location":"explanation/candidate-vs-ranking/#ranking-precision","title":"Ranking (precision)","text":"<p>Ranking answers: \u201cWhich of these candidates are best for this request?\u201d</p> <p><code>recsys-algo</code> is deterministic and can explain its output. At a high level it:</p> <ul> <li>merges candidates from available sources</li> <li>computes per-item scores (a blend of signals)</li> <li>optionally adds explainability metadata (<code>options.explain</code>, <code>options.include_reasons</code>)</li> </ul>"},{"location":"explanation/candidate-vs-ranking/#signal-weights-weights","title":"Signal weights (<code>weights</code>)","text":"<p>You can influence blending per request:</p> <ul> <li><code>weights.pop</code>: popularity contribution</li> <li><code>weights.cooc</code>: co-visitation contribution</li> <li><code>weights.emb</code>: \u201csimilarity\u201d contribution (a bucket for non-pop/non-cooc signals)</li> </ul> <p>If you omit <code>weights</code>, the service uses its configured defaults (see <code>RECSYS_ALGO_*</code> config in <code>reference/config/recsys-service.md</code>).</p>"},{"location":"explanation/candidate-vs-ranking/#controls-constraints-and-rules-order-matters","title":"Controls: constraints and rules (order matters)","text":"<p>After the algorithm produces ranked items, the service applies controls in this order:</p> <ol> <li>Rule pins: pinned items are moved to the top.</li> <li>Pin rules can inject items that were not in the candidate pool.</li> <li>If injection happens, you will see <code>RULE_PIN_INJECTED</code>.</li> <li>Post-ranking constraints (when tag data is available):</li> <li><code>constraints.forbidden_tags</code></li> <li><code>constraints.max_per_tag</code></li> <li>If filtering happens, you will see <code>CONSTRAINTS_FILTERED</code>.</li> <li>Candidate allow-list:</li> <li><code>candidates.include_ids</code> is applied as a final allow-list filter.</li> <li>If it removes some results, you will see <code>CANDIDATES_INCLUDE_FILTERED</code>.</li> <li>If it removes everything, you will see <code>CANDIDATES_INCLUDE_EMPTY</code>.</li> </ol> <p>Additionally:</p> <ul> <li><code>candidates.exclude_ids</code> is treated as a strict exclusion and removes those items from consideration.</li> <li><code>constraints.required_tags</code> is used to require at least one tag match (for example: require a category tag).</li> </ul>"},{"location":"explanation/candidate-vs-ranking/#worked-example-request-candidates-output","title":"Worked example: request \u2192 candidates \u2192 output","text":"<p>Request (illustrative):</p> <pre><code>{\n  \"surface\": \"home\",\n  \"k\": 5,\n  \"user\": { \"user_id\": \"u_1\" },\n  \"anchors\": { \"item_ids\": [\"item_10\"] },\n  \"candidates\": {\n    \"include_ids\": [\"item_1\", \"item_2\", \"item_99\"],\n    \"exclude_ids\": [\"item_3\"]\n  },\n  \"constraints\": {\n    \"forbidden_tags\": [\"adult\"],\n    \"max_per_tag\": { \"category:shoes\": 2 }\n  },\n  \"options\": { \"include_reasons\": true, \"explain\": \"summary\" }\n}\n</code></pre> <p>How to think about it:</p> <ol> <li>Candidate generation produces a pool, e.g.:</li> <li>popularity candidates: <code>item_1, item_2, item_3, item_4, item_5</code></li> <li>co-visitation from anchor <code>item_10</code>: <code>item_6, item_7</code></li> <li>Ranking scores candidates and returns a ranked list (top-K):</li> <li><code>item_2, item_4, item_3, item_6, item_1</code></li> <li>Exclusions remove <code>item_3</code> (because it is explicitly excluded).</li> <li>Post-ranking constraints remove items with <code>adult</code> tags and enforce <code>max_per_tag</code>.</li> <li>Allow-list keeps only <code>item_1, item_2, item_99</code> (and drops everything else).</li> <li>If a pin rule injected <code>item_99</code>, it can appear even if it was not in the original pool.</li> </ol> <p>If the allow-list contains items that never appear, you will likely end up with fewer than <code>k</code> results (and a warning).</p>"},{"location":"explanation/candidate-vs-ranking/#debugging-checklist","title":"Debugging checklist","text":"<ul> <li>Call <code>POST /v1/recommend/validate</code> first to see the normalized request and early warnings.</li> <li>Check <code>warnings[]</code> in responses for:</li> <li><code>SIGNAL_UNAVAILABLE</code> / <code>SIGNAL_PARTIAL</code></li> <li><code>CONSTRAINTS_FILTERED</code></li> <li><code>CANDIDATES_INCLUDE_*</code></li> <li><code>RULE_PIN_INJECTED</code></li> <li>Turn on explainability for development:</li> <li><code>options.include_reasons=true</code> for per-item <code>reasons[]</code></li> <li><code>options.explain=summary</code> or <code>options.explain=full</code> for structured <code>explain.signals</code></li> <li>If you get empty results in production, follow the runbook:   <code>operations/runbooks/empty-recs.md</code></li> </ul>"},{"location":"explanation/candidate-vs-ranking/#read-next","title":"Read next","text":"<ul> <li>Exposure logging (to measure impact): <code>explanation/exposure-logging-and-attribution.md</code></li> <li>Surface namespaces (avoid mismatches): <code>explanation/surface-namespaces.md</code></li> <li>Data modes (DB-only vs artifact/manifest): <code>explanation/data-modes.md</code></li> </ul>"},{"location":"explanation/cold-start-strategies/","title":"Cold start strategies","text":""},{"location":"explanation/cold-start-strategies/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Product and data stakeholders planning a pilot or rollout</li> <li>Engineers integrating <code>recsys-service</code> who need predictable fallbacks</li> <li>Recommendation engineers defining \u201cgood enough\u201d behavior for new users/items</li> </ul>"},{"location":"explanation/cold-start-strategies/#what-you-will-get","title":"What you will get","text":"<ul> <li>A taxonomy of cold-start scenarios (new user, new item, new surface)</li> <li>Practical strategies that work with today\u2019s RecSys suite capabilities</li> <li>A recommended fallback ladder (most personalized \u2192 least personalized)</li> <li>\u201cGotchas\u201d that commonly cause empty or low-quality results</li> </ul>"},{"location":"explanation/cold-start-strategies/#cold-start-scenarios","title":"Cold-start scenarios","text":"<p>Cold start usually means \u201cwe don\u2019t have a strong signal yet\u201d. In this suite, it often shows up as:</p> <ul> <li>New user / guest: no interaction history and no explicit anchors.</li> <li>Sparse-history user: a few events; personalization signals are noisy.</li> <li>New item: exists in the catalog but has little/no interaction signal.</li> <li>New surface (namespace): you have not seeded signals for a <code>surface</code> yet.</li> </ul>"},{"location":"explanation/cold-start-strategies/#baseline-behavior-in-this-suite","title":"Baseline behavior in this suite","text":"<ul> <li>In DB-only mode, the service reads signals from Postgres (at minimum <code>item_popularity_daily</code> and <code>item_tags</code>). If   <code>item_popularity_daily</code> has no rows for the surface namespace, you should expect empty recs (see the runbook).</li> <li>Candidate sources are opportunistic: when a signal/store is missing, the service still returns results when it   can, but emits warnings like <code>SIGNAL_UNAVAILABLE</code> / <code>SIGNAL_PARTIAL</code>.</li> <li>Rule pins can inject items that were not in the candidate pool (useful for curated cold-start defaults).</li> <li><code>segment</code> defaults to <code>default</code> when omitted. Segments are used to scope rules and to slice evaluation.</li> </ul>"},{"location":"explanation/cold-start-strategies/#strategy-1-catalog-only-curated-defaults-via-rules","title":"Strategy 1: Catalog-only (curated defaults via rules)","text":"<p>If you have a catalog but not enough interaction data yet, start with a curated \u201cstarter set\u201d:</p> <ul> <li>Add segment-scoped pin rules for <code>segment=guest</code> / <code>segment=new_user</code>.</li> <li>Roll pins forward/back by updating rules (versioned + cacheable).</li> </ul> <p>Minimal example (pin two items for guest users on <code>home</code>):</p> <pre><code>[\n  {\n    \"action\": \"pin\",\n    \"target_type\": \"item\",\n    \"item_ids\": [\"item_101\", \"item_202\"],\n    \"surface\": \"home\",\n    \"segment\": \"guest\",\n    \"priority\": 100\n  }\n]\n</code></pre> <p>Notes:</p> <ul> <li>Pin rules can inject items that are not in the candidate pool, but constraints/caps may still filter them if you use   tag-based constraints.</li> <li>If you need tighter control over how many pins a rule can place, set <code>max_pins</code> on the rule.</li> </ul>"},{"location":"explanation/cold-start-strategies/#strategy-2-popularity-priors-bootstrap-new-items-and-new-surfaces","title":"Strategy 2: Popularity priors (bootstrap new items and new surfaces)","text":"<p>Popularity is the simplest reliable fallback, but new items won\u2019t show up until they have signal. You can bootstrap them using a prior:</p> <ul> <li>When an item is created, write a small initial score into <code>item_popularity_daily</code> for \u201ctoday\u201d.</li> <li>Keep priors small so they don\u2019t dominate real popularity, and let the configured half-life decay them naturally.</li> </ul> <p>This is also how you avoid \u201cnew surface cold start\u201d:</p> <ul> <li>Seed a minimal popularity table for the new surface namespace.</li> <li>If you intentionally want a cross-surface fallback, use the <code>default</code> namespace fallback described in   <code>explanation/surface-namespaces.md</code>.</li> </ul>"},{"location":"explanation/cold-start-strategies/#strategy-3-segment-defaults-different-policies-per-cohort","title":"Strategy 3: Segment defaults (different policies per cohort)","text":"<p>Segments are a lightweight way to make cold-start behavior explicit without changing surfaces:</p> <ul> <li>Set <code>segment</code> in requests (examples: <code>guest</code>, <code>new_user</code>, <code>returning</code>).</li> <li>Use segment-scoped rules to pin/boost/block items differently per cohort.</li> <li>Use <code>segment</code> in <code>recsys-eval</code> to slice metrics (\u201cdoes cold-start improve without harming returning users?\u201d).</li> </ul>"},{"location":"explanation/cold-start-strategies/#strategy-4-a-fallback-ladder-what-to-try-in-order","title":"Strategy 4: A fallback ladder (what to try, in order)","text":"<p>Treat cold start as a fallback ladder: try the most specific signal you have, then degrade gracefully.</p> <p>Recommended ladder:</p> <ol> <li>Contextual anchors: if you can provide <code>anchors.item_ids</code> (for example, the PDP item), do so.</li> <li>Co-visitation (when available): similar-by-context, even for new users (anchors don\u2019t require user history).</li> <li>Popularity: surface-level trending / frequently interacted.</li> <li>Curated pins: rules-based starter set per surface/segment.</li> <li>Application-level fallback: if the API returns empty, render a safe default and log that it happened.</li> </ol>"},{"location":"explanation/cold-start-strategies/#common-cold-start-failure-modes-and-fixes","title":"Common cold-start failure modes (and fixes)","text":"<ul> <li>Empty results because the surface has no popularity rows</li> <li>Fix: seed <code>item_popularity_daily</code> for the surface namespace (or intentionally rely on <code>default</code> fallback).</li> <li>Runbook: <code>operations/runbooks/empty-recs.md</code></li> <li>Overly strict allow-lists</li> <li>Symptom: <code>CANDIDATES_INCLUDE_EMPTY</code>.</li> <li>Fix: prefer <code>anchors.item_ids</code> for seeding; use <code>candidates.include_ids</code> only when you mean \u201conly these items\u201d.</li> <li>Constraints filtering everything</li> <li>Symptom: <code>CONSTRAINTS_FILTERED</code>.</li> <li>Fix: ensure <code>item_tags</code> exists for the same surface namespace and relax constraints during cold start.</li> </ul>"},{"location":"explanation/cold-start-strategies/#read-next","title":"Read next","text":"<ul> <li>Candidate vs ranking (controls order and warnings): <code>explanation/candidate-vs-ranking.md</code></li> <li>Admin API (rules scoping by segment): <code>reference/api/admin.md</code></li> <li>Minimal pilot (DB-only): <code>tutorials/minimal-pilot-db-only.md</code></li> </ul>"},{"location":"explanation/data-modes/","title":"Data modes: DB-only vs object store","text":"<p>The service supports DB-only mode and artifact/manifest mode. DB-only is the default; artifact mode is opt-in via config.</p>"},{"location":"explanation/data-modes/#db-only-mode-current-recommended-for-mvp","title":"DB-only mode (current, recommended for MVP)","text":"<p>Signals are stored directly in Postgres tables and read by the service:</p> <ul> <li><code>item_tags</code></li> <li><code>item_popularity_daily</code></li> <li><code>item_covisit_daily</code> (if enabled)</li> </ul> <p>Popularity uses a decayed sum over <code>item_popularity_daily</code> with the configured half-life, so newer days dominate when you seed both recent and older rows.</p> <p>This is ideal for local development and popularity-only pilots.</p>"},{"location":"explanation/data-modes/#artifactmanifest-mode-pipelines-object-store","title":"Artifact/manifest mode (pipelines + object store)","text":"<p>Pipelines can publish artifacts (popularity, co-vis, embeddings) to object storage and update a manifest pointer. This enables atomic updates and easy rollback, but the service must be configured to read artifacts.</p> <p>Enable artifact mode:</p> <ul> <li><code>RECSYS_ARTIFACT_MODE_ENABLED=true</code></li> <li><code>RECSYS_ARTIFACT_MANIFEST_TEMPLATE</code> (e.g. <code>s3://recsys/registry/current/{tenant}/{surface}/manifest.json</code>,</li> </ul> <p>or <code>file:///data/registry/current/{tenant}/{surface}/manifest.json</code>)</p> <p>Notes:</p> <ul> <li><code>{tenant}</code> uses the incoming tenant id (header/JWT) when available.</li> <li><code>{surface}</code> maps to the request surface (namespace).</li> <li>Tags and constraints still read from Postgres (<code>item_tags</code>), even in artifact mode.</li> </ul>"},{"location":"explanation/data-modes/#recommendation","title":"Recommendation","text":"<ul> <li>Use DB-only for MVP and local testing (default today).</li> <li>Use object store + manifest for production-scale artifacts once the</li> </ul> <p>pipelines are producing artifacts and the service is configured to read them.</p>"},{"location":"explanation/data-modes/#which-mode-is-active","title":"Which mode is active?","text":"<p>The service runs in DB-only mode by default. When <code>RECSYS_ARTIFACT_MODE_ENABLED=true</code>, the service reads popularity/co-visitation from the artifact manifest and uses Postgres for tag metadata.</p>"},{"location":"explanation/experimentation-model/","title":"Experimentation model (A/B, interleaving, OPE)","text":""},{"location":"explanation/experimentation-model/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Product and stakeholders who need a clear \u201chow do we measure lift?\u201d story</li> <li>Engineers wiring evaluation into CI and production workflows</li> <li>Recommendation engineers choosing between A/B, interleaving, and OPE</li> </ul>"},{"location":"explanation/experimentation-model/#what-you-will-get","title":"What you will get","text":"<ul> <li>A decision guide for which evaluation mode to use (and when)</li> <li>The instrumentation required for each mode (what to log)</li> <li>How <code>recsys-service</code> supports experiment metadata and deterministic bucketing</li> <li>Common failure modes (SRM, broken joins, confounded tests)</li> </ul>"},{"location":"explanation/experimentation-model/#the-key-idea-measure-with-logs","title":"The key idea: measure with logs","text":"<p>Every evaluation mode in this suite is built on the same foundation:</p> <ul> <li>Expose: what you showed (ranked list)</li> <li>Outcome: what the user did (click/conversion)</li> <li>Correlate: join by <code>request_id</code></li> </ul> <p>If exposures or <code>request_id</code> are missing, everything else becomes guesswork.</p> <p>See: <code>explanation/exposure-logging-and-attribution.md</code></p>"},{"location":"explanation/experimentation-model/#choosing-a-mode-what-to-use-when","title":"Choosing a mode (what to use when)","text":"<p>Use this as your default decision guide:</p> Goal Mode What you need What you get Regression gate Offline evaluation exposures + outcomes ranking metrics (NDCG/Recall/etc.) KPI lift (shipping) Experiment (A/B) exposures + outcomes + assignments KPI deltas + guardrails + SRM Ranker comparison Interleaving ranklist A + ranklist B + outcomes win rate + significance Estimate (no randomize) OPE exposures + outcomes + propensities IPS/SNIPS/DR + diagnostics <p>Notes:</p> <ul> <li>Offline metrics are excellent for \u201cdid we break something?\u201d, but they are not a replacement for measuring KPI lift.</li> <li>OPE is powerful but easy to get wrong; treat it as advanced and validate assumptions carefully.</li> </ul>"},{"location":"explanation/experimentation-model/#required-instrumentation-minimal","title":"Required instrumentation (minimal)","text":"<p>The suite uses <code>recsys-eval</code> data contracts. At minimum:</p> <ul> <li>Exposure (<code>exposure.v1</code> / eval JSONL): <code>request_id</code>, <code>user_id</code>, <code>ts</code>, <code>items[]</code></li> <li>Outcome (<code>outcome.v1</code>): <code>request_id</code>, <code>user_id</code>, <code>item_id</code>, <code>event_type</code>, <code>ts</code></li> </ul> <p>Mode-specific:</p> <ul> <li>Experiment (A/B): assignment stream (<code>assignment.v1</code>) with <code>experiment_id</code>, <code>variant</code>, <code>request_id</code>, <code>user_id</code>, <code>ts</code></li> <li>Interleaving: rank lists (<code>ranklist.v1</code>) for ranker A and ranker B (same <code>request_id</code> join key)</li> <li>OPE: propensities on each exposed item (<code>propensity</code> fields on exposure items)</li> </ul> <p>Full schemas: <code>reference/data-contracts/eval-events.md</code></p>"},{"location":"explanation/experimentation-model/#experiment-metadata-in-recsys-service","title":"Experiment metadata in <code>recsys-service</code>","text":"<p>The recommend API accepts optional experiment metadata:</p> <pre><code>{\n  \"surface\": \"home\",\n  \"k\": 10,\n  \"user\": { \"user_id\": \"u_123\" },\n  \"experiment\": { \"id\": \"exp_home_rank_v2\", \"variant\": \"B\" }\n}\n</code></pre> <p>What the service does with it:</p> <ul> <li>The experiment is included in exposure logging (when <code>EXPOSURE_LOG_FORMAT=eval_v1</code>) as <code>experiment_id</code> and   <code>experiment_variant</code> context keys.</li> <li>The service does not change ranking behavior based on <code>experiment.variant</code>. Your application (or an experiment   platform) must decide what differs between control and candidate (for example: <code>algorithm</code>, <code>weights</code>, or an upstream   candidate set).</li> </ul>"},{"location":"explanation/experimentation-model/#deterministic-variant-assignment-optional","title":"Deterministic variant assignment (optional)","text":"<p>If you provide an experiment ID but omit the variant:</p> <ul> <li>and <code>EXPERIMENT_ASSIGNMENT_ENABLED=true</code></li> <li>and you provide at least one stable identifier (<code>user_id</code>, <code>session_id</code>, or <code>anonymous_id</code>)</li> </ul> <p>then the service assigns a deterministic variant during request normalization (see <code>POST /v1/recommend/validate</code>).</p> <p>Configure:</p> <ul> <li><code>EXPERIMENT_DEFAULT_VARIANTS</code> (default: <code>A,B</code>)</li> <li><code>EXPERIMENT_ASSIGNMENT_SALT</code> (recommended: set this; defaults to <code>EXPOSURE_HASH_SALT</code>)</li> </ul> <p>This feature is primarily for consistent logging and debugging; it is not a full experimentation platform.</p>"},{"location":"explanation/experimentation-model/#getting-assignmentv1-events-practical-options","title":"Getting <code>assignment.v1</code> events (practical options)","text":"<p><code>recsys-eval</code> experiment analysis expects a separate assignment stream.</p> <p>You have two good options:</p> <ol> <li>If you already have an experimentation platform: export its assignment logs into <code>assignment.v1</code>.</li> <li>If you use <code>recsys-service</code> exposure logs: derive assignments from exposure records (when experiment context is    present):</li> </ol> <pre><code>jq -c '\n  select(.context.experiment_id and .context.experiment_variant) |\n  {\n    experiment_id: .context.experiment_id,\n    variant: .context.experiment_variant,\n    request_id: .request_id,\n    user_id: .user_id,\n    ts: .ts,\n    context: {\n      tenant_id: .context.tenant_id,\n      surface: .context.surface,\n      segment: .context.segment\n    }\n  }\n' exposures.eval.jsonl &gt; assignments.jsonl\n</code></pre>"},{"location":"explanation/experimentation-model/#common-experiment-failure-modes","title":"Common experiment failure modes","text":"<ul> <li>Broken joins (missing/mismatched <code>request_id</code>)</li> <li>Symptom: low join rate, unstable metrics.</li> <li>Fix: follow the join rules in <code>reference/data-contracts/join-logic.md</code>.</li> <li>SRM (sample ratio mismatch)</li> <li>Symptom: recsys-eval report warns that buckets are imbalanced.</li> <li>Fix: ensure deterministic assignment and stable subject IDs; avoid platform-specific bucketing bugs.</li> <li>Confounded experiments</li> <li>Symptom: variant B is \u201cbetter\u201d, but you changed multiple things at once.</li> <li>Fix: keep the treatment minimal (one meaningful change), and record config/rules/algo versions in logs.</li> </ul>"},{"location":"explanation/experimentation-model/#read-next","title":"Read next","text":"<ul> <li>Run eval and ship (suite workflow): <code>how-to/run-eval-and-ship.md</code></li> <li>recsys-eval concepts (modes and pitfalls): <code>recsys-eval/docs/concepts.md</code></li> <li>recsys-eval interleaving and OPE: <code>recsys-eval/docs/interleaving.md</code>,   <code>recsys-eval/docs/ope.md</code></li> </ul>"},{"location":"explanation/exposure-logging-and-attribution/","title":"Exposure logging and attribution","text":""},{"location":"explanation/exposure-logging-and-attribution/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Integrators wiring RecSys into a product (webshop, content feed, etc.)</li> <li>Recommendation engineers and analysts running <code>recsys-eval</code></li> <li>Operators who need to debug \u201cwhy are metrics wrong?\u201d incidents</li> </ul>"},{"location":"explanation/exposure-logging-and-attribution/#what-you-will-get","title":"What you will get","text":"<ul> <li>The minimum you must log to measure recommendations</li> <li>How to attribute outcomes to exposures safely (joins that work)</li> <li>How to configure <code>recsys-service</code> to emit eval-compatible exposure logs</li> <li>Common logging bugs and the symptoms they cause</li> </ul>"},{"location":"explanation/exposure-logging-and-attribution/#the-one-rule-log-exposures","title":"The one rule: log exposures","text":"<p>If you only log clicks/purchases (outcomes) but not \u201cwhat you showed\u201d (exposures), you cannot evaluate recommendation quality. Clicks without exposures are not attributable.</p> <p>Exposure logging is also the foundation for:</p> <ul> <li>offline regression (quality gates before shipping)</li> <li>online experiments (measuring lift)</li> <li>incident debugging (\u201cdid we serve the wrong config/rules/algo?\u201d)</li> </ul>"},{"location":"explanation/exposure-logging-and-attribution/#end-to-end-flow-request-exposure-outcome","title":"End-to-end flow (request \u2192 exposure \u2192 outcome)","text":"<p>```mermaid sequenceDiagram   participant Client   participant Service as recsys-service   participant DB as Postgres   participant Store as Object store   participant Log as Exposure log   participant Events as Outcome events</p> <p>Client-&gt;&gt;Service: POST /v1/recommend   Service-&gt;&gt;DB: Load config + rules   alt Artifact mode enabled     Service-&gt;&gt;Store: Fetch manifest + artifacts   end   Service--&gt;&gt;Client: Response (items[], request_id)   Service-&gt;&gt;Log: Write exposure.v1 (request_id, items, context)   Client-&gt;&gt;Events: Emit outcome.v1 (request_id, item_id, ts) ```</p> <p>The join key is <code>request_id</code>. Your product must carry it from the recommend call to the outcome event.</p>"},{"location":"explanation/exposure-logging-and-attribution/#what-to-log-minimum-viable","title":"What to log (minimum viable)","text":"<p>You need two streams, plus an optional third:</p> <ol> <li>Exposure: what items you showed and in what order (ranked list)</li> <li>Outcome: what the user did (click, conversion, etc.)</li> <li>Assignment (optional): what experiment variant this request/user was in</li> </ol> <p>For evaluation, all joins are driven by <code>request_id</code>.</p>"},{"location":"explanation/exposure-logging-and-attribution/#exposure-recsys-eval-exposurev1","title":"Exposure (recsys-eval: <code>exposure.v1</code>)","text":"<p>Required fields:</p> <ul> <li><code>request_id</code>: join key (stable per recommendation request)</li> <li><code>user_id</code>: stable, pseudonymous identifier (do not log raw PII)</li> <li><code>ts</code>: RFC3339 timestamp</li> <li><code>items[]</code>: array of <code>{ item_id, rank }</code> (rank is 1-based)</li> </ul> <p>Strongly recommended context keys:</p> <ul> <li><code>tenant_id</code>, <code>surface</code>, <code>segment</code></li> <li><code>algo_version</code>, <code>config_version</code>, <code>rules_version</code> (for auditability)</li> </ul> <p>Example (JSONL; one object per line):</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"u_hash_1\",\"ts\":\"2026-02-05T10:00:00Z\",\"items\":[{\"item_id\":\"item_1\",\"rank\":1},{\"item_id\":\"item_2\",\"rank\":2}],\"context\":{\"tenant_id\":\"demo\",\"surface\":\"home\",\"segment\":\"default\"}}\n</code></pre>"},{"location":"explanation/exposure-logging-and-attribution/#outcome-recsys-eval-outcomev1","title":"Outcome (recsys-eval: <code>outcome.v1</code>)","text":"<p>Required fields:</p> <ul> <li><code>request_id</code>: must match the exposure\u2019s <code>request_id</code></li> <li><code>user_id</code>: should match the exposure\u2019s <code>user_id</code> (recommended for sanity checks and downstream analytics)</li> <li><code>item_id</code>: item that was clicked/converted</li> <li><code>event_type</code>: <code>click</code> or <code>conversion</code></li> <li><code>ts</code>: RFC3339 timestamp</li> </ul> <p>Example:</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"u_hash_1\",\"item_id\":\"item_2\",\"event_type\":\"click\",\"ts\":\"2026-02-05T10:00:03Z\"}\n</code></pre>"},{"location":"explanation/exposure-logging-and-attribution/#assignment-recsys-eval-assignmentv1-optional","title":"Assignment (recsys-eval: <code>assignment.v1</code>, optional)","text":"<p>If you run A/B tests, log assignments so analysis can segment by variant.</p> <p>Required fields:</p> <ul> <li><code>experiment_id</code>, <code>variant</code>, <code>request_id</code>, <code>user_id</code>, <code>ts</code></li> </ul> <p>Example:</p> <pre><code>{\"experiment_id\":\"exp-1\",\"variant\":\"A\",\"request_id\":\"req-1\",\"user_id\":\"u_hash_1\",\"ts\":\"2026-02-05T10:00:00Z\",\"context\":{\"tenant_id\":\"demo\",\"surface\":\"home\"}}\n</code></pre> <p>See full schemas and examples: <code>reference/data-contracts/eval-events.md</code></p>"},{"location":"explanation/exposure-logging-and-attribution/#getting-request_id-right-attribution-correctness","title":"Getting <code>request_id</code> right (attribution correctness)","text":"<p>To attribute outcomes to the right exposure, you need a single <code>request_id</code> that flows:</p> <p><code>client request \u2192 recsys-service response \u2192 outcome event</code></p> <p>You have two common options:</p> <ul> <li>Client-supplied request IDs: set <code>X-Request-Id</code> when calling <code>/v1/recommend</code>, then reuse that ID in outcome events.</li> <li>Server-generated request IDs: read <code>meta.request_id</code> from the response and attach it to outcome events.</li> </ul> <p>Pick one, implement it consistently, and test joins early with <code>recsys-eval validate</code>.</p>"},{"location":"explanation/exposure-logging-and-attribution/#recsys-service-exposure-logging-built-in","title":"<code>recsys-service</code> exposure logging (built-in)","text":"<p>The service can write exposure logs as JSONL to a file or a directory:</p> <ul> <li><code>EXPOSURE_LOG_ENABLED=true</code></li> <li><code>EXPOSURE_LOG_PATH=/app/tmp/exposures.jsonl</code> (file) or <code>/app/tmp/</code> (directory)</li> <li><code>EXPOSURE_LOG_RETENTION_DAYS=30</code> (directory mode rotates and prunes old files)</li> </ul> <p>There are two output formats:</p> <ul> <li><code>service_v1</code>: service-native exposure event (good for audit/debugging)</li> <li><code>eval_v1</code>: <code>recsys-eval</code> compatible <code>exposure.v1</code> records (recommended for evaluation workflows)</li> </ul> <p>Recommended for evaluation:</p> <pre><code>EXPOSURE_LOG_ENABLED=true\nEXPOSURE_LOG_FORMAT=eval_v1\nEXPOSURE_LOG_PATH=/app/tmp/exposures.eval.jsonl\n</code></pre>"},{"location":"explanation/exposure-logging-and-attribution/#privacy-stable-pseudonymous-ids","title":"Privacy: stable pseudonymous IDs","text":"<p>The service logs hashed identifiers (HMAC-SHA256) rather than raw user IDs. Set a secret salt so hashes are stable and non-guessable:</p> <pre><code>EXPOSURE_HASH_SALT=change-me-to-a-secret\n</code></pre> <p>If no user/session identifier is available for eval output, the service falls back to using <code>request_id</code> as <code>user_id</code> to keep schemas valid (but this weakens user-level evaluation).</p>"},{"location":"explanation/exposure-logging-and-attribution/#common-logging-bugs-and-symptoms","title":"Common logging bugs (and symptoms)","text":"<ul> <li>Only outcomes, no exposures</li> <li>Symptom: you can\u2019t compute offline metrics; experiments are ambiguous.</li> <li>Outcome events missing <code>request_id</code></li> <li>Symptom: join rate collapses; reports look \u201ctoo good\u201d or \u201ctoo bad\u201d randomly.</li> <li>Different <code>user_id</code> values in exposures vs outcomes</li> <li>Symptom: low join rate or joins that only work for some platforms (web vs app).</li> <li>Multiple request IDs per single rendered list</li> <li>Symptom: duplicates, inconsistent attribution, confusing on-call investigations.</li> <li>Logging raw PII</li> <li>Symptom: security review blocks adoption; you may breach internal policy.</li> </ul>"},{"location":"explanation/exposure-logging-and-attribution/#verification-checklist-do-this-early","title":"Verification checklist (do this early)","text":"<ul> <li>Validate schemas:</li> <li><code>recsys-eval validate --schema exposure.v1 --input exposures.jsonl</code></li> <li><code>recsys-eval validate --schema outcome.v1 --input outcomes.jsonl</code></li> <li>Compute a basic join rate in your warehouse:</li> <li><code>% of exposures with at least one matching outcome by request_id</code></li> <li>Ensure your top slicing keys exist (at minimum: <code>tenant_id</code>, <code>surface</code>).</li> </ul>"},{"location":"explanation/exposure-logging-and-attribution/#read-next","title":"Read next","text":"<ul> <li>Data contracts hub: <code>reference/data-contracts/index.md</code></li> <li>Event join logic: <code>reference/data-contracts/join-logic.md</code></li> <li>Experimentation model (A/B, interleaving, OPE): <code>explanation/experimentation-model.md</code></li> <li>Candidate vs ranking: <code>explanation/candidate-vs-ranking.md</code></li> <li>Run eval and ship: <code>how-to/run-eval-and-ship.md</code></li> </ul>"},{"location":"explanation/pipelines-operational-invariants/","title":"Pipelines operational invariants (safety model)","text":""},{"location":"explanation/pipelines-operational-invariants/#who-this-is-for","title":"Who this is for","text":"<ul> <li>SRE/on-call and platform engineers operating <code>recsys-pipelines</code></li> <li>Lead developers designing a safe ship/rollback workflow</li> <li>Data engineers who need to reason about retries and partial failures</li> </ul>"},{"location":"explanation/pipelines-operational-invariants/#what-you-will-get","title":"What you will get","text":"<ul> <li>The invariants the pipelines try to maintain (and what is not guaranteed)</li> <li>What \u201cidempotent publish\u201d and \u201catomic ship\u201d mean in practice</li> <li>The failure modes that matter operationally, with safe recovery actions</li> </ul>"},{"location":"explanation/pipelines-operational-invariants/#invariant-1-artifacts-are-immutable-and-version-addressed","title":"Invariant 1: artifacts are immutable and version-addressed","text":"<p>An artifact is published under a version (hash) and treated as immutable:</p> <ul> <li>the same canonical payload should produce the same version</li> <li>older artifact versions remain readable after new publishes</li> </ul> <p>Operational consequence: you can cache aggressively and roll back safely because \u201cold\u201d data still exists.</p>"},{"location":"explanation/pipelines-operational-invariants/#invariant-2-publish-is-two-phase-and-swaps-the-manifest-last","title":"Invariant 2: publish is two-phase and swaps the manifest last","text":"<p>Publishing is structured so serving never reads a half-updated set:</p> <ol> <li>Write the versioned artifact blob</li> <li>Validate the artifact (including recomputing the version)</li> <li>Write a registry record for audit/rollback</li> <li>Swap the current manifest pointer last</li> </ol> <p>Operational consequence: if a publish fails before the final swap, \u201ccurrent\u201d serving stays on the previous manifest.</p>"},{"location":"explanation/pipelines-operational-invariants/#invariant-3-re-running-publish-is-intended-to-be-safe-idempotent","title":"Invariant 3: re-running publish is intended to be safe (idempotent)","text":"<p>Rerunning a pipeline for the same <code>(tenant, surface, window)</code> should not corrupt \u201ccurrent\u201d:</p> <ul> <li>versioned objects are written under stable keys (<code>\u2026/&lt;type&gt;/&lt;version&gt;.json</code>)</li> <li>registry records are append-only (re-recording an existing version is a no-op)</li> <li>the manifest swap is a whole-document replace, not an in-place patch</li> </ul> <p>Operational consequence: retrying is the default remediation for transient failures.</p>"},{"location":"explanation/pipelines-operational-invariants/#invariant-4-rollback-is-a-manifest-pointer-change","title":"Invariant 4: rollback is a manifest pointer change","text":"<p>Rollback is switching the current manifest back to a previous version.</p> <p>Operational consequence: rollback is fast and does not require re-computing artifacts.</p>"},{"location":"explanation/pipelines-operational-invariants/#what-is-not-guaranteed-plan-for-it","title":"What is not guaranteed (plan for it)","text":"<ul> <li>No built-in concurrency control: two publishes to the same <code>(tenant, surface)</code> can race; last manifest swap wins.</li> <li>No automatic garbage collection: failed publishes can leave unreferenced artifacts (\u201corphans\u201d) in storage.</li> <li>Eventual visibility in serving: <code>recsys-service</code> may cache manifests/artifacts; changes apply after TTL or explicit   cache invalidation.</li> </ul>"},{"location":"explanation/pipelines-operational-invariants/#safe-recovery-patterns","title":"Safe recovery patterns","text":"<ul> <li>If publish failed before manifest swap: fix the cause and retry (serving stayed on the previous manifest).</li> <li>If you shipped a bad manifest: roll back the manifest pointer (do not delete artifacts).</li> <li>If you see stale serving: invalidate caches or wait for TTL; then verify the service is reading the expected manifest.</li> </ul>"},{"location":"explanation/pipelines-operational-invariants/#read-next","title":"Read next","text":"<ul> <li>Artifacts + manifest lifecycle: <code>explanation/artifacts-and-manifest-lifecycle.md</code></li> <li>Pipelines output layout (registry paths): <code>recsys-pipelines/docs/reference/output-layout.md</code></li> <li>Roll back the manifest: <code>recsys-pipelines/docs/how-to/rollback-manifest.md</code></li> </ul>"},{"location":"explanation/suite-architecture/","title":"Suite architecture","text":""},{"location":"explanation/suite-architecture/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Lead developers and platform engineers integrating the suite</li> <li>Recommendation engineers who want a \u201cwhole system\u201d mental model</li> <li>SRE / on-call engineers who need to know rollback levers and common failure modes</li> </ul>"},{"location":"explanation/suite-architecture/#what-you-will-get","title":"What you will get","text":"<ul> <li>The end-to-end data flow from serving \u2192 logging \u2192 pipelines \u2192 evaluation</li> <li>Where state lives in each mode (DB-only vs artifact/manifest)</li> <li>The IDs that tie everything together (<code>tenant_id</code>, <code>surface</code>, <code>request_id</code>)</li> <li>The operational levers for safe shipping and rollback</li> </ul>"},{"location":"explanation/suite-architecture/#one-screen-mental-model","title":"One-screen mental model","text":"<p>```mermaid flowchart LR   C[Client] --&gt;|/v1/recommend| S[recsys-service]   S --&gt; A[recsys-algo]   S --&gt; E[(Exposure logs)]   C --&gt; O[(Outcome logs)]</p> <p>E --&gt; P[recsys-pipelines]   O --&gt; P   P --&gt; M[(Manifest pointer)]   M --&gt; S</p> <p>E --&gt; V[recsys-eval]   O --&gt; V   V --&gt; D[(Report + ship/rollback decision)] ```</p> <p>See also: <code>start-here/diagrams/suite-context.md</code></p>"},{"location":"explanation/suite-architecture/#components-and-responsibilities","title":"Components and responsibilities","text":""},{"location":"explanation/suite-architecture/#recsys-service-online","title":"recsys-service (online)","text":"<p>Responsibilities:</p> <ul> <li>Low-latency HTTP API (<code>/v1/recommend</code>, <code>/v1/similar</code>)</li> <li>Tenancy and scoping (tenant headers/JWT claims, surfaces, segments)</li> <li>Caching and backpressure</li> <li>Exposure logging (for evaluation and auditability)</li> </ul> <p>Reads:</p> <ul> <li>Tenant config/rules (versioned) from Postgres (optional but recommended)</li> <li>Signals either:</li> <li>from Postgres tables (DB-only mode), or</li> <li>from artifacts referenced by a manifest pointer (artifact/manifest mode)</li> </ul> <p>Writes:</p> <ul> <li>Exposure logs (file-based JSONL by default)</li> <li>Optional audit logs for admin writes</li> </ul> <p>Start here:</p> <ul> <li>Admin/bootstrap: <code>reference/api/admin.md</code></li> <li>Config reference: <code>reference/config/recsys-service.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#recsys-algo-ranking-core","title":"recsys-algo (ranking core)","text":"<p>Responsibilities:</p> <ul> <li>Deterministic ranking/scoring of candidate sets</li> <li>Constraints/rules/diversity with explainability support</li> <li>Ports-and-adapters design so storage backends can vary</li> </ul> <p>Start here:</p> <ul> <li><code>recsys-algo</code></li> </ul>"},{"location":"explanation/suite-architecture/#recsys-pipelines-offline-artifact-builder","title":"recsys-pipelines (offline artifact builder)","text":"<p>Responsibilities:</p> <ul> <li>Ingest and canonicalize raw events</li> <li>Compute versioned artifacts (e.g., popularity, co-occurrence)</li> <li>Publish artifacts and update the \u201ccurrent\u201d pointer (manifest)</li> <li>Provide rollback by pointer swap (never point serving at missing blobs)</li> </ul> <p>Start here:</p> <ul> <li><code>recsys-pipelines/docs/start-here.md</code></li> <li>Artifact lifecycle: <code>recsys-pipelines/docs/explanation/artifacts-and-versioning.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#recsys-eval-evaluation-decision-support","title":"recsys-eval (evaluation + decision support)","text":"<p>Responsibilities:</p> <ul> <li>Validate logs against strict schemas</li> <li>Compute offline regression gates and online experiment analysis</li> <li>Produce reports and a decision trail (\u201cship / hold / rollback\u201d)</li> </ul> <p>Start here:</p> <ul> <li>Overview: <code>recsys-eval/overview.md</code></li> <li>Interpreting results: <code>recsys-eval/docs/interpreting_results.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#the-key-identifiers-how-the-system-joins-up","title":"The key identifiers (how the system joins up)","text":"<ul> <li><code>tenant_id</code>: organization boundary for data isolation and config (see <code>tenants.external_id</code>)</li> <li><code>surface</code>: where recommendations are shown (e.g., <code>home</code>, <code>pdp</code>); also a signal namespace by default</li> <li><code>segment</code>: optional sub-slice within a surface (e.g., <code>new_users</code>)</li> <li><code>request_id</code>: join key across exposure logs and outcomes; make it stable per request</li> <li><code>user_id</code>: stable, pseudonymous identifier (avoid raw PII)</li> </ul> <p>Related:</p> <ul> <li>Namespacing: <code>explanation/surface-namespaces.md</code></li> <li>Logging: <code>explanation/exposure-logging-and-attribution.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#data-modes-db-only-vs-artifactmanifest","title":"Data modes: DB-only vs artifact/manifest","text":"<p>There are two supported serving modes:</p> <ul> <li>DB-only mode: signals live in Postgres tables and are read directly by the service.</li> <li>Artifact/manifest mode: pipelines publish versioned blobs to object storage and the service reads the current   versions via a manifest pointer.</li> </ul> <p>This tradeoff is explained here:</p> <ul> <li><code>explanation/data-modes.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#ship-and-rollback-what-changes-in-production","title":"Ship and rollback: what changes in production","text":"<p>Common production levers:</p> <p>1) Config and rules</p> <ul> <li>Update via admin endpoints (versioned, optimistic concurrency).</li> <li>Invalidate service caches after updates.</li> </ul> <p>See:</p> <ul> <li><code>reference/api/admin.md</code></li> </ul> <p>2) Artifacts / manifest pointer</p> <ul> <li>Pipelines publish new artifacts and swap the manifest pointer last.</li> <li>Rollback is a pointer swap to the last known-good manifest.</li> </ul> <p>See:</p> <ul> <li>Pipelines rollback: <code>recsys-pipelines/docs/how-to/rollback-manifest.md</code></li> <li>Suite runbook (service): <code>operations/runbooks/rollback-config-rules.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#common-failure-modes-and-where-to-look","title":"Common failure modes (and where to look)","text":"<ul> <li>Empty recs</li> <li>missing signals (DB-only) or missing/incorrect manifest (artifact mode)</li> <li>surface/namespace mismatch (<code>home</code> data queried under <code>pdp</code>)</li> <li>overly strict constraints/rules</li> </ul> <p>See:</p> <ul> <li><code>operations/runbooks/empty-recs.md</code></li> <li> <p><code>explanation/surface-namespaces.md</code></p> </li> <li> <p>Forbidden / tenant scope errors</p> </li> <li>tenant headers missing or mismatched</li> </ul> <p>See:</p> <ul> <li><code>how-to/integrate-recsys-service.md</code></li> </ul>"},{"location":"explanation/suite-architecture/#read-next","title":"Read next","text":"<ul> <li>Tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>How-to: <code>how-to/run-eval-and-ship.md</code></li> </ul>"},{"location":"explanation/surface-namespaces/","title":"Surface namespaces","text":"<p>The service treats surface as a first-class scoping key. In practice this means the online API uses <code>surface</code> as the namespace when reading signals (e.g., popularity, tags, co-vis). This keeps signals isolated per surface by default and prevents \"home\" data from leaking into \"pdp\" results.</p>"},{"location":"explanation/surface-namespaces/#recommended-strategy","title":"Recommended strategy","text":"<ul> <li>Use a small, stable list of surface names (e.g., <code>home</code>, <code>pdp</code>, <code>cart</code>).</li> <li>In pipelines, emit artifacts/signals with <code>surface</code> matching the API surface.</li> <li>In DB-only mode, write signals under <code>namespace = &lt;surface&gt;</code>.</li> </ul>"},{"location":"explanation/surface-namespaces/#default-namespace-fallback","title":"Default namespace fallback","text":"<p>The service currently falls back to <code>default</code> for popularity/tags when a surface namespace is missing. This is helpful for local development but can be surprising in production.</p> <p>Best practice:</p> <ul> <li>Seed per-surface data for production.</li> <li>Use <code>default</code> only for shared or global signals.</li> </ul> <p>Note on similar-items:</p> <ul> <li><code>/v1/similar</code> reads co-visit signals scoped by surface/namespace.</li> <li>If you only seed <code>home</code>, requests for <code>surface=pdp</code> will return empty results.</li> </ul>"},{"location":"explanation/surface-namespaces/#example","title":"Example","text":"<ul> <li>API request: <code>surface=home</code></li> <li>Signals stored under: <code>namespace=home</code></li> <li>Optional fallback: <code>namespace=default</code> if <code>home</code> has no rows</li> </ul>"},{"location":"how-to/deploy-helm/","title":"Deploy with Helm (production-ish)","text":""},{"location":"how-to/deploy-helm/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Platform engineers deploying <code>recsys-service</code> to Kubernetes</li> <li>Teams running artifact/manifest mode with external Postgres + S3/MinIO</li> </ul>"},{"location":"how-to/deploy-helm/#goal","title":"Goal","text":"<p>Install <code>recsys-service</code> and optionally a <code>recsys-pipelines</code> CronJob. Postgres and MinIO are disabled by default so you can bring your own.</p>"},{"location":"how-to/deploy-helm/#prereqs","title":"Prereqs","text":"<ul> <li>Helm 3 + <code>kubectl</code></li> <li>A Postgres database (or enable the chart\u2019s bundled Postgres for local demos)</li> <li>An S3-compatible bucket (or enable the chart\u2019s bundled MinIO for local demos)</li> </ul>"},{"location":"how-to/deploy-helm/#steps","title":"Steps","text":""},{"location":"how-to/deploy-helm/#1-install-byo-postgres-s3","title":"1) Install (BYO Postgres + S3)","text":"<pre><code>RECSYS_ARTIFACT_MANIFEST_TEMPLATE='s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json'\n\nhelm install recsys ./charts/recsys \\\n  --set api.env.DATABASE_URL='postgres://user:pass@db:5432/recsys?sslmode=disable' \\\n  --set api.env.RECSYS_ARTIFACT_MANIFEST_TEMPLATE=\"${RECSYS_ARTIFACT_MANIFEST_TEMPLATE}\" \\\n  --set api.env.RECSYS_ARTIFACT_S3_ENDPOINT='s3.example.com' \\\n  --set api.env.RECSYS_ARTIFACT_S3_ACCESS_KEY='***' \\\n  --set api.env.RECSYS_ARTIFACT_S3_SECRET_KEY='***'\n</code></pre>"},{"location":"how-to/deploy-helm/#2-local-demo-enable-bundled-postgres-minio","title":"2) Local demo (enable bundled Postgres + MinIO)","text":"<pre><code># kind\n./scripts/helm_local.sh --kind\n\n# minikube\n./scripts/helm_local.sh --minikube\n</code></pre>"},{"location":"how-to/deploy-helm/#3-enable-pipelines-cronjob","title":"3) Enable pipelines CronJob","text":"<pre><code>helm upgrade --install recsys ./charts/recsys \\\n  --set pipelines.enabled=true \\\n  --set pipelines.schedule='0 2 * * *'\n</code></pre> <p>The CronJob reads <code>pipelines.configJson</code> from a ConfigMap. Override it in <code>values.yaml</code> for your tenant, surfaces, and storage endpoints.</p>"},{"location":"how-to/deploy-helm/#verify","title":"Verify","text":"<pre><code>kubectl get deploy,svc,cronjob\nkubectl logs deploy/recsys-api\n</code></pre>"},{"location":"how-to/deploy-helm/#pitfalls","title":"Pitfalls","text":"<ul> <li>The chart uses the <code>DATABASE_URL</code> env var as defined in <code>api/.env.example</code>.</li> <li>If you disable bundled Postgres/MinIO, you must provide external endpoints.</li> <li>The pipelines job requires object store + registry configured in its config.</li> </ul>"},{"location":"how-to/deploy-helm/#read-next","title":"Read next","text":"<ul> <li>Operational invariants (pipelines safety model): <code>explanation/pipelines-operational-invariants.md</code></li> <li>Artifacts and manifest lifecycle: <code>explanation/artifacts-and-manifest-lifecycle.md</code></li> <li>Production readiness checklist: <code>operations/production-readiness-checklist.md</code></li> </ul>"},{"location":"how-to/integrate-recsys-service/","title":"How-to: integrate recsys-service into an application","text":""},{"location":"how-to/integrate-recsys-service/#who-this-is-for","title":"Who this is for","text":"<p>Backend and platform engineers integrating <code>recsys-service</code> into a product (webshop, content feed, etc.).</p>"},{"location":"how-to/integrate-recsys-service/#goal","title":"Goal","text":"<p>Call <code>POST /v1/recommend</code>, render the list, and log outcomes with correct attribution so evaluation and troubleshooting work.</p>"},{"location":"how-to/integrate-recsys-service/#prereqs","title":"Prereqs","text":"<ul> <li>A small stable set of surfaces, e.g. <code>home</code>, <code>pdp</code>, <code>cart</code></li> <li>Stable pseudonymous identifiers (<code>user_id</code> and/or <code>session_id</code>)</li> <li>Admin bootstrap completed for the tenant (tenant + config + rules)</li> </ul>"},{"location":"how-to/integrate-recsys-service/#steps","title":"Steps","text":"<p>1) Define your surfaces (home, pdp, checkout) and keep names stable. 2) Send stable pseudonymous user/session identifiers. 3) Call <code>POST /v1/recommend</code> and render the ranked list. 4) Log outcomes (click/purchase) linked by <code>request_id</code>. 5) Use <code>POST /v1/recommend/validate</code> during development to catch warnings early. 6) Handle failures: empty list fallback; respect <code>429 Retry-After</code> under load.</p> <p>Notes:</p> <ul> <li><code>surface</code> also acts as the signal/rules namespace.</li> <li>For local MVPs, a <code>default</code> namespace fallback is available (see <code>explanation/surface-namespaces.md</code>).</li> <li>Admin bootstrap (tenant + config + rules) is required before first use:</li> </ul> <p>see <code>reference/api/admin.md</code>. - If you want a domain-specific mental model, start with the cookbooks:   - <code>how-to/integration-cookbooks/index.md</code></p>"},{"location":"how-to/integrate-recsys-service/#verify","title":"Verify","text":"<p>Validate one request shape:</p> <pre><code>curl -fsS http://localhost:8000/v1/recommend/validate \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: integ-req-1' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"u_1\"}}'\n</code></pre> <p>Then call recommend and ensure you capture <code>meta.request_id</code> (or supply <code>X-Request-Id</code>) and propagate it into outcomes.</p>"},{"location":"how-to/integrate-recsys-service/#pitfalls","title":"Pitfalls","text":""},{"location":"how-to/integrate-recsys-service/#tenant-headers-local-dev","title":"Tenant headers (local dev)","text":"<ul> <li>When <code>DEV_AUTH_ENABLED=true</code>, send both:</li> <li><code>X-Dev-Org-Id</code> (dev auth tenant context)</li> <li><code>X-Org-Id</code> (tenant scope enforced by middleware)</li> <li>In JWT mode, a bearer token with a tenant claim is sufficient (see <code>AUTH_TENANT_CLAIMS</code>).</li> <li>To use a single header locally, set <code>DEV_AUTH_TENANT_HEADER=X-Org-Id</code>.</li> </ul>"},{"location":"how-to/integrate-recsys-service/#read-next","title":"Read next","text":"<ul> <li>Exposure logging &amp; attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> <li>Admin bootstrap (tenant + config + rules): <code>reference/api/admin.md</code></li> <li>Integration cookbooks: <code>how-to/integration-cookbooks/index.md</code></li> </ul>"},{"location":"how-to/operate-pipelines/","title":"How-to: operate recsys-pipelines","text":""},{"location":"how-to/operate-pipelines/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Data engineers and platform engineers operating <code>recsys-pipelines</code></li> <li>SRE/on-call who need a concrete ship/rollback model for artifact mode</li> </ul>"},{"location":"how-to/operate-pipelines/#goal","title":"Goal","text":"<p>Keep artifacts fresh and safely ship/rollback manifests for each <code>(tenant, surface)</code> pair.</p>"},{"location":"how-to/operate-pipelines/#prereqs","title":"Prereqs","text":"<ul> <li>Decide your data mode:</li> <li>DB-only (signals in Postgres)</li> <li>artifact/manifest mode (artifacts in an object store + a     manifest pointer)</li> <li>If using artifact/manifest mode:</li> <li>object store credentials are configured for pipelines and the service</li> <li><code>RECSYS_ARTIFACT_MANIFEST_TEMPLATE</code> points at your \u201ccurrent manifest\u201d convention</li> </ul>"},{"location":"how-to/operate-pipelines/#steps","title":"Steps","text":""},{"location":"how-to/operate-pipelines/#daily-operation-artifactmanifest-mode","title":"Daily operation (artifact/manifest mode)","text":"<ul> <li>Ingest exposure/outcome events.</li> <li>Validate and canonicalize.</li> <li>Build artifacts (start with popularity).</li> <li>Publish artifacts and swap the manifest pointer last.</li> <li>Monitor freshness, volume anomalies, and output sizes.</li> </ul>"},{"location":"how-to/operate-pipelines/#backfills","title":"Backfills","text":"<ul> <li>Compute artifacts for explicit time windows.</li> <li>Publish and swap the manifest pointer to the new version.</li> <li>Keep prior manifests available for rollback.</li> </ul>"},{"location":"how-to/operate-pipelines/#rollback","title":"Rollback","text":"<ul> <li>Swap the manifest pointer back to a last-known-good version.</li> <li>Invalidate service caches (or wait for TTL) to reduce \u201cstale manifest\u201d confusion.</li> </ul>"},{"location":"how-to/operate-pipelines/#local-minio-example-docker-compose-default","title":"Local MinIO example (docker-compose default)","text":"<ul> <li>Bucket: <code>${MINIO_BUCKET:-recsys-artifacts}</code></li> <li>Manifest path convention: <code>registry/current/{tenant}/{surface}/manifest.json</code></li> <li>Example manifest URI:</li> </ul> <p><code>s3://recsys-artifacts/registry/current/demo/home/manifest.json</code></p>"},{"location":"how-to/operate-pipelines/#service-env-artifact-mode","title":"Service env (artifact mode)","text":"<pre><code>RECSYS_ARTIFACT_MODE_ENABLED=true\nRECSYS_ARTIFACT_MANIFEST_TEMPLATE=s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json\nRECSYS_ARTIFACT_S3_ENDPOINT=minio:9000\nRECSYS_ARTIFACT_S3_ACCESS_KEY=minioadmin\nRECSYS_ARTIFACT_S3_SECRET_KEY=minioadmin\nRECSYS_ARTIFACT_S3_REGION=us-east-1\nRECSYS_ARTIFACT_S3_USE_SSL=false\n</code></pre>"},{"location":"how-to/operate-pipelines/#verify","title":"Verify","text":"<ul> <li>Pipelines produced a manifest for your tenant/surface (local filesystem registry example):</li> </ul> <pre><code>cat .out/registry/current/demo/home/manifest.json\n</code></pre> <ul> <li>The service can read the manifest (no <code>artifact incompatible</code> errors) and returns non-empty results for a seeded   tenant/surface.</li> </ul>"},{"location":"how-to/operate-pipelines/#pitfalls","title":"Pitfalls","text":""},{"location":"how-to/operate-pipelines/#registry_dir-location-matters","title":"<code>registry_dir</code> location matters","text":"<ul> <li>If <code>registry_dir</code> points to <code>s3://.../registry</code>, pipelines will write   manifests directly to MinIO and you do not need a manual upload step.   A local path (e.g. <code>registry</code>) requires uploading the manifest yourself.</li> </ul>"},{"location":"how-to/operate-pipelines/#db-only-mode-simplest-pilot","title":"DB-only mode (simplest pilot)","text":"<ul> <li>write signals into Postgres tables instead of publishing artifacts</li> <li>useful for local MVPs and popularity-only pilots</li> <li>seed examples: <code>reference/database/db-only-seeding.md</code></li> </ul>"},{"location":"how-to/operate-pipelines/#read-next","title":"Read next","text":"<ul> <li>Operational invariants (pipelines safety model): <code>explanation/pipelines-operational-invariants.md</code></li> <li>Artifacts and manifest lifecycle: <code>explanation/artifacts-and-manifest-lifecycle.md</code></li> <li>Pipelines SLOs and freshness: <code>recsys-pipelines/docs/operations/slos-and-freshness.md</code></li> </ul>"},{"location":"how-to/run-eval-and-ship/","title":"How-to: run evaluation and make ship decisions","text":""},{"location":"how-to/run-eval-and-ship/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers shipping recommender changes and needing a quality gate</li> <li>Analysts validating impact from logs</li> <li>Operators who need an auditable \u201cship / hold / rollback\u201d decision trail</li> </ul>"},{"location":"how-to/run-eval-and-ship/#what-you-will-get","title":"What you will get","text":"<ul> <li>A runnable baseline workflow for validating logs and producing reports</li> <li>A clear recommendation for when to use offline vs experiment analysis</li> <li>Links to the deeper <code>recsys-eval</code> docs for interpretation and scaling</li> </ul>"},{"location":"how-to/run-eval-and-ship/#goal","title":"Goal","text":"<p>Turn exposure/outcome logs into a report you can use to decide ship / hold / rollback.</p>"},{"location":"how-to/run-eval-and-ship/#prereqs","title":"Prereqs","text":"<ul> <li><code>recsys-eval</code> built (from this repo):</li> </ul> <pre><code>cd recsys-eval\nmake build\n</code></pre> <ul> <li>Logs in the v1 schemas:</li> <li>exposures: <code>exposure.v1</code></li> <li>outcomes: <code>outcome.v1</code></li> <li>assignments: <code>assignment.v1</code> (required for experiment mode)</li> </ul>"},{"location":"how-to/run-eval-and-ship/#0-validate-inputs-always","title":"0) Validate inputs (always)","text":"<p>Validation is strict (extra fields can fail). Run this before trusting any metric:</p> <pre><code>./bin/recsys-eval validate --schema exposure.v1 --input exposures.jsonl\n./bin/recsys-eval validate --schema outcome.v1 --input outcomes.jsonl\n./bin/recsys-eval validate --schema assignment.v1 --input assignments.jsonl\n</code></pre> <p>Tip: if you want <code>recsys-service</code> to emit <code>exposure.v1</code> directly, set:</p> <ul> <li><code>EXPOSURE_LOG_ENABLED=true</code></li> <li><code>EXPOSURE_LOG_FORMAT=eval_v1</code></li> </ul> <p>See: <code>explanation/exposure-logging-and-attribution.md</code></p>"},{"location":"how-to/run-eval-and-ship/#1-run-an-offline-regression-gate-recommended-baseline","title":"1) Run an offline regression gate (recommended baseline)","text":"<p>Always run an offline regression gate in CI:</p> <ul> <li>compare baseline vs candidate versions</li> <li>fail if a primary metric regresses beyond a threshold</li> </ul> <p>Example:</p> <pre><code>./bin/recsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.ci.yaml \\\n  --output /tmp/offline_report.md \\\n  --output-format markdown\n</code></pre> <p>If your exposure logs come from <code>recsys-service</code> in <code>eval_v1</code> format, the exposure <code>context</code> keys are named like <code>tenant_id</code>, <code>surface</code>, and <code>segment</code>. Ensure your <code>slice_keys</code> use the same names.</p>"},{"location":"how-to/run-eval-and-ship/#2-prefer-online-experiments-when-possible","title":"2) Prefer online experiments when possible","text":"<p>Online A/B tests are the best way to measure real impact:</p> <ul> <li>log exposures with experiment id/variant</li> <li>log outcomes tied to the same <code>request_id</code></li> <li>check KPI + guardrails</li> </ul> <p>Example:</p> <pre><code>./bin/recsys-eval run \\\n  --mode experiment \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/experiment.default.yaml \\\n  --output /tmp/experiment_report.md \\\n  --output-format markdown\n</code></pre>"},{"location":"how-to/run-eval-and-ship/#3-ship-rollback-mechanics","title":"3) Ship / rollback mechanics","text":"<p>Ship if KPI improves and guardrails hold. Hold if results are inconclusive. Roll back if primary or guardrails regress.</p> <p>Rollback levers:</p> <ul> <li>Artifacts/manifest: swap the manifest pointer (pipelines) and invalidate service caches</li> <li>Config/rules: roll back config/rules versions and invalidate service caches</li> </ul> <p>See:</p> <ul> <li>Pipelines rollback: <code>recsys-pipelines/docs/how-to/rollback-manifest.md</code></li> <li>Admin cache invalidation: <code>reference/api/admin.md</code></li> <li>Interpreting results: <code>recsys-eval/docs/interpreting_results.md</code></li> </ul>"},{"location":"how-to/run-eval-and-ship/#verify","title":"Verify","text":"<ul> <li>The report file exists and includes a summary table for your chosen mode.</li> <li>Join integrity is sane (if join rate is low, fix logging before trusting metrics).</li> </ul>"},{"location":"how-to/run-eval-and-ship/#read-next","title":"Read next","text":"<ul> <li>Experimentation model: <code>explanation/experimentation-model.md</code></li> <li>Exposure logging and attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> </ul>"},{"location":"how-to/integration-cookbooks/","title":"Integration cookbooks (map RecSys to your domain)","text":""},{"location":"how-to/integration-cookbooks/#who-this-is-for","title":"Who this is for","text":"<p>Integrators and platform engineers who need a quick, concrete mapping from RecSys concepts to real product patterns.</p>"},{"location":"how-to/integration-cookbooks/#what-you-will-get","title":"What you will get","text":"<ul> <li>Three \u201ccopy this mental model\u201d integration patterns</li> <li>What to log (and why) so evaluation and troubleshooting work</li> <li>Pitfalls that commonly break attribution and trust</li> </ul>"},{"location":"how-to/integration-cookbooks/#common-building-blocks-all-cookbooks","title":"Common building blocks (all cookbooks)","text":"<ul> <li>Define stable surfaces (<code>home</code>, <code>pdp</code>, <code>related</code>, etc.).</li> <li>Generate or propagate a stable <code>request_id</code> per rendered list.</li> <li>Log exposures (ranked list) and outcomes (click/conversion) with the same <code>request_id</code>.</li> </ul> <p>Read first if you haven\u2019t yet:</p> <ul> <li>Basic integration steps: <code>how-to/integrate-recsys-service.md</code></li> <li>Exposure logging &amp; attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> <li>Event join logic: <code>reference/data-contracts/join-logic.md</code></li> </ul>"},{"location":"how-to/integration-cookbooks/#cookbooks","title":"Cookbooks","text":"<ul> <li>Webshop: <code>webshop.md</code></li> <li>Content feed: <code>content-feed.md</code></li> <li>Event bus / streaming: <code>event-bus.md</code></li> </ul>"},{"location":"how-to/integration-cookbooks/content-feed/","title":"Cookbook: integrate with a content feed","text":""},{"location":"how-to/integration-cookbooks/content-feed/#who-this-is-for","title":"Who this is for","text":"<p>Engineers integrating recommendations into a feed-like product (articles, videos, collections).</p>"},{"location":"how-to/integration-cookbooks/content-feed/#what-you-will-get","title":"What you will get","text":"<ul> <li>A surface plan for feed placements (<code>home</code>, <code>related</code>, <code>next_up</code>)</li> <li>A minimal request + attribution pattern that supports offline eval and experiments</li> <li>Pitfalls to avoid for infinite scroll and delayed outcomes</li> </ul>"},{"location":"how-to/integration-cookbooks/content-feed/#goal","title":"Goal","text":"<p>Integrate recommendations into a feed-like product (articles, videos, collections) with attribution that supports both offline evaluation and online experiments.</p>"},{"location":"how-to/integration-cookbooks/content-feed/#typical-surfaces","title":"Typical surfaces","text":"<ul> <li><code>home</code>: personalized feed modules</li> <li><code>related</code>: \u201crelated content\u201d blocks on detail pages</li> <li><code>next_up</code>: \u201cwatch next\u201d / \u201cread next\u201d</li> </ul> <p>Use surfaces to represent \u201cwhere the list appears\u201d, not \u201cwhat the algorithm is\u201d. You can change algorithms without breaking instrumentation if surfaces stay stable.</p>"},{"location":"how-to/integration-cookbooks/content-feed/#minimal-serving-integration","title":"Minimal serving integration","text":"<ol> <li>Call <code>POST /v1/recommend</code> with a stable <code>request_id</code>.</li> <li>Render results in the feed module.</li> <li>Log exposure and outcomes with that same <code>request_id</code>.</li> </ol> <p>Example request:</p> <pre><code>curl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: feed-req-1' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"related\",\"k\":8,\"user\":{\"user_id\":\"u_9\",\"session_id\":\"s_9\"}}'\n</code></pre>"},{"location":"how-to/integration-cookbooks/content-feed/#outcomes-decide-what-counts-as-success","title":"Outcomes: decide what counts as \u201csuccess\u201d","text":"<p>Pick one primary outcome to start:</p> <ul> <li>click \u2192 <code>click</code></li> <li>long read / watch completion \u2192 <code>conversion</code></li> </ul> <p>If you change the definition of \u201cconversion\u201d, treat it as an evaluation contract change and communicate it (otherwise metric trends become incomparable).</p>"},{"location":"how-to/integration-cookbooks/content-feed/#verify","title":"Verify","text":"<ul> <li>Validate schemas with <code>recsys-eval validate</code>.</li> <li>Slice join rates by platform (web/app) and surface (<code>home</code>, <code>related</code>).</li> <li>Track \u201cempty recs\u201d rate per surface; it\u2019s a fast signal of missing signals or bad rules.</li> </ul>"},{"location":"how-to/integration-cookbooks/content-feed/#pitfalls","title":"Pitfalls","text":"<ul> <li>Infinite scroll creates many recommendation calls</li> <li>Fix: log one exposure per rendered module instance; avoid reusing <code>request_id</code> across modules.</li> <li>Outcome events missing <code>item_id</code></li> <li>Symptom: conversions exist but can\u2019t be attributed to ranked lists.</li> <li>Delayed outcomes</li> <li>For long reads/watches, outcomes may arrive minutes later. Ensure your event pipeline preserves <code>request_id</code>.</li> </ul>"},{"location":"how-to/integration-cookbooks/content-feed/#read-next","title":"Read next","text":"<ul> <li>Exposure logging &amp; attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> <li>Event join logic: <code>reference/data-contracts/join-logic.md</code></li> </ul>"},{"location":"how-to/integration-cookbooks/event-bus/","title":"Cookbook: integrate with an event bus (streaming)","text":""},{"location":"how-to/integration-cookbooks/event-bus/#who-this-is-for","title":"Who this is for","text":"<p>Platform engineers publishing exposure/outcome events into Kafka/Kinesis/PubSub and building downstream datasets.</p>"},{"location":"how-to/integration-cookbooks/event-bus/#what-you-will-get","title":"What you will get","text":"<ul> <li>A minimal architecture for correct attribution with an event bus</li> <li>A request_id strategy that survives retries and at-least-once delivery</li> <li>Verification checks that catch broken joins early</li> </ul>"},{"location":"how-to/integration-cookbooks/event-bus/#goal","title":"Goal","text":"<p>Publish exposure and outcome events to an event bus (Kafka/Kinesis/PubSub) so you can:</p> <ul> <li>build evaluation datasets reliably</li> <li>run <code>recsys-pipelines</code> on a schedule or stream</li> <li>debug and roll back with a clear audit trail</li> </ul>"},{"location":"how-to/integration-cookbooks/event-bus/#minimal-architecture","title":"Minimal architecture","text":"<p><code>mermaid flowchart LR   A[App / Edge] --&gt;|/v1/recommend| S[recsys-service]   S --&gt;|response + request_id| A   A --&gt;|exposure event| B[(Event bus)]   A --&gt;|outcome event| B   B --&gt; W[(Warehouse / object store)]   W --&gt; E[recsys-eval]   W --&gt; P[recsys-pipelines]</code></p>"},{"location":"how-to/integration-cookbooks/event-bus/#steps","title":"Steps","text":"<ol> <li>Choose where <code>request_id</code> is generated</li> <li>Client-generated: set <code>X-Request-Id</code> on the API call, reuse for outcomes.</li> <li> <p>Server-generated: read <code>meta.request_id</code> from the response, reuse for outcomes.</p> </li> <li> <p>Publish exposure events only after render</p> </li> <li> <p>Avoid logging prefetches; they destroy attribution quality.</p> </li> <li> <p>Publish outcomes with the same <code>request_id</code></p> </li> <li> <p>A retry that creates a new <code>request_id</code> is the fastest way to break joins.</p> </li> <li> <p>Handle duplicates</p> </li> <li>Most buses are at-least-once. Deduplicate downstream by <code>(request_id, item_id, event_type, ts)</code> (or your      equivalent).</li> </ol>"},{"location":"how-to/integration-cookbooks/event-bus/#verify","title":"Verify","text":"<ul> <li>Validate event schemas at the edge (or immediately in your stream processor).</li> <li>Monitor join rates and missing fields:</li> <li>outcomes missing <code>request_id</code></li> <li>outcomes missing <code>item_id</code></li> <li>exposures with empty <code>items[]</code></li> </ul>"},{"location":"how-to/integration-cookbooks/event-bus/#pitfalls","title":"Pitfalls","text":"<ul> <li>Out-of-order delivery</li> <li>Outcomes may arrive before exposures. Design your joins to handle late data.</li> <li>Multi-surface reuse</li> <li>Do not reuse <code>request_id</code> across different surfaces/modules.</li> <li>PII in event payloads</li> <li>Keep user identity pseudonymous; do not include raw email/phone.</li> </ul>"},{"location":"how-to/integration-cookbooks/event-bus/#read-next","title":"Read next","text":"<ul> <li>Data contracts hub: <code>reference/data-contracts/index.md</code></li> <li>Event join logic: <code>reference/data-contracts/join-logic.md</code></li> </ul>"},{"location":"how-to/integration-cookbooks/webshop/","title":"Cookbook: integrate with a webshop","text":""},{"location":"how-to/integration-cookbooks/webshop/#who-this-is-for","title":"Who this is for","text":"<p>Product and platform engineers integrating recommendations into an ecommerce experience.</p>"},{"location":"how-to/integration-cookbooks/webshop/#what-you-will-get","title":"What you will get","text":"<ul> <li>A surface plan for common ecommerce placements (<code>home</code>, <code>pdp</code>, <code>cart</code>)</li> <li>A minimal request + logging pattern that keeps attribution correct</li> <li>Early verification checks that prevent \u201cwe can\u2019t measure lift\u201d failures later</li> </ul>"},{"location":"how-to/integration-cookbooks/webshop/#goal","title":"Goal","text":"<p>Serve recommendations on common ecommerce surfaces and log events so you can measure impact and roll back safely.</p>"},{"location":"how-to/integration-cookbooks/webshop/#typical-surfaces","title":"Typical surfaces","text":"<ul> <li><code>home</code>: \u201cpopular now\u201d / personalized modules</li> <li><code>pdp</code>: \u201csimilar items\u201d</li> <li><code>cart</code>: cross-sell / \u201cfrequently bought together\u201d</li> </ul> <p>Treat each surface as a stable namespace. Changing surface names breaks rule targeting, signal routing, and evaluation slicing.</p>"},{"location":"how-to/integration-cookbooks/webshop/#minimal-serving-integration","title":"Minimal serving integration","text":"<ol> <li>Call <code>POST /v1/recommend</code> with a stable <code>request_id</code>.</li> <li>Render the returned <code>items[]</code> in the UI.</li> <li>Log an exposure event (what was shown, with ranks).</li> </ol> <p>Example request:</p> <pre><code>curl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: shop-req-1' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"pdp\",\"k\":12,\"user\":{\"user_id\":\"u_123\",\"session_id\":\"s_456\"}}'\n</code></pre>"},{"location":"how-to/integration-cookbooks/webshop/#minimal-logging-what-makes-evaluation-possible","title":"Minimal logging (what makes evaluation possible)","text":"<p>Log two streams:</p> <ul> <li>Exposure: ranked list served (join key: <code>request_id</code>)</li> <li>Outcome: what the user did (click and/or purchase)</li> </ul> <p>Outcome schema in <code>recsys-eval</code> supports <code>click</code> and <code>conversion</code>. A common webshop mapping is:</p> <ul> <li>PDP click \u2192 <code>click</code></li> <li>purchase \u2192 <code>conversion</code> (optionally include order value as <code>value</code>)</li> </ul> <p>Example outcome JSONL (one object per line):</p> <pre><code>{\"request_id\":\"shop-req-1\",\"user_id\":\"u_123\",\"item_id\":\"sku_42\",\"event_type\":\"click\",\"ts\":\"2026-02-05T10:00:03Z\"}\n{\"request_id\":\"shop-req-1\",\"user_id\":\"u_123\",\"item_id\":\"sku_42\",\"event_type\":\"conversion\",\"value\":79.00,\"ts\":\"2026-02-05T10:05:12Z\"}\n</code></pre>"},{"location":"how-to/integration-cookbooks/webshop/#verify-early-before-you-scale","title":"Verify (early, before you scale)","text":"<ul> <li>Ensure <code>request_id</code> is the same in:</li> <li>the HTTP request (<code>X-Request-Id</code>)</li> <li>the exposure log record</li> <li>the outcome log record</li> <li>Validate schemas:</li> <li><code>recsys-eval validate --schema exposure.v1 --input exposures.jsonl</code></li> <li><code>recsys-eval validate --schema outcome.v1 --input outcomes.jsonl</code></li> <li>Compute a join rate in your warehouse:</li> <li>% of exposures with \u22651 matching outcome by <code>request_id</code></li> </ul>"},{"location":"how-to/integration-cookbooks/webshop/#pitfalls-common-failure-modes","title":"Pitfalls (common failure modes)","text":"<ul> <li>CDN/UI retries generate new request IDs</li> <li>Symptom: outcomes don\u2019t join, join rate collapses.</li> <li>Fix: generate <code>request_id</code> once per rendered list and propagate it.</li> <li>Pre-fetching without rendering</li> <li>Symptom: many exposures with no outcomes; misleading metrics.</li> <li>Fix: only log exposures when you actually render to a user.</li> <li>Logging raw PII</li> <li>Fix: use pseudonymous IDs; never log email/phone.</li> </ul>"},{"location":"how-to/integration-cookbooks/webshop/#read-next","title":"Read next","text":"<ul> <li>Production-like ship/rollback: <code>tutorials/production-like-run.md</code></li> <li>Rules and constraints (control plane): <code>reference/api/admin.md</code></li> </ul>"},{"location":"licensing/","title":"Licensing","text":"<p>This repository is a multi-license codebase. Different directories are licensed under different terms.</p>"},{"location":"licensing/#quick-map","title":"Quick map","text":"<p>Path/component: <code>recsys-eval/**</code> License: Apache License 2.0 Purpose: Offline evaluation &amp; reporting tooling.</p> <p>Path/component: <code>api/**</code>, <code>recsys-algo/**</code>, <code>recsys-pipelines/**</code>, and everything else unless stated otherwise License: GNU AGPL v3 Purpose: Serving API, algorithms, pipelines, ops templates</p> <p>The authoritative license texts are in:</p> <ul> <li><code>LICENSE</code> (AGPLv3)</li> <li><code>recsys-eval/LICENSE</code> (Apache-2.0)</li> </ul>"},{"location":"licensing/#how-to-determine-the-license-for-a-file","title":"How to determine the license for a file","text":"<p>We recommend (and are moving toward) using SPDX license identifiers in file headers and storing license texts in a <code>LICENSES/</code> directory (REUSE specification style).</p> <p>If there is ever a mismatch between this page and file headers, the per-file SPDX identifier (or the closest directory-level declaration) is the source of truth.</p>"},{"location":"licensing/#using-recsys-eval-apache-20","title":"Using <code>recsys-eval</code> (Apache-2.0)","text":"<p>You can use, modify, and redistribute <code>recsys-eval</code> under Apache-2.0 terms, including in proprietary systems, provided you comply with the Apache-2.0 conditions (e.g., preserving notices).</p>"},{"location":"licensing/#using-the-serving-stack-agplv3","title":"Using the serving stack (AGPLv3)","text":"<p>The serving stack is licensed under the GNU Affero General Public License v3 (AGPLv3).</p> <p>If your organization cannot or does not want to comply with AGPL obligations, you can obtain a commercial license (see <code>COMMERCIAL.md</code>).</p>"},{"location":"licensing/#commercial-licensing","title":"Commercial licensing","text":"<p>We offer a commercial license as an alternative set of terms for parts of this repository covered by AGPLv3.</p> <p>See:</p> <ul> <li><code>COMMERCIAL.md</code> (overview, what you get, and how to buy)</li> <li><code>pricing.md</code> (tiers)</li> </ul>"},{"location":"licensing/#third-party-dependencies","title":"Third-party dependencies","text":"<p>This project depends on third-party open source libraries with their own licenses. Compliance for those dependencies is separate from this project\u2019s license. If you publish releases, include SBOMs and/or dependency license reports as part of your compliance workflow.</p>"},{"location":"licensing/#questions","title":"Questions","text":"<p>If you have licensing questions, open an issue titled \"Licensing question\" (public) or contact us privately if your question contains confidential details.</p>"},{"location":"licensing/commercial/","title":"Commercial Use &amp; Licensing","text":"<p>This page explains how to purchase and use a commercial license for parts of this repository that are otherwise licensed under AGPLv3.</p> <p>This page is informational and describes our commercial offering at a high level.</p>"},{"location":"licensing/commercial/#why-a-commercial-license","title":"Why a commercial license?","text":"<p>The AGPLv3 is designed for software used over a network. If you modify AGPL-covered code and provide network access to users, AGPLv3 requires offering those users access to the Corresponding Source of your modified version (see Section 13).</p> <p>A commercial license allows you to use the covered components under alternative terms, typically enabling:</p> <ul> <li>Internal or external deployment without AGPL source-offer obligations (subject to the commercial agreement)</li> <li>Keeping modifications private</li> <li>Using the software in proprietary stacks</li> </ul>"},{"location":"licensing/commercial/#what-is-covered","title":"What is covered?","text":"<p>Commercial licensing applies to the components that are AGPLv3 in this repository, including typically:</p> <ul> <li><code>recsys-svc</code> (serving API)</li> <li><code>recsys-algo</code> (algorithms used by the service)</li> <li><code>recsys-pipelines</code> (batch pipelines and artifact generation)</li> </ul> <p><code>recsys-eval</code> remains Apache-2.0.</p>"},{"location":"licensing/commercial/#what-you-get-when-you-buy","title":"What you get when you buy","text":"<p>A typical commercial purchase includes:</p> <ul> <li>A signed commercial license grant (agreement + order form)</li> <li>A license token/file for bookkeeping (optional, not DRM)</li> <li>Access to commercial release artifacts (e.g., signed container images) if you offer those</li> <li>Security and patch releases according to the purchased tier</li> <li>Optional support terms (if purchased)</li> </ul> <p>See <code>pricing.md</code> for tier definitions.</p>"},{"location":"licensing/commercial/#how-to-buy","title":"How to buy","text":"<p>Recommended low-friction flow:</p> <ol> <li>Choose a tier in <code>pricing.md</code></li> <li>Purchase via a self-serve checkout (e.g., Stripe payment link) or request an invoice</li> <li>Receive:</li> <li>commercial license paperwork,</li> <li>delivery instructions for artifacts (if applicable),</li> <li>optional support contact</li> </ol> <p>Placeholder: Replace the following with your actual process:</p> <ul> <li>Sales contact: <code>sales@recsys.app</code></li> <li>Billing contact: <code>billing@recsys.app</code></li> </ul>"},{"location":"licensing/commercial/#evaluation-licenses-optional","title":"Evaluation licenses (optional)","text":"<p>If you offer evaluation terms, define them clearly:</p> <ul> <li>Duration (e.g., 30 days)</li> <li>Limits (e.g., 1 deployment, non-production)</li> <li>What\u2019s included (e.g., private artifact access)</li> </ul> <p>Document details in <code>docs/licensing/eval_license.md</code> if you provide this.</p>"},{"location":"licensing/commercial/#where-are-the-legal-terms","title":"Where are the legal terms?","text":"<p>Commercial terms live in:</p> <ul> <li><code>docs/licensing/commercial_license.md</code></li> <li><code>docs/licensing/order_form.md</code></li> </ul>"},{"location":"licensing/commercial_license/","title":"RecSys Commercial License Agreement","text":"<p>Version: <code>1.0</code> Last updated: <code>2026-02-01</code></p> <p>This Commercial License Agreement (\"Agreement\") is between:</p> <ul> <li>Vendor: <code>VENDOR_LEGAL_NAME</code>, <code>ADDRESS</code> (\"Vendor\"), and  </li> <li>Customer: <code>CUSTOMER_LEGAL_NAME</code>, <code>ADDRESS</code> (\"Customer\")</li> </ul> <p>This Agreement provides the general terms for Customer\u2019s commercial use of the Software. Specific scope, fees, and entitlements are set out in one or more Order Forms that reference this Agreement.</p>"},{"location":"licensing/commercial_license/#1-definitions","title":"1. Definitions","text":"<ul> <li>\"Software\": The RecSys software identified in an Order Form, including related documentation, and any updates provided by Vendor under this Agreement.</li> <li>\"Commercial Artifacts\": Vendor-provided binaries, container images, license files/keys, and related deliverables made available under commercial terms.</li> <li>\"Open Source Components\": Components distributed under open-source licenses (e.g., Apache-2.0, AGPLv3) as identified in <code>licensing/index.md</code> or applicable notices.</li> <li>\"Production Deployment\": A production environment serving real end-user traffic.</li> <li>\"Tenant\": A logically separate recommendation domain (catalog + signals partition) as described in <code>pricing.md</code> or the Order Form.</li> <li>\"Authorized Scope\": The entitlements purchased by Customer and specified in the Order Form (e.g.,   number of tenants, number of production deployments).</li> <li>\"Order Form\": A document signed or accepted by Customer and Vendor that references this Agreement and specifies products, scope, term, and fees.</li> </ul>"},{"location":"licensing/commercial_license/#2-agreement-structure-and-order-of-precedence","title":"2. Agreement Structure and Order of Precedence","text":"<p>2.1. Order Forms are incorporated into and governed by this Agreement. 2.2. In case of conflict, the following order controls: Order Form \u2192 this Agreement \u2192 referenced policies/attachments.</p>"},{"location":"licensing/commercial_license/#3-commercial-license-grant","title":"3. Commercial License Grant","text":"<p>3.1. Subject to payment of fees and compliance with this Agreement, Vendor grants Customer a non-exclusive, worldwide, non-transferable license to:</p> <ul> <li>install, run, and use the Commercial Artifacts within the Authorized Scope for Customer\u2019s internal business operations;</li> <li>run the Software as a network service (including internal SaaS) within the Authorized Scope;</li> <li>make a reasonable number of copies for backup and internal administrative purposes.</li> </ul> <p>3.2. Modification Rights. Customer may modify the Software for internal use within the Authorized Scope. Customer is not required to disclose modifications under this commercial license.</p> <p>3.3. Affiliates and Contractors. Customer may permit affiliates and contractors to use the Software solely on Customer\u2019s behalf within the Authorized Scope, provided they are bound by obligations consistent with this Agreement. Customer remains responsible for their compliance.</p> <p>3.4. No implied rights. All rights not expressly granted are reserved by Vendor.</p>"},{"location":"licensing/commercial_license/#4-restrictions","title":"4. Restrictions","text":"<p>Customer must not:</p> <ul> <li>exceed the Authorized Scope (e.g., number of Production Deployments or Tenants) without purchasing an upgrade;</li> <li>sublicense, resell, rent, lease, or commercially distribute the Software or Commercial Artifacts, except as expressly allowed in an Order Form;</li> <li>use the Software for OEM/resale or third-party hosting unless explicitly purchased (Enterprise terms).</li> </ul>"},{"location":"licensing/commercial_license/#5-open-source-components","title":"5. Open Source Components","text":"<p>5.1. Open Source Components are governed by their respective open-source licenses. 5.2. This Agreement grants additional permissions for commercial use of the covered components as specified in Order Forms and/or <code>licensing/index.md</code>. 5.3. Nothing in this Agreement limits Customer\u2019s rights under applicable open-source licenses for Open Source Components.</p>"},{"location":"licensing/commercial_license/#6-delivery-updates","title":"6. Delivery; Updates","text":"<p>6.1. Vendor will provide Commercial Artifacts via <code>DELIVERY_METHOD</code> (e.g., private container registry). 6.2. Updates, if included, are provided during the Term as specified in the Order Form.</p>"},{"location":"licensing/commercial_license/#7-fees-and-payment","title":"7. Fees and Payment","text":"<p>7.1. Fees, invoicing, and payment terms are specified in the Order Form. 7.2. Taxes: Customer is responsible for applicable taxes/VAT, excluding Vendor\u2019s income taxes.</p>"},{"location":"licensing/commercial_license/#8-support-if-purchased","title":"8. Support (If Purchased)","text":"<p>8.1. Support is provided only if included in an Order Form. 8.2. Support scope, channels, and response targets are specified in the Order Form or an attached Support Policy.</p>"},{"location":"licensing/commercial_license/#9-confidentiality","title":"9. Confidentiality","text":"<p>Each party may receive the other\u2019s Confidential Information. The receiving party will protect it using reasonable care and use it only to perform under this Agreement.</p> <p>Confidentiality does not apply to information that is public, independently developed, or rightfully received from a third party.</p>"},{"location":"licensing/commercial_license/#10-intellectual-property-feedback","title":"10. Intellectual Property; Feedback","text":"<p>10.1. Vendor retains all IP rights in the Software and Commercial Artifacts, except the rights expressly granted to Customer. 10.2. Customer may provide feedback; Vendor may use feedback without obligation, provided it does not disclose Customer Confidential Information.</p>"},{"location":"licensing/commercial_license/#11-warranty-disclaimer","title":"11. Warranty Disclaimer","text":"<p>EXCEPT AS EXPRESSLY STATED IN AN ORDER FORM, THE SOFTWARE AND COMMERCIAL ARTIFACTS ARE PROVIDED \"AS IS\". VENDOR DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT, TO THE MAXIMUM EXTENT PERMITTED BY LAW.</p>"},{"location":"licensing/commercial_license/#12-limitation-of-liability","title":"12. Limitation of Liability","text":"<p>TO THE MAXIMUM EXTENT PERMITTED BY LAW:</p> <ul> <li>NEITHER PARTY IS LIABLE FOR INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL, OR PUNITIVE DAMAGES, OR LOSS OF PROFITS, REVENUE, DATA, OR BUSINESS INTERRUPTION.</li> <li>VENDOR\u2019S TOTAL LIABILITY UNDER THIS AGREEMENT WILL NOT EXCEED THE FEES PAID OR PAYABLE BY CUSTOMER UNDER THE APPLICABLE ORDER FORM IN THE 12 MONTHS PRECEDING THE EVENT GIVING RISE TO LIABILITY.</li> </ul>"},{"location":"licensing/commercial_license/#13-term-and-termination","title":"13. Term and Termination","text":"<p>13.1. This Agreement begins on the Effective Date and remains in effect until terminated. 13.2. Each Order Form has its own term. 13.3. Either party may terminate for material breach if not cured within 30 days of written notice. 13.4. Upon termination/expiration of an Order Form, Customer must stop using the Software beyond the scope of remaining active Order Forms.</p>"},{"location":"licensing/commercial_license/#14-compliance","title":"14. Compliance","text":"<p>Customer will comply with applicable laws, including export/sanctions laws, where applicable.</p>"},{"location":"licensing/commercial_license/#15-governing-law-venue","title":"15. Governing Law; Venue","text":"<p>This Agreement is governed by the laws of <code>GOVERNING_LAW_JURISDICTION</code>, excluding conflict-of-law rules. Exclusive venue: <code>VENUE</code>.</p>"},{"location":"licensing/commercial_license/#16-miscellaneous","title":"16. Miscellaneous","text":"<p>Assignment, force majeure, notices, severability, waiver, entire agreement.</p>"},{"location":"licensing/commercial_license/#signatures","title":"Signatures","text":"<p>Vendor: ___  Date: _ Name/Title: ______</p> <p>Customer: ____  Date: _ Name/Title: ___</p>"},{"location":"licensing/eval_license/","title":"RecSys Evaluation License Terms","text":"<p>Last updated: 2026-02-01 Vendor: RecSys (\"Vendor\") Licensee: The individual or entity downloading, installing, accessing, or using the Evaluation Materials (\"Licensee\")</p> <p>NOTE: This document is a lightweight evaluation agreement intended to enable internal evaluation. For production use under commercial terms, see <code>COMMERCIAL.md</code> and the Commercial License Agreement/Order Form templates under <code>commercial/</code>.</p>"},{"location":"licensing/eval_license/#1-acceptance","title":"1. Acceptance","text":"<p>By downloading, installing, accessing, pulling, or using any Evaluation Materials (defined below), Licensee agrees to these Evaluation License Terms.</p>"},{"location":"licensing/eval_license/#2-definitions","title":"2. Definitions","text":"<ul> <li>\"Software\": The RecSys software components and documentation.</li> <li>\"Evaluation Materials\": Any of the following, provided by Vendor for evaluation: (a) commercial builds (e.g.,   container images, binaries), (b) license files/keys, (c) documentation or evaluation pack, (d) updates to any of the   foregoing.</li> <li>\"Evaluation Term\": The time-limited period stated in Section 5.</li> <li>\"Production\": Use serving real end-user traffic in a live environment where recommendations materially affect   business operations, customers, or revenue (as determined reasonably by Vendor).</li> <li>\"Non-Production\": Dev/test/staging/sandbox evaluation environments.</li> </ul>"},{"location":"licensing/eval_license/#3-evaluation-license-grant","title":"3. Evaluation License Grant","text":"<p>Subject to these terms, Vendor grants Licensee a non-exclusive, non-transferable, non-sublicensable (except to permitted contractors under Section 4.4), revocable, limited license to install and operate the Evaluation Materials solely in Non-Production for Licensee\u2019s internal evaluation of suitability for Licensee\u2019s business needs during the Evaluation Term.</p> <p>No rights are granted beyond those expressly stated.</p>"},{"location":"licensing/eval_license/#4-restrictions","title":"4. Restrictions","text":""},{"location":"licensing/eval_license/#41-non-production-only","title":"4.1 Non-Production only","text":"<p>Licensee must not use the Evaluation Materials in Production.</p>"},{"location":"licensing/eval_license/#42-no-resale-oem-third-party-hosting","title":"4.2 No resale / OEM / third-party hosting","text":"<p>Licensee must not (a) resell, rent, lease, or otherwise commercialize the Evaluation Materials, (b) offer the Evaluation Materials as a service to third parties, or (c) embed the Evaluation Materials in a product or service offered to third parties.</p>"},{"location":"licensing/eval_license/#43-no-public-distribution","title":"4.3 No public distribution","text":"<p>Licensee must not distribute Evaluation Materials outside Licensee\u2019s organization.</p>"},{"location":"licensing/eval_license/#44-contractors","title":"4.4 Contractors","text":"<p>Licensee may allow its contractors to access Evaluation Materials only if:</p> <ul> <li>they are under confidentiality obligations at least as protective as Licensee\u2019s, and</li> <li>access is limited to the internal evaluation purpose.</li> </ul> <p>Licensee remains responsible for contractor compliance.</p>"},{"location":"licensing/eval_license/#45-benchmark-publication-optional","title":"4.5 Benchmark publication (optional)","text":"<p>Unless Vendor gives written permission, Licensee must not publish benchmark results of the Evaluation Materials. (If you want \"maximum openness\", delete this section.)</p>"},{"location":"licensing/eval_license/#5-term-and-expiration","title":"5. Term and Expiration","text":"<p>The Evaluation Term begins on the date Licensee first accesses the Evaluation Materials and lasts 30 days, unless extended in writing by Vendor.</p> <p>Upon expiration or termination, Licensee must stop use and destroy all Evaluation Materials in its possession, including license files/keys and any copied commercial artifacts, except that Licensee may retain evaluation results and notes that do not contain Vendor Confidential Information.</p>"},{"location":"licensing/eval_license/#6-confidentiality","title":"6. Confidentiality","text":"<p>Evaluation Materials, license files/keys, and any non-public documentation are Vendor\u2019s confidential information (\"Confidential Information\").</p> <p>Licensee agrees to protect Confidential Information using reasonable measures and not disclose it except as allowed under this agreement. This obligation survives for 3 years after expiration/termination.</p>"},{"location":"licensing/eval_license/#7-feedback","title":"7. Feedback","text":"<p>If Licensee provides feedback, suggestions, or evaluation results, Vendor may use them to improve the Software without obligation to Licensee. Feedback does not include Licensee\u2019s Confidential Information.</p>"},{"location":"licensing/eval_license/#8-support","title":"8. Support","text":"<p>Evaluation support, if any, is provided on a best-effort basis and may be limited. Vendor may choose not to provide support during evaluation.</p>"},{"location":"licensing/eval_license/#9-open-source-components","title":"9. Open Source Components","text":"<p>If Licensee uses any open-source components of RecSys separately, such components are governed by their respective open-source licenses. These Evaluation Terms govern only Evaluation Materials provided under this document.</p>"},{"location":"licensing/eval_license/#10-warranty-disclaimer","title":"10. Warranty Disclaimer","text":"<p>THE EVALUATION MATERIALS ARE PROVIDED \"AS IS\" AND \"AS AVAILABLE\". VENDOR DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT, TO THE MAXIMUM EXTENT PERMITTED BY LAW.</p>"},{"location":"licensing/eval_license/#11-limitation-of-liability","title":"11. Limitation of Liability","text":"<p>TO THE MAXIMUM EXTENT PERMITTED BY LAW:</p> <ul> <li>VENDOR WILL NOT BE LIABLE FOR ANY INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL, OR PUNITIVE DAMAGES, OR LOSS OF   PROFITS, REVENUE, DATA, OR BUSINESS INTERRUPTION.</li> <li>VENDOR\u2019S TOTAL LIABILITY UNDER THESE TERMS WILL NOT EXCEED EUR 500 (OR THE AMOUNT PAID FOR THE EVALUATION, IF   ANY), WHICHEVER IS GREATER.</li> </ul>"},{"location":"licensing/eval_license/#12-termination","title":"12. Termination","text":"<p>Vendor may terminate this Evaluation License immediately if Licensee breaches these terms. Upon termination, Licensee must comply with Section 5 (stop use and destroy Evaluation Materials).</p>"},{"location":"licensing/eval_license/#13-governing-law","title":"13. Governing Law","text":"<p>These terms are governed by the laws of <code>GOVERNING_LAW_JURISDICTION</code>, excluding conflict-of-law rules. The parties agree to the exclusive venue of <code>VENUE</code>.</p>"},{"location":"licensing/eval_license/#14-contact","title":"14. Contact","text":"<p>Vendor contact for evaluation questions: <code>CONTACT_EMAIL</code></p>"},{"location":"licensing/order_form/","title":"Order Form (Template) \u2014 RecSys Commercial License","text":"<p>Order Form ID: <code>OF-YYYY-NNN</code> Effective Date: <code>YYYY-MM-DD</code> Vendor: <code>VENDOR_LEGAL_NAME</code> (\"Vendor\") Customer: <code>CUSTOMER_LEGAL_NAME</code> (\"Customer\")</p> <p>This Order Form is governed by and incorporates the Commercial License Agreement (RecSys) v<code>version</code> (\"Agreement\"). Capitalized terms not defined here have the meaning given in the Agreement.</p>"},{"location":"licensing/order_form/#1-products-and-fees","title":"1. Products and Fees","text":""},{"location":"licensing/order_form/#11-product","title":"1.1 Product","text":"<ul> <li>Product: RecSys Commercial License</li> <li>Plan: \u2610 Starter \u2610 Growth \u2610 Enterprise (custom)</li> </ul>"},{"location":"licensing/order_form/#12-term","title":"1.2 Term","text":"<ul> <li>Start date: <code>YYYY-MM-DD</code></li> <li>End date: <code>YYYY-MM-DD</code></li> <li>Renewal: \u2610 Annual renewal \u2610 Non-renewing (evaluation/custom)</li> </ul>"},{"location":"licensing/order_form/#13-fees-excl-vat","title":"1.3 Fees (excl. VAT)","text":"<ul> <li>License fee: \u20ac <code>AMOUNT</code></li> <li>Support fee (if any): \u20ac <code>AMOUNT</code></li> <li>Total: \u20ac <code>AMOUNT</code></li> <li>Payment terms: <code>e.g., Net 14 / Net 30</code></li> <li>Billing method: \u2610 Invoice \u2610 Payment link/credit card \u2610 Other: <code>...</code></li> </ul>"},{"location":"licensing/order_form/#14-taxes","title":"1.4 Taxes","text":"<p>Customer is responsible for applicable VAT/sales taxes unless a valid exemption applies. Customer VAT ID: <code>VAT_ID</code></p>"},{"location":"licensing/order_form/#2-authorized-scope-entitlements","title":"2. Authorized Scope (Entitlements)","text":""},{"location":"licensing/order_form/#21-tenants","title":"2.1 Tenants","text":"<ul> <li>Authorized Tenants: <code>N</code></li> </ul>"},{"location":"licensing/order_form/#22-production-deployments","title":"2.2 Production Deployments","text":"<ul> <li>Authorized Production Deployments: <code>N</code></li> </ul>"},{"location":"licensing/order_form/#23-non-production-environments","title":"2.3 Non-Production Environments","text":"<p>Included at no extra charge:</p> <ul> <li>Up to 2 non-prod environments per Production Deployment (dev/staging/sandbox)</li> </ul>"},{"location":"licensing/order_form/#24-regions-affiliates-if-applicable","title":"2.4 Regions / Affiliates (if applicable)","text":"<ul> <li>Regions allowed: <code>e.g., EU / global</code></li> <li>Affiliates allowed: \u2610 Yes \u2610 No (details if yes): <code>...</code></li> </ul>"},{"location":"licensing/order_form/#25-oem-resale-third-party-hosting","title":"2.5 OEM / Resale / Third-Party Hosting","text":"<ul> <li>OEM/resale: \u2610 Not allowed \u2610 Allowed (details): <code>...</code></li> <li>Third-party hosting: \u2610 Not allowed \u2610 Allowed (details): <code>...</code></li> </ul>"},{"location":"licensing/order_form/#3-support-if-purchased","title":"3. Support (If Purchased)","text":"<p>Support tier: \u2610 None \u2610 Best effort async \u2610 8x5 SLA \u2610 24x7 SLA Support channel(s): <code>email/ticket portal</code> Response targets (if applicable): <code>e.g., P1 4h, P2 1bd, ...</code> Exclusions/limits: <code>optional</code></p>"},{"location":"licensing/order_form/#4-delivery-and-access","title":"4. Delivery and Access","text":"<ul> <li>Delivery method: \u2610 Private container registry \u2610 Download link \u2610 Other</li> <li>Registry/URL: <code>REGISTRY_URL or DOWNLOAD_URL</code></li> <li>Credential delivery: <code>how credentials are provided</code></li> <li>License file delivery: <code>signed license.json/JWT, delivered via email/portal</code></li> </ul>"},{"location":"licensing/order_form/#5-special-terms-optional","title":"5. Special Terms (Optional)","text":"<p><code>Any negotiated terms, e.g., security addendum, DPA reference, custom liability cap, etc.</code></p>"},{"location":"licensing/order_form/#6-signatures","title":"6. Signatures","text":"<p>Vendor: ___  Date: _ Name/Title: ______</p> <p>Customer: ____  Date: _ Name/Title: ___</p>"},{"location":"licensing/pricing/","title":"Pricing (Commercial License)","text":"<p>This repository includes open-source components (e.g., Apache-2.0 and AGPLv3). A commercial license is available for organizations that want commercial terms and/or prefer not to adopt AGPL obligations for production use.</p> <p>All prices below are EUR, excl. VAT.</p>"},{"location":"licensing/pricing/#quick-definitions","title":"Quick definitions","text":"<ul> <li>Tenant: A logically separate recommendation domain with its own catalog and behavior signals (e.g., brand, product   line, customer partition).</li> <li>Production deployment: One production environment serving real end-user traffic (e.g., a Kubernetes cluster/namespace   or a distinct production installation).</li> <li>Non-production environments: Up to 2 non-prod environments (dev/staging) per production deployment are included   at no extra charge.</li> </ul> <p>If your use case involves OEM/resale, multi-region HA across many clusters, or unusually large scale, use Enterprise.</p>"},{"location":"licensing/pricing/#plans","title":"Plans","text":""},{"location":"licensing/pricing/#commercial-evaluation","title":"Commercial Evaluation","text":"<p>Price: \u20ac490 (one-time, 30 days)</p> <p>For teams who want to evaluate under commercial terms and/or use signed commercial artifacts.</p> <p>Includes:</p> <ul> <li>Commercial evaluation license grant (time-boxed)</li> <li>Access to signed commercial artifacts (private registry)</li> <li>Scope: 1 tenant, 1 deployment (non-prod allowed)</li> </ul> <p>Notes:</p> <ul> <li>Evaluation is for internal testing only (no resale/OEM).</li> <li>See <code>docs/licensing/eval_license.md</code> for the exact evaluation terms.</li> </ul>"},{"location":"licensing/pricing/#starter","title":"Starter","text":"<p>Price: \u20ac9,900 / year</p> <p>Scope:</p> <ul> <li>1 tenant</li> <li>1 production deployment</li> <li>Includes up to 2 non-prod environments</li> </ul> <p>Includes:</p> <ul> <li>Commercial license grant for the commercial-licensed components (as described in <code>COMMERCIAL.md</code>)</li> <li>Access to signed commercial artifacts (private registry)</li> <li>Updates during the license term</li> <li>Async support channel (best effort)</li> </ul>"},{"location":"licensing/pricing/#growth","title":"Growth","text":"<p>Price: \u20ac24,900 / year</p> <p>Scope:</p> <ul> <li>Up to 3 tenants and/or up to 3 production deployments</li> <li>Includes up to 2 non-prod environments per production deployment</li> </ul> <p>Includes:</p> <ul> <li>Everything in Starter</li> <li>Faster async response target (typically within 2 business days)</li> </ul>"},{"location":"licensing/pricing/#enterprise","title":"Enterprise","text":"<p>Price: From \u20ac60,000 / year</p> <p>For:</p> <ul> <li>Many tenants/deployments, multi-region HA, OEM/resale, custom legal/security requirements, or regulated environments.</li> </ul> <p>Includes:</p> <ul> <li>Custom scope and terms</li> <li>Optional premium support / security commitments</li> <li>Optional fixed-scope professional services (explicitly scoped)</li> </ul>"},{"location":"licensing/pricing/#optional-add-ons-available-for-growthenterprise","title":"Optional add-ons (available for Growth/Enterprise)","text":"<ul> <li>Premium support / SLA (8\u00d75 or 24\u00d77)</li> <li>Security review package (SBOM/provenance guidance, hardening checklist)</li> <li>Fixed-scope onboarding (time-boxed)</li> </ul>"},{"location":"licensing/pricing/#what-you-get-when-you-buy","title":"What you get when you buy","text":"<ul> <li>A signed license file (offline verifiable), or equivalent commercial entitlement artifact</li> <li>Credentials to pull signed commercial images from the private registry</li> <li>Instructions to run the \"Commercial lane\" of the evaluation pack (if applicable)</li> </ul>"},{"location":"licensing/pricing/#payment-renewal","title":"Payment &amp; renewal","text":"<ul> <li>Annual plans are billed annually in advance unless otherwise agreed.</li> <li>Renewals are annual. Upgrades are typically prorated.</li> <li>Taxes: VAT may apply depending on your location and VAT ID status.</li> </ul>"},{"location":"licensing/pricing/#how-to-buy","title":"How to buy","text":"<p>Use the payment links (recommended for fastest fulfillment) or contact us for Enterprise terms.</p> <ul> <li>Commercial Evaluation (30 days)</li> <li>Starter (annual)</li> <li>Growth (annual)</li> <li>Enterprise (contact)</li> </ul> <p>Contact: <code>contact@recsys.app</code></p>"},{"location":"licensing/pricing/#contact","title":"Contact","text":"<p>If you need Enterprise terms, OEM/resale rights, or help selecting the right plan, contact: <code>contact@recsys.app</code></p>"},{"location":"operations/performance-and-capacity/","title":"Performance and capacity guide","text":"<p>This guide describes how to run reproducible load tests against recsys-service and capture sizing data for production planning.</p>"},{"location":"operations/performance-and-capacity/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Lead developers and SREs sizing <code>recsys-service</code> for production</li> <li>Engineers running load tests before enabling new signals or data modes</li> </ul>"},{"location":"operations/performance-and-capacity/#what-you-will-get","title":"What you will get","text":"<ul> <li>A runnable load-test harness</li> <li>The parameters that matter for repeatability</li> <li>A table format for recording sizing data over time</li> </ul>"},{"location":"operations/performance-and-capacity/#1-preflight-checklist","title":"1) Preflight checklist","text":"<ul> <li>Postgres is seeded with a tenant, config, and signal data.</li> <li>recsys-service is healthy (<code>/healthz</code> returns 200).</li> <li>Auth headers are configured (dev headers or a bearer token).</li> </ul>"},{"location":"operations/performance-and-capacity/#2-run-the-load-test","title":"2) Run the load test","text":"<p>Use the built-in harness:</p> <pre><code>./scripts/loadtest.sh\n</code></pre> <p>Key parameters (env vars):</p> <ul> <li><code>BASE_URL</code> (default: http://localhost:8000)</li> <li><code>ENDPOINT</code> (default: /v1/recommend; set /v1/similar for similar-items)</li> <li><code>TENANT_ID</code>, <code>SURFACE</code>, <code>K</code></li> <li><code>REQUESTS</code>, <code>CONCURRENCY</code></li> <li><code>DEV_HEADERS=true</code> (local) or set <code>BEARER_TOKEN</code> / <code>API_KEY</code></li> </ul> <p>Example:</p> <pre><code>BASE_URL=http://localhost:8000 \\\nENDPOINT=/v1/recommend \\\nTENANT_ID=demo \\\nSURFACE=home \\\nREQUESTS=1000 \\\nCONCURRENCY=25 \\\n./scripts/loadtest.sh\n</code></pre> <p>Capture:</p> <ul> <li><code>rps</code> (requests/sec)</li> <li>p50/p95/p99 latency</li> <li>error rate (non-2xx + timeouts)</li> </ul>"},{"location":"operations/performance-and-capacity/#3-record-sizing-data","title":"3) Record sizing data","text":"<p>Use this table as a living record. Fill with measured results from your environment (hardware, cache settings, dataset size).</p> Tier Target QPS p95 Latency CPU Memory Notes dev local, seeded data small single tenant med multi-tenant large dedicated cache"},{"location":"operations/performance-and-capacity/#4-tuning-levers","title":"4) Tuning levers","text":"<ul> <li>Cache TTLs: <code>RECSYS_CONFIG_CACHE_TTL</code>, <code>RECSYS_RULES_CACHE_TTL</code></li> <li>Backpressure: <code>RECSYS_BACKPRESSURE_MAX_INFLIGHT</code>, <code>RECSYS_BACKPRESSURE_MAX_QUEUE</code></li> <li>Algorithm mode: <code>RECSYS_ALGO_MODE</code> (<code>blend</code>, <code>popularity</code>, <code>cooc</code>, etc.)</li> <li>Artifact mode: <code>RECSYS_ARTIFACT_MODE_ENABLED</code> (affects S3/manifest latency)</li> </ul>"},{"location":"operations/performance-and-capacity/#5-repeat-after-changes","title":"5) Repeat after changes","text":"<p>Re-run the load test after:</p> <ul> <li>schema changes (new signals)</li> <li>algorithm changes</li> <li>cache or artifact mode changes</li> <li>infrastructure changes</li> </ul>"},{"location":"operations/performance-and-capacity/#read-next","title":"Read next","text":"<ul> <li>Production readiness checklist: <code>operations/production-readiness-checklist.md</code></li> <li>Backpressure and limits: <code>reference/config/recsys-service.md</code></li> </ul>"},{"location":"operations/production-readiness-checklist/","title":"Production readiness checklist (RecSys suite)","text":""},{"location":"operations/production-readiness-checklist/#who-this-is-for","title":"Who this is for","text":"<p>Lead developers, platform/SRE, and security reviewers preparing to run <code>recsys-service</code> in production.</p>"},{"location":"operations/production-readiness-checklist/#what-you-will-get","title":"What you will get","text":"<p>A practical checklist to catch the most common \u201cwe went live and it broke\u201d gaps: auth/tenancy, data modes, privacy, observability, runbooks, backups, and safe rollout/rollback.</p>"},{"location":"operations/production-readiness-checklist/#0-decide-your-serving-mode-db-only-vs-artifactmanifest","title":"0) Decide your serving mode (DB-only vs artifact/manifest)","text":"<ul> <li>[ ] Pick a serving mode per tenant/environment:</li> <li>[ ] DB-only mode (fastest pilot; signals live in Postgres)</li> <li>[ ] Artifact/manifest mode (production-like; pipelines publish artifacts + manifest)</li> <li>[ ] Read: Data modes</li> <li>[ ] Document the choice for your deployment (values/env + runbooks).</li> </ul>"},{"location":"operations/production-readiness-checklist/#1-tenancy-and-authentication","title":"1) Tenancy and authentication","text":"<ul> <li>[ ] Decide the production auth mechanism:</li> <li>[ ] JWT (recommended for production)</li> <li>[ ] API keys (for server-to-server integrations)</li> <li>[ ] Ensure dev headers are disabled in production (<code>DEV_AUTH_ENABLED=false</code>).</li> <li>[ ] If using JWT:</li> <li>[ ] Configure <code>JWT_JWKS_URL</code>, <code>JWT_ISSUER</code>, <code>JWT_AUDIENCE</code></li> <li>[ ] Configure <code>AUTH_JWKS_ALLOWED_HOSTS</code> (and keep <code>AUTH_ALLOW_INSECURE_JWKS=false</code>)</li> <li>[ ] Confirm readiness check passes from the cluster network (<code>/readyz</code>)</li> <li>[ ] If using API keys:</li> <li>[ ] Set <code>API_KEY_ENABLED=true</code>, store <code>API_KEY_HASH_SECRET</code> securely</li> <li>[ ] Rotate keys and document the process</li> <li>[ ] Decide and document tenancy source:</li> <li>[ ] tenant claim(s) in JWT (<code>AUTH_TENANT_CLAIMS</code>) and/or header (<code>TENANT_HEADER_NAME</code>)</li> <li>[ ] Validate RBAC rules for admin endpoints:</li> <li>[ ] <code>AUTH_VIEWER_ROLE</code>, <code>AUTH_OPERATOR_ROLE</code>, <code>AUTH_ADMIN_ROLE</code></li> </ul> <p>See: Admin API + local bootstrap</p>"},{"location":"operations/production-readiness-checklist/#2-data-contracts-logging-and-privacy","title":"2) Data contracts, logging, and privacy","text":"<ul> <li>[ ] Decide what identifiers are allowed (user_id / anonymous_id / session_id).</li> <li>[ ] Confirm exposure/outcome logging design:</li> <li>[ ] Required IDs + correlation strategy (request_id, item_id, subject id)</li> <li>[ ] Retention policy and access control</li> <li>[ ] If using exposure hashing, set and rotate <code>EXPOSURE_HASH_SALT</code> as a secret.</li> <li>[ ] Document your PII stance (what fields are considered PII in your org).</li> </ul> <p>See:</p> <ul> <li>Exposure logging &amp; attribution</li> <li>Eval events</li> </ul>"},{"location":"operations/production-readiness-checklist/#3-pipelines-readiness-artifactmanifest-mode-only","title":"3) Pipelines readiness (artifact/manifest mode only)","text":"<ul> <li>[ ] Confirm artifact publishing is automated (scheduler) and has an owner/on-call.</li> <li>[ ] Confirm you can roll back the manifest safely.</li> <li>[ ] Define freshness SLOs and alerting.</li> </ul> <p>See:</p> <ul> <li>SLOs and freshness (pipelines)</li> <li>Roll back the manifest</li> </ul>"},{"location":"operations/production-readiness-checklist/#4-database-and-migrations","title":"4) Database and migrations","text":"<ul> <li>[ ] Ensure Postgres is provisioned with backups and a tested restore procedure.</li> <li>[ ] Confirm migrations are applied safely:</li> <li>[ ] preflight checks in CI</li> <li>[ ] an explicit migration job in production (not \u201chope MIGRATE_ON_START is fine\u201d)</li> <li>[ ] Document your rollback strategy for schema changes.</li> </ul> <p>See: Database migrations</p>"},{"location":"operations/production-readiness-checklist/#5-observability-and-runbooks","title":"5) Observability and runbooks","text":"<ul> <li>[ ] Liveness/readiness probes are wired:</li> <li>[ ] <code>/healthz</code> (liveness)</li> <li>[ ] <code>/readyz</code> (readiness)</li> <li>[ ] <code>/health/detailed</code> (debugging)</li> <li>[ ] Metrics are scraped and dashboards exist for:</li> <li>[ ] request rate, error rate, latency (p50/p95/p99)</li> <li>[ ] empty-recs rate</li> <li>[ ] cache hit/miss (if enabled)</li> <li>[ ] Tracing/logging is configured per your standards (and does not leak secrets).</li> <li>[ ] Runbooks exist and have been exercised at least once:</li> <li>[ ] Service not ready</li> <li>[ ] Empty recs</li> <li>[ ] Roll back config/rules</li> </ul>"},{"location":"operations/production-readiness-checklist/#6-performance-and-capacity","title":"6) Performance and capacity","text":"<ul> <li>[ ] Run a load test against production-like data and record results.</li> <li>[ ] Configure caching and backpressure based on observed behavior:</li> <li>[ ] <code>RECSYS_CONFIG_CACHE_TTL</code>, <code>RECSYS_RULES_CACHE_TTL</code></li> <li>[ ] <code>RECSYS_BACKPRESSURE_MAX_INFLIGHT</code>, <code>RECSYS_BACKPRESSURE_MAX_QUEUE</code></li> <li>[ ] Decide if and how you will enable profiling endpoints (keep <code>PPROF_ENABLED=false</code> by default).</li> </ul> <p>See: Performance and capacity</p>"},{"location":"operations/production-readiness-checklist/#7-safe-rollout-and-rollback","title":"7) Safe rollout and rollback","text":"<ul> <li>[ ] Define \u201cship\u201d and \u201crollback\u201d procedures for:</li> <li>[ ] config and rules (admin API, audit log)</li> <li>[ ] artifact manifests (pipelines)</li> <li>[ ] algorithm version changes (deployments)</li> <li>[ ] Confirm you can answer: \u201cWhich config/rules/algo version served this request?\u201d</li> <li>[ ] <code>meta.config_version</code>, <code>meta.rules_version</code>, <code>meta.algo_version</code> in responses</li> <li>[ ] Document gates and criteria for shipping.</li> </ul> <p>See: Run eval and ship</p>"},{"location":"operations/runbooks/db-migration-issues/","title":"Runbook: Database migration issues","text":""},{"location":"operations/runbooks/db-migration-issues/#symptoms","title":"Symptoms","text":"<ul> <li>Service crashes or fails to start during deploy/upgrade</li> <li>Requests fail with schema errors (missing table/column, constraint mismatch)</li> <li>Migration job exits non-zero or reports failed migrations</li> </ul>"},{"location":"operations/runbooks/db-migration-issues/#decision-tree-fast-path","title":"Decision tree (fast path)","text":"<p><code>mermaid flowchart TD   A[Upgrade failing] --&gt; B{DB reachable?}   B --&gt;|No| C[Fix connectivity/creds/network policy]   B --&gt;|Yes| D{Failed migrations present?}   D --&gt;|Yes| E[Investigate the failed migration and roll forward]   D --&gt;|No| F{Migrations behind the code?}   F --&gt;|Yes| G[Apply migrations (up)]   F --&gt;|No| H[Check app logs for non-migration causes]</code></p>"},{"location":"operations/runbooks/db-migration-issues/#quick-triage-copypaste","title":"Quick triage (copy/paste)","text":"<p>Local dev:</p> <pre><code>cd api\nmake migrate-preflight\nmake migrate-status\n</code></pre> <p>Production:</p> <ul> <li>Run your migration job/container and capture output.</li> <li>If you have DB access, run the same migrate commands in a controlled job environment.</li> </ul>"},{"location":"operations/runbooks/db-migration-issues/#safe-remediations","title":"Safe remediations","text":"<ul> <li>Prefer roll forward:</li> <li>fix the migration and deploy a new migration</li> <li>re-run <code>up</code></li> <li>Avoid <code>down</code> in production unless you have an explicit rollback plan and DB backups.</li> </ul> <p>See the migration policy and commands: <code>reference/database/migrations.md</code></p>"},{"location":"operations/runbooks/db-migration-issues/#verification","title":"Verification","text":"<ul> <li><code>migrate status</code> shows no failed migrations.</li> <li>Service starts cleanly and <code>/readyz</code> becomes <code>200 OK</code>.</li> </ul>"},{"location":"operations/runbooks/db-migration-issues/#read-next","title":"Read next","text":"<ul> <li>Service readiness runbook: <code>operations/runbooks/service-not-ready.md</code></li> <li>Migrations reference: <code>reference/database/migrations.md</code></li> </ul>"},{"location":"operations/runbooks/empty-recs/","title":"Runbook: Empty recs","text":""},{"location":"operations/runbooks/empty-recs/#symptoms","title":"Symptoms","text":"<ul> <li><code>POST /v1/recommend</code> returns <code>200 OK</code> but <code>items</code> is empty (<code>[]</code>)</li> <li>The issue is tenant/surface specific (some tenants/surfaces work, others don\u2019t)</li> </ul>"},{"location":"operations/runbooks/empty-recs/#decision-tree-fast-path","title":"Decision tree (fast path)","text":"<p>```mermaid flowchart TD   A[items[] is empty] --&gt; B{warnings[] explains why?}   B --&gt;|CANDIDATES_INCLUDE_EMPTY| C[Check candidates.include_ids / allow-lists]   B --&gt;|CONSTRAINTS_FILTERED| D[Relax constraints (tags, caps, price)]   B --&gt;|SIGNAL_UNAVAILABLE / SIGNAL_PARTIAL| E{Artifact mode enabled?}   B --&gt;|No warnings| F{config_version or rules_version empty?}</p> <p>F --&gt;|Yes| G[Bootstrap tenant config/rules + invalidate caches]   F --&gt;|No| E</p> <p>E --&gt;|Yes| H[Verify current manifest + artifact URIs are readable]   E --&gt;|No| I[Verify DB signals exist (item_popularity_daily, item_tags)] ```</p>"},{"location":"operations/runbooks/empty-recs/#quick-triage-copypaste","title":"Quick triage (copy/paste)","text":"<p>Set:</p> <pre><code>BASE_URL=${BASE_URL:-http://localhost:8000}\nTENANT_ID=demo\n</code></pre> <p>1) Validate the request shape (normalization + warnings):</p> <pre><code>curl -fsS \"$BASE_URL/v1/recommend/validate\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Org-Id: $TENANT_ID\" \\\n  -d '{\"surface\":\"home\",\"k\":10,\"user\":{\"user_id\":\"debug-user-1\"}}'\n</code></pre> <p>2) Call recommend and inspect <code>meta</code> + <code>warnings</code>:</p> <pre><code>curl -fsS \"$BASE_URL/v1/recommend\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Org-Id: $TENANT_ID\" \\\n  -d '{\"surface\":\"home\",\"k\":10,\"user\":{\"user_id\":\"debug-user-1\"}}'\n</code></pre> <p>If your environment requires auth headers, see Admin API + local bootstrap.</p>"},{"location":"operations/runbooks/empty-recs/#what-to-look-for-in-the-response","title":"What to look for in the response","text":""},{"location":"operations/runbooks/empty-recs/#1-metaconfig_version-and-metarules_version","title":"1) <code>meta.config_version</code> and <code>meta.rules_version</code>","text":"<p>If either is empty, the tenant may be missing config/rules.</p> <ul> <li>Confirm with:</li> <li><code>GET /v1/admin/tenants/{tenant_id}/config</code></li> <li><code>GET /v1/admin/tenants/{tenant_id}/rules</code></li> </ul> <p>If config/rules were just updated, invalidate caches:</p> <ul> <li><code>POST /v1/admin/tenants/{tenant_id}/cache/invalidate</code> with <code>{\"targets\":[\"config\",\"rules\"]}</code>.</li> </ul>"},{"location":"operations/runbooks/empty-recs/#2-warnings","title":"2) <code>warnings[]</code>","text":"<p>Common warning codes that explain \u201cempty recs\u201d:</p> <ul> <li><code>CANDIDATES_INCLUDE_EMPTY</code>: <code>candidates.include_ids</code> filtered everything out</li> <li><code>CONSTRAINTS_FILTERED</code>: tag constraints filtered most/all results</li> <li><code>SIGNAL_UNAVAILABLE</code> / <code>SIGNAL_PARTIAL</code>: one or more signals are missing or incomplete</li> </ul>"},{"location":"operations/runbooks/empty-recs/#likely-causes-and-checks","title":"Likely causes (and checks)","text":""},{"location":"operations/runbooks/empty-recs/#a-no-popularity-signal-available-most-common","title":"A) No popularity signal available (most common)","text":"<p>DB-only mode:</p> <ul> <li>Verify <code>item_popularity_daily</code> has rows for your tenant and surface (namespace):</li> </ul> <pre><code>select count(*) from item_popularity_daily\nwhere tenant_id = (select id from tenants where external_id = 'demo')\n  and namespace = 'home';\n</code></pre> <p>Artifact/manifest mode (<code>RECSYS_ARTIFACT_MODE_ENABLED=true</code>):</p> <ul> <li>Verify the manifest exists and points to readable artifacts for the tenant/surface.</li> <li>If artifacts were just published, invalidate caches:</li> <li><code>POST /v1/admin/tenants/{tenant_id}/cache/invalidate</code> with <code>{\"targets\":[\"popularity\"]}</code>.</li> </ul> <p>See Data modes for how DB-only vs artifact mode works.</p>"},{"location":"operations/runbooks/empty-recs/#b-constraints-or-allow-lists-filtered-everything","title":"B) Constraints or allow-lists filtered everything","text":"<p>Checks:</p> <ul> <li>If you set <code>constraints.required_tags</code>, make sure items actually carry those tags.</li> <li>If you set <code>constraints.forbidden_tags</code> or <code>constraints.max_per_tag</code>, relax them temporarily.</li> <li>If you set <code>candidates.include_ids</code>, confirm those item IDs exist in your catalog/signals.</li> </ul> <p>DB-only mode tag lookup depends on <code>item_tags</code>:</p> <ul> <li>Confirm the items you expect are tagged under the same <code>namespace</code> (surface).</li> </ul>"},{"location":"operations/runbooks/empty-recs/#c-rules-blocked-everything","title":"C) Rules blocked everything","text":"<p>Checks:</p> <ul> <li><code>GET /v1/admin/tenants/{tenant_id}/rules</code> and look for high-priority <code>block</code> rules.</li> <li>Verify the response <code>meta.rules_version</code> matches what you think is active.</li> </ul> <p>Safe remediation:</p> <ul> <li>Roll back rules to a last-known-good version (see Runbook: Roll back config/rules).</li> </ul>"},{"location":"operations/runbooks/empty-recs/#if-you-need-a-fast-is-the-system-alive-sanity-check","title":"If you need a fast \u201cis the system alive?\u201d sanity check","text":"<p>Temporarily remove constraints/allow-lists and request a small <code>k</code>:</p> <pre><code>curl -fsS \"$BASE_URL/v1/recommend\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Org-Id: $TENANT_ID\" \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"debug-user-1\"},\"constraints\":null,\"candidates\":null}'\n</code></pre>"},{"location":"operations/runbooks/rollback-config-rules/","title":"Runbook: Roll back config/rules","text":"<p>This runbook covers rolling back tenant config and rules in <code>recsys-service</code>.</p> <p>If you need to roll back the artifact manifest (artifact mode), see: Roll back the manifest.</p>"},{"location":"operations/runbooks/rollback-config-rules/#symptoms","title":"Symptoms","text":"<ul> <li>A recent config/rules change caused empty recs, regressions, or elevated errors</li> <li>You need to revert a tenant to the last-known-good behavior quickly</li> </ul>"},{"location":"operations/runbooks/rollback-config-rules/#what-version-means-here","title":"What \u201cversion\u201d means here","text":"<p><code>config_version</code> and <code>rules_version</code> are ETags derived from the JSON payload (SHA-256 of the document). Rolling back to an earlier document means setting the current pointer back to that exact JSON payload.</p>"},{"location":"operations/runbooks/rollback-config-rules/#preferred-rollback-path-audited-api-only","title":"Preferred rollback path (audited, API-only)","text":"<p>This path is safe and leaves an audit trail.</p>"},{"location":"operations/runbooks/rollback-config-rules/#1-capture-the-current-state","title":"1) Capture the current state","text":"<ul> <li><code>GET /v1/admin/tenants/{tenant_id}/config</code> \u2192 record <code>config_version</code> (and <code>ETag</code> header)</li> <li><code>GET /v1/admin/tenants/{tenant_id}/rules</code> \u2192 record <code>rules_version</code> (and <code>ETag</code> header)</li> </ul> <p>Also capture a failing <code>POST /v1/recommend</code> response <code>meta</code> for the incident record.</p>"},{"location":"operations/runbooks/rollback-config-rules/#2-find-the-last-known-good-payload-audit-log","title":"2) Find the last-known-good payload (Audit Log)","text":"<p>Use:</p> <ul> <li><code>GET /v1/admin/tenants/{tenant_id}/audit?limit=50</code></li> </ul> <p>Look for:</p> <ul> <li><code>action=config.update</code> (config changes)</li> <li><code>action=rules.update</code> (rules changes)</li> </ul> <p>For the entry you want to revert, copy the JSON from:</p> <ul> <li><code>before_state</code> (the previous payload)</li> </ul>"},{"location":"operations/runbooks/rollback-config-rules/#3-re-apply-the-previous-payload","title":"3) Re-apply the previous payload","text":"<p>PUT the previous payload back:</p> <ul> <li><code>PUT /v1/admin/tenants/{tenant_id}/config</code> with body = <code>before_state</code></li> <li><code>PUT /v1/admin/tenants/{tenant_id}/rules</code> with body = <code>before_state</code></li> </ul> <p>Use <code>If-Match</code> (recommended) to avoid overwriting a concurrent update:</p> <ul> <li><code>If-Match: &lt;current config_version&gt;</code> / <code>If-Match: &lt;current rules_version&gt;</code></li> </ul> <p>If you get <code>409 RECSYS_VERSION_MISMATCH</code>, re-run step (1) and try again.</p>"},{"location":"operations/runbooks/rollback-config-rules/#4-invalidate-caches","title":"4) Invalidate caches","text":"<ul> <li><code>POST /v1/admin/tenants/{tenant_id}/cache/invalidate</code> with:</li> </ul> <pre><code>{ \"targets\": [\"config\", \"rules\", \"popularity\"] }\n</code></pre> <p>Notes:</p> <ul> <li><code>popularity</code> is relevant in artifact/manifest mode (no-op in DB-only mode).</li> </ul>"},{"location":"operations/runbooks/rollback-config-rules/#5-verify","title":"5) Verify","text":"<p>1) Call <code>POST /v1/recommend</code> and confirm <code>meta.config_version</code> and    <code>meta.rules_version</code> match the expected rolled-back versions. 2) Watch key metrics (error rate, latency, empty-recs rate) for recovery.</p>"},{"location":"operations/runbooks/rollback-config-rules/#break-glass-rollback-direct-db-pointer-update","title":"Break-glass rollback (direct DB pointer update)","text":"<p>Only use this if the admin API is unavailable and you have DBA-level access.</p> <p>Warning</p> <p>Direct DB changes can cause outages. Prefer the audited API rollback path above.</p> <p>High-level steps:</p> <p>1) Identify the tenant UUID:</p> <pre><code>select id from tenants where external_id = 'demo';\n</code></pre> <p>2) Pick the target version IDs (for example, the most recent two versions):</p> <pre><code>select id, etag, created_at\n  from tenant_config_versions\n where tenant_id = :tenant_uuid\n order by created_at desc\n limit 5;\n</code></pre> <p>3) Update the current pointer in a transaction:</p> <pre><code>begin;\nupdate tenant_configs_current\n   set config_version_id = :target_config_version_id,\n       updated_by_sub = 'break-glass',\n       updated_at = now()\n where tenant_id = :tenant_uuid;\ncommit;\n</code></pre> <p>Repeat the same pattern for <code>tenant_rules_current</code>.</p>"},{"location":"operations/runbooks/service-not-ready/","title":"Runbook: Service not ready","text":""},{"location":"operations/runbooks/service-not-ready/#symptoms","title":"Symptoms","text":"<ul> <li><code>/readyz</code> returns <code>503 Service Unavailable</code></li> <li>Kubernetes marks the pod <code>Ready=False</code> (readiness probe failing)</li> <li><code>/healthz</code> may still return <code>200 OK</code> (process is running but not ready)</li> </ul>"},{"location":"operations/runbooks/service-not-ready/#quick-triage-copypaste","title":"Quick triage (copy/paste)","text":"<p>Set:</p> <pre><code>BASE_URL=${BASE_URL:-http://localhost:8000}\n</code></pre> <p>Then run:</p> <pre><code>curl -fsS \"$BASE_URL/healthz\"\ncurl -fsS \"$BASE_URL/readyz\" || true\ncurl -fsS \"$BASE_URL/health/detailed\"\n</code></pre> <p>Interpretation:</p> <ul> <li><code>healthz</code> failing means the process is not healthy (check container logs first).</li> <li><code>readyz</code> failing means at least one readiness dependency is unhealthy.</li> <li><code>health/detailed</code> tells you which check(s) are unhealthy and why.</li> </ul> <p>Warning</p> <p>When sharing <code>/health/detailed</code> output (tickets, Slack), redact secrets and internal hostnames.</p>"},{"location":"operations/runbooks/service-not-ready/#what-readiness-checks-exist","title":"What readiness checks exist","text":"<p>In <code>recsys-service</code>, readiness includes:</p> <ul> <li><code>basic</code> (always healthy)</li> <li><code>database</code> (Postgres ping) when <code>DATABASE_URL</code> is configured</li> <li>auth provider checks (for example: JWKS fetch) when JWT auth is enabled</li> </ul>"},{"location":"operations/runbooks/service-not-ready/#common-causes-and-safe-remediations","title":"Common causes and safe remediations","text":""},{"location":"operations/runbooks/service-not-ready/#check-database-is-unhealthy","title":"Check <code>database</code> is unhealthy","text":"<p>Likely causes:</p> <ul> <li>Postgres is down or not reachable from the service network</li> <li><code>DATABASE_URL</code> points to the wrong host/db or has invalid credentials</li> <li>network policy / DNS / TLS issues</li> </ul> <p>Checks:</p> <ul> <li>Local dev (docker compose): <code>cd api &amp;&amp; make migrate-status</code></li> <li>From a pod/container: run a simple query (for example <code>psql \"$DATABASE_URL\" -c 'select 1'</code>)</li> </ul> <p>Safe remediations:</p> <ul> <li>Fix connectivity/credentials (secret wiring, DNS, firewall, DB availability)</li> <li>Apply migrations if they are behind:</li> <li>Local dev: <code>cd api &amp;&amp; make migrate-up</code></li> <li>Production: run your migration job (see Database migrations)</li> <li>If migrations fail: see Runbook: Database migration issues</li> </ul>"},{"location":"operations/runbooks/service-not-ready/#authjwks-check-is-unhealthy-jwt-enabled","title":"Auth/JWKS check is unhealthy (JWT enabled)","text":"<p>Likely causes:</p> <ul> <li><code>JWT_JWKS_URL</code> is unreachable from the pod (egress/DNS)</li> <li>the JWKS host is not allowlisted (<code>AUTH_JWKS_ALLOWED_HOSTS</code>)</li> <li>TLS/certificate problems</li> </ul> <p>Checks:</p> <ul> <li>Verify configuration: <code>JWT_JWKS_URL</code>, <code>AUTH_JWKS_ALLOWED_HOSTS</code></li> <li>From the same network as the service, check reachability:</li> <li><code>curl -fsS \"$JWT_JWKS_URL\" &gt;/dev/null</code></li> </ul> <p>Safe remediations:</p> <ul> <li>Fix egress/DNS/TLS for the JWKS URL</li> <li>Update <code>AUTH_JWKS_ALLOWED_HOSTS</code> to match the JWKS hostname</li> </ul> <p>Warning</p> <p>Do not use insecure JWKS settings (<code>AUTH_ALLOW_INSECURE_JWKS=true</code>) in production.</p>"},{"location":"operations/runbooks/service-not-ready/#if-readyz-is-ok-but-traffic-still-fails","title":"If <code>/readyz</code> is OK but traffic still fails","text":"<p>Readiness only covers baseline dependencies. If <code>/readyz</code> is <code>200</code> but:</p> <ul> <li><code>/v1/recommend</code> returns empty \u2192 see Runbook: Empty recs</li> <li>you are in artifact/manifest mode and requests fail \u2192 verify <code>RECSYS_ARTIFACT_*</code> config and manifest publishing (see   Data modes)</li> </ul>"},{"location":"operations/runbooks/stale-manifest/","title":"Runbook: Stale manifest (artifact mode)","text":""},{"location":"operations/runbooks/stale-manifest/#symptoms","title":"Symptoms","text":"<ul> <li>Recommendations look stale even after pipelines published new artifacts</li> <li>The \u201ccurrent manifest\u201d <code>updated_at</code> is older than expected for a tenant/surface</li> <li><code>POST /v1/admin/tenants/{tenant_id}/cache/invalidate</code> with <code>popularity</code> fixes it temporarily</li> </ul>"},{"location":"operations/runbooks/stale-manifest/#decision-tree-fast-path","title":"Decision tree (fast path)","text":"<p><code>mermaid flowchart TD   A[Serving stale artifacts] --&gt; B{Artifact mode enabled?}   B --&gt;|No| C[DB-only mode: check DB signal freshness]   B --&gt;|Yes| D{Can you fetch the current manifest from object store?}   D --&gt;|No| E[Fix object store access (DNS/egress/creds/TLS)]   D --&gt;|Yes| F{Manifest updated recently?}   F --&gt;|No| G[Pipeline publish failed or scheduler not running]   F --&gt;|Yes| H{Service still stale after manifest TTL?}   H --&gt;|No| I[Wait for TTL expiry or invalidate caches]   H --&gt;|Yes| J[Invalidate caches; check service logs for fetch errors]</code></p>"},{"location":"operations/runbooks/stale-manifest/#quick-triage-copypaste","title":"Quick triage (copy/paste)","text":"<p>Set:</p> <pre><code>TENANT_ID=demo\nSURFACE=home\nBASE_URL=${BASE_URL:-http://localhost:8000}\n</code></pre> <ol> <li> <p>Confirm the service is in artifact mode:</p> </li> <li> <p><code>RECSYS_ARTIFACT_MODE_ENABLED=true</code> is required.</p> </li> <li> <p>If you\u2019re not sure, check the service config for <code>RECSYS_ARTIFACT_*</code> variables and object store settings.</p> </li> <li> <p>Fetch the current manifest from object storage.</p> </li> </ol> <p>The manifest location is defined by:</p> <ul> <li><code>RECSYS_ARTIFACT_MANIFEST_TEMPLATE</code> (default:   <code>s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json</code>)</li> </ul> <p>Example with AWS CLI:</p> <pre><code>aws s3 cp \"s3://recsys-artifacts/registry/current/${TENANT_ID}/${SURFACE}/manifest.json\" -\n</code></pre> <p>Local dev (MinIO via docker compose):</p> <pre><code>docker compose run --rm --entrypoint sh minio-init -c \\\n  \"mc alias set local http://minio:9000 minioadmin minioadmin &gt;/dev/null &amp;&amp; \\\n   mc cat local/recsys-artifacts/registry/current/${TENANT_ID}/${SURFACE}/manifest.json | head\"\n</code></pre> <ol> <li>If the manifest is new but service output is still old, invalidate caches:</li> </ol> <pre><code>curl -fsS -X POST \"$BASE_URL/v1/admin/tenants/${TENANT_ID}/cache/invalidate\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"X-Org-Id: $TENANT_ID\" \\\n  -d \"{\\\"targets\\\":[\\\"popularity\\\"],\\\"surface\\\":\\\"${SURFACE}\\\"}\"\n</code></pre>"},{"location":"operations/runbooks/stale-manifest/#likely-causes-and-safe-remediations","title":"Likely causes and safe remediations","text":"<ul> <li>Manifest pointer not updated</li> <li>Check pipeline scheduler health and recent pipeline runs.</li> <li>See pipelines runbook: <code>recsys-pipelines/docs/operations/runbooks/stale-artifacts.md</code></li> <li>TTLs are too long for your workflow</li> <li>Tune <code>RECSYS_ARTIFACT_MANIFEST_TTL</code> and <code>RECSYS_ARTIFACT_CACHE_TTL</code>.</li> <li>Object store connectivity problems</li> <li>Validate endpoint/creds (<code>RECSYS_ARTIFACT_S3_*</code>) from the service network.</li> </ul>"},{"location":"operations/runbooks/stale-manifest/#verification","title":"Verification","text":"<ul> <li>Fetch the current manifest again and confirm <code>updated_at</code> advanced.</li> <li>Call <code>/v1/recommend</code> twice (after TTL expiry or cache invalidation) and confirm outputs reflect the new artifacts.</li> </ul>"},{"location":"operations/runbooks/stale-manifest/#read-next","title":"Read next","text":"<ul> <li>Artifacts and manifest lifecycle: <code>explanation/artifacts-and-manifest-lifecycle.md</code></li> <li>Data modes: <code>explanation/data-modes.md</code></li> <li>Pipelines rollback guide: <code>recsys-pipelines/docs/how-to/rollback-manifest.md</code></li> </ul>"},{"location":"project/","title":"Project","text":"<ul> <li><code>Code of Conduct</code></li> <li><code>Contributing</code></li> <li><code>Governance</code></li> <li><code>License Directory Notes</code></li> <li><code>Security Policy</code></li> <li><code>Support</code></li> <li><code>Docs versioning</code></li> <li><code>Docs per release policy</code></li> </ul>"},{"location":"project/code_of_conduct/","title":"Code of Conduct","text":"<p>This project adopts the Contributor Covenant Code of Conduct.</p>"},{"location":"project/code_of_conduct/#our-pledge","title":"Our pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone.</p>"},{"location":"project/code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces and also applies when an individual is officially representing the community in public spaces.</p>"},{"location":"project/code_of_conduct/#enforcement","title":"Enforcement","text":"<p>To report incidents, contact: <code>conduct@recsys.app</code>.</p>"},{"location":"project/code_of_conduct/#full-text","title":"Full text","text":"<p>The full text of Contributor Covenant v2.1 is available at: Contributor Covenant v2.1.</p> <p>Attribution: Contributor Covenant v2.1.</p>"},{"location":"project/contributing/","title":"Contributing","text":"<p>Thanks for your interest in contributing!</p>"},{"location":"project/contributing/#contribution-scope","title":"Contribution scope","text":"<p>We welcome:</p> <ul> <li>Bug reports and reproducible issue reports</li> <li>Documentation improvements</li> <li>Tests and CI improvements</li> <li>Code contributions (see licensing note below)</li> </ul>"},{"location":"project/contributing/#licensing-of-contributions","title":"Licensing of contributions","text":"<p>By submitting a contribution, you agree that your contribution is licensed under the same license as the component you are contributing to (Apache-2.0 for <code>recsys-eval</code>, AGPLv3 for the serving stack), unless otherwise agreed in writing.</p>"},{"location":"project/contributing/#commercial-dual-licensing-note-important","title":"Commercial dual-licensing note (important)","text":"<p>If we accept code contributions into the AGPL-covered components and later want to include them in commercial distributions, we may require an additional contributor agreement for those specific contributions.</p> <p>To keep things simple, we may ask contributors to:</p> <ul> <li>contribute substantial feature code to <code>recsys-eval</code> (Apache-2.0), or</li> <li>contribute via issues/design proposals for AGPL components, or</li> <li>sign an additional agreement when necessary.</li> </ul>"},{"location":"project/contributing/#development-workflow","title":"Development workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Run tests and linters</li> <li>Open a pull request</li> </ol>"},{"location":"project/contributing/#commit-sign-off-dco","title":"Commit sign-off (DCO)","text":"<p>We use the Developer Certificate of Origin (DCO) sign-off on commits.</p> <p>Use: <code>git commit -s -m \"...\"</code></p> <p>Your commits should include a <code>Signed-off-by:</code> line.</p>"},{"location":"project/contributing/#style","title":"Style","text":"<ul> <li>Prefer small, focused PRs</li> <li>Add tests for bug fixes and new behavior</li> <li>Update docs when behavior changes</li> </ul>"},{"location":"project/docs-per-release/","title":"Docs per release policy","text":""},{"location":"project/docs-per-release/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Maintainers preparing a release</li> <li>Reviewers validating that a change is \u201ccustomer-ready\u201d</li> </ul>"},{"location":"project/docs-per-release/#what-you-will-get","title":"What you will get","text":"<ul> <li>A checklist that turns doc updates into a release habit (not an afterthought)</li> <li>Clear \u201cwhen X changes, update Y\u201d guidance for the suite docs site</li> </ul>"},{"location":"project/docs-per-release/#policy","title":"Policy","text":"<ul> <li>Doc changes ship with product changes.</li> <li>The canonical API spec lives in <code>reference/api/openapi.yaml</code>.</li> <li>Tutorials must remain runnable (see the tutorial smoke test workflow).</li> </ul>"},{"location":"project/docs-per-release/#checklists-by-change-type","title":"Checklists (by change type)","text":""},{"location":"project/docs-per-release/#http-api-changes","title":"HTTP API changes","text":"<ul> <li>Update <code>docs/reference/api/openapi.yaml</code>.</li> <li>Regenerate derived API artifacts: <code>cd api &amp;&amp; make codegen</code>.</li> <li>Update examples and troubleshooting pages if behavior changed:</li> <li><code>reference/api/examples.md</code></li> <li><code>reference/api/errors.md</code></li> <li>Add an entry to \u201cWhat\u2019s new\u201d for customer-visible changes:</li> <li><code>whats-new/index.md</code></li> </ul>"},{"location":"project/docs-per-release/#config-changes","title":"Config changes","text":"<ul> <li>Update the config reference:</li> <li><code>reference/config/index.md</code></li> <li>module-specific pages under <code>reference/config/</code></li> <li>If a setting changes defaults or semantics, add a note to \u201cWhat\u2019s new\u201d.</li> </ul>"},{"location":"project/docs-per-release/#data-contract-changes-exposuresoutcomesmanifests","title":"Data contract changes (exposures/outcomes/manifests)","text":"<ul> <li>Update:</li> <li><code>reference/data-contracts/index.md</code></li> <li>schema files under <code>reference/data-contracts/</code> (and examples)</li> <li>Update join/explanation docs if attribution logic changes:</li> <li><code>reference/data-contracts/join-logic.md</code></li> <li><code>explanation/exposure-logging-and-attribution.md</code></li> </ul>"},{"location":"project/docs-per-release/#operational-behavior-changes","title":"Operational behavior changes","text":"<ul> <li>Update runbooks for new failure modes or changes in remediation:</li> <li><code>docs/operations/runbooks/*</code></li> <li>Update capacity guidance if perf characteristics changed:</li> <li><code>operations/performance-and-capacity.md</code></li> </ul>"},{"location":"project/docs-per-release/#verification-required","title":"Verification (required)","text":"<p>Run the suite-level quality gates:</p> <pre><code>make finalize\n</code></pre> <p>If you changed tutorials or serving behavior, also run the tutorial smoke test locally (or wait for CI):</p> <pre><code>bash scripts/tutorial_smoke_test.sh\n</code></pre>"},{"location":"project/docs-per-release/#read-next","title":"Read next","text":"<ul> <li>Docs versioning: <code>project/docs-versioning.md</code></li> </ul>"},{"location":"project/docs-style/","title":"Documentation style guide","text":"<p>This repository follows the Diataxis structure:</p> <ul> <li>Tutorials: learning by doing</li> <li>How-to: goal-oriented steps</li> <li>Explanation: understanding and design rationale</li> <li>Reference: precise specification (APIs, schemas, config)</li> </ul>"},{"location":"project/docs-style/#scope","title":"Scope","text":"<p>These rules apply to suite-level docs under <code>docs/</code> (the MkDocs site).</p> <p>Module docs may have their own style guides and can deviate when that improves clarity:</p> <ul> <li><code>docs/recsys-eval/docs/</code> (see <code>docs/recsys-eval/docs/style.md</code>)</li> <li><code>docs/recsys-pipelines/docs/</code> (see <code>docs/recsys-pipelines/docs/contributing/style.md</code>)</li> <li><code>docs/recsys-algo/</code></li> </ul>"},{"location":"project/docs-style/#writing-rules","title":"Writing rules","text":"<ul> <li>Prefer short sections and explicit headings.</li> <li>Use consistent terminology (see <code>glossary.md</code>).</li> <li>Use consistent product naming and capitalization (see \"Naming\" below).</li> <li>Always include:</li> <li>prerequisites</li> <li>expected outcomes</li> <li>examples and sample outputs (when applicable)</li> <li>Prefer relative links inside <code>/docs</code>.</li> <li>Avoid linking to repository paths that do not exist in the rendered MkDocs site.</li> </ul>"},{"location":"project/docs-style/#suite-level-page-templates","title":"Suite-level page templates","text":"<p>Use these templates for suite-level docs under <code>docs/</code> (as opposed to module docs that have their own style guides).</p>"},{"location":"project/docs-style/#tutorials","title":"Tutorials","text":"<ul> <li>Goal (what you will build/run)</li> <li>Who this is for</li> <li>What you will get</li> <li>Prereqs (tools + access)</li> <li>Steps (numbered, copy/paste)</li> <li>Verify (expected output shape)</li> <li>Troubleshooting (common failures)</li> <li>Read next (links)</li> </ul>"},{"location":"project/docs-style/#how-to-guides","title":"How-to guides","text":"<ul> <li>Who this is for (optional but recommended)</li> <li>Goal / outcomes (what you will achieve)</li> <li>Prereqs</li> <li>Steps</li> <li>Verify</li> <li>Pitfalls / gotchas</li> <li>Read next</li> </ul>"},{"location":"project/docs-style/#explanations","title":"Explanations","text":"<ul> <li>Who this is for</li> <li>What you will get</li> <li>Concepts and data flow (diagram if helpful)</li> <li>Failure modes and recovery notes</li> <li>Read next</li> </ul>"},{"location":"project/docs-style/#reference","title":"Reference","text":"<ul> <li>Who this is for</li> <li>What you will get</li> <li>Definitions / contracts / options (be precise)</li> <li>Examples (when it prevents ambiguity)</li> <li>Read next (optional)</li> </ul>"},{"location":"project/docs-style/#runbooks","title":"Runbooks","text":"<ul> <li>Symptoms</li> <li>Quick triage (commands + what to look for)</li> <li>Likely causes</li> <li>Safe remediations</li> <li>Verification</li> <li>Escalation criteria</li> </ul>"},{"location":"project/docs-style/#copypaste-templates","title":"Copy/paste templates","text":"<p>Use these skeletons for new suite-level pages. Keep headings consistent so readers can scan quickly.</p>"},{"location":"project/docs-style/#tutorial-skeleton","title":"Tutorial skeleton","text":"<pre><code># Title\n\n## Who this is for\n\n## What you will get\n\n## Prereqs\n\n## Steps\n\n## Verify\n\n## Troubleshooting\n\n## Read next\n</code></pre>"},{"location":"project/docs-style/#how-to-skeleton","title":"How-to skeleton","text":"<pre><code># How-to: Title\n\n## Who this is for\n\n## Goal\n\n## Prereqs\n\n## Steps\n\n## Verify\n\n## Pitfalls\n\n## Read next\n</code></pre>"},{"location":"project/docs-style/#explanation-skeleton","title":"Explanation skeleton","text":"<pre><code># Title\n\n## Who this is for\n\n## What you will get\n\n## Concepts and data flow\n\n## Failure modes and recovery\n\n## Read next\n</code></pre>"},{"location":"project/docs-style/#reference-skeleton","title":"Reference skeleton","text":"<pre><code># Title\n\n## Who this is for\n\n## What you will get\n\n## Reference\n\n## Examples\n\n## Read next\n</code></pre>"},{"location":"project/docs-style/#markdown-conventions","title":"Markdown conventions","text":"<ul> <li>Use fenced code blocks with language hints.</li> <li>Use admonitions for warnings and important notes.</li> <li>Keep line length readable (wrap long paragraphs).</li> </ul>"},{"location":"project/docs-style/#glossary-linking","title":"Glossary linking","text":"<ul> <li>Add new suite terms to <code>glossary.md</code> (so we don\u2019t define the same thing in five places).</li> <li>On first mention in a page, link glossary terms to the relevant entry (for example: <code>glossary.md#manifest</code>).</li> <li>Avoid over-linking: link once per page/section unless repetition prevents scanning.</li> </ul>"},{"location":"project/docs-style/#naming","title":"Naming","text":"<p>Use these names consistently across pages, nav labels, and headings:</p> <ul> <li>Product: RecSys suite (or RecSys when the context is unambiguous)</li> <li>Service/API module: <code>recsys-service</code></li> <li>Ranking core module: <code>recsys-algo</code></li> <li>Pipelines module: <code>recsys-pipelines</code></li> <li>Evaluation module: <code>recsys-eval</code></li> </ul> <p>Avoid mixed capitalization like \u201cRecsys\u201d in prose.</p>"},{"location":"project/docs-style/#api-docs-quality-checklist","title":"API docs quality checklist","text":"<p>Use this as a PR checklist when changing the HTTP API or its docs.</p> <ul> <li>OpenAPI stays canonical: update <code>docs/reference/api/openapi.yaml</code> and re-run <code>cd api &amp;&amp; make codegen</code>.</li> <li>Every changed endpoint has examples:</li> <li>at least one success example</li> <li>the common errors for that endpoint (e.g. 400/401/403/404/409/429)</li> <li>Errors are consistent: use Problem Details (RFC 7807) and document new problem types in   <code>reference/api/errors.md</code>.</li> <li>Auth expectations are explicit: what headers/claims are required (dev headers vs JWT).</li> <li>The \u201chappy path\u201d is copy/paste runnable: examples in <code>reference/api/examples.md</code>   match the schema and response shapes in OpenAPI.</li> </ul>"},{"location":"project/docs-versioning/","title":"Docs versioning","text":""},{"location":"project/docs-versioning/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Maintainers who publish releases</li> <li>Customers who need docs that match what they are running</li> </ul>"},{"location":"project/docs-versioning/#what-you-will-get","title":"What you will get","text":"<ul> <li>What \u201cdev\u201d and \u201clatest\u201d mean on the hosted site</li> <li>How to publish docs for a specific release tag</li> <li>How to preview older versions locally</li> </ul>"},{"location":"project/docs-versioning/#versioning-model","title":"Versioning model","text":"<p>This MkDocs site is versioned using <code>mike</code> (versions are stored on the <code>gh-pages</code> branch).</p> <p>Hosted paths:</p> <ul> <li><code>/dev/</code> = docs built from <code>master</code> (can change every merge)</li> <li><code>/latest/</code> = alias to the newest released version</li> <li><code>/vX.Y.Z/</code> = docs for a specific release tag</li> </ul>"},{"location":"project/docs-versioning/#release-tags","title":"Release tags","text":"<p>Docs versions are published from git tags.</p> <p>Recommended suite tag format:</p> <ul> <li><code>recsys-suite/vX.Y.Z</code> (SemVer)</li> </ul> <p>The Pages workflow strips the <code>recsys-suite/</code> prefix, so the version label becomes <code>vX.Y.Z</code>.</p>"},{"location":"project/docs-versioning/#publishing-a-new-version","title":"Publishing a new version","text":"<ol> <li>Create a tag:</li> </ol> <pre><code>git tag recsys-suite/v0.1.0\n</code></pre> <ol> <li>Push the tag:</li> </ol> <pre><code>git push origin recsys-suite/v0.1.0\n</code></pre> <ol> <li>GitHub Actions deploys:</li> <li><code>/v0.1.0/</code></li> <li>updates <code>/latest/</code> to point to <code>v0.1.0</code></li> </ol>"},{"location":"project/docs-versioning/#local-preview-optional","title":"Local preview (optional)","text":"<p>To preview multiple versions locally, install <code>mike</code> and serve the <code>gh-pages</code> branch:</p> <pre><code>python -m venv .venv\n. .venv/bin/activate\npython -m pip install mkdocs mkdocs-material mkdocs-swagger-ui-tag pymdown-extensions mike\n\nmike serve\n</code></pre>"},{"location":"project/docs-versioning/#read-next","title":"Read next","text":"<ul> <li>Docs update policy: <code>project/docs-per-release.md</code></li> <li>What\u2019s new: <code>whats-new/index.md</code></li> </ul>"},{"location":"project/glossary/","title":"Glossary","text":"<p>A small shared vocabulary used throughout the suite docs.</p>"},{"location":"project/glossary/#artifact","title":"Artifact","text":"<p>An immutable, version-addressed blob produced offline (for example: popularity, co-visitation, embeddings) and consumed by <code>recsys-service</code>.</p>"},{"location":"project/glossary/#manifest","title":"Manifest","text":"<p>A small document that maps artifact types to artifact URIs for a <code>(tenant, surface)</code> pair. In artifact mode, the \u201ccurrent manifest pointer\u201d is what you ship and roll back.</p>"},{"location":"project/glossary/#candidate","title":"Candidate","text":"<p>An item considered for ranking. Candidate generation prioritizes recall: \u201cwhat items should we even consider?\u201d</p>"},{"location":"project/glossary/#ranking","title":"Ranking","text":"<p>Scoring and ordering candidates to produce the final top-K list. Ranking prioritizes precision: \u201cwhich of these are best?\u201d</p>"},{"location":"project/glossary/#exposure","title":"Exposure","text":"<p>An event that records what items were shown (and in what order) for a single recommendation request.</p>"},{"location":"project/glossary/#outcome","title":"Outcome","text":"<p>An event that records what the user did after an exposure (click, conversion, etc.). Outcomes are attributed to exposures by <code>request_id</code>.</p>"},{"location":"project/glossary/#assignment","title":"Assignment","text":"<p>An event that records experiment bucket membership (experiment id + variant) used for A/B analysis.</p>"},{"location":"project/glossary/#request-id","title":"Request ID","text":"<p>A correlation identifier that ties together \u201crecommend\u201d responses, exposure logs, and outcome events. In this suite it is the primary join key for evaluation.</p>"},{"location":"project/glossary/#segment","title":"Segment","text":"<p>A cohort/slice label (default: <code>default</code>) used for rule scoping and evaluation breakdowns (guest vs returning, locale, etc.).</p>"},{"location":"project/glossary/#control-plane","title":"Control plane","text":"<p>The admin APIs and versioned documents (tenant config + rules) that control serving behavior without redeploying code.</p>"},{"location":"project/glossary/#ship","title":"Ship","text":"<p>Promote a candidate change to \u201ccurrent\u201d in a safe, reversible way (for example: update the manifest pointer, or update tenant config/rules versions).</p>"},{"location":"project/glossary/#rollback","title":"Rollback","text":"<p>Revert \u201ccurrent\u201d to a last-known-good version (config/rules rollback or manifest pointer rollback).</p>"},{"location":"project/glossary/#namespace","title":"Namespace","text":"<p>An application-defined bucket of recommendation logic/data. In this suite, <code>surface</code> typically acts as the namespace for signals and rules.</p>"},{"location":"project/glossary/#surface","title":"Surface","text":"<p>Where recommendations are shown (home, PDP, cart, \u2026). Surface names should be stable; they scope signals, rules, and evaluation slices.</p>"},{"location":"project/glossary/#tenant","title":"Tenant","text":"<p>An organization boundary for configuration and data isolation.</p>"},{"location":"project/governance/","title":"Governance","text":""},{"location":"project/governance/#maintainers","title":"Maintainers","text":"<p>This project is currently maintained by the core maintainer(s). Maintainers are responsible for:</p> <ul> <li>Reviewing and merging pull requests</li> <li>Cutting releases</li> <li>Managing security reports</li> <li>Curating roadmap direction</li> </ul>"},{"location":"project/governance/#decision-making","title":"Decision-making","text":"<p>Default decision model:</p> <ul> <li>Lazy consensus for small changes</li> <li>Maintainer decision for roadmap and release decisions</li> <li>Discuss major changes in an issue before implementation</li> </ul>"},{"location":"project/governance/#becoming-a-maintainer","title":"Becoming a maintainer","text":"<p>We may invite contributors to become maintainers based on:</p> <ul> <li>sustained high-quality contributions</li> <li>good judgment and communication</li> <li>alignment with project goals</li> </ul>"},{"location":"project/licenses_readme/","title":"License Directory Notes","text":"<p>This repository uses multiple licenses.</p> <p>Recommended best practice (REUSE/SPDX style):</p> <ul> <li>License texts are stored in <code>LICENSES/</code> directory.</li> </ul> <ul> <li>Use <code>SPDX-License-Identifier:</code> headers in files</li> </ul> <p>Current split: See <code>docs/licensing/index.md</code> for the human-readable guide.</p>"},{"location":"project/security/","title":"Security Policy","text":""},{"location":"project/security/#reporting-a-vulnerability","title":"Reporting a vulnerability","text":"<p>Please do not open public GitHub issues for security vulnerabilities.</p> <p>Preferred reporting options:</p> <ol> <li>GitHub Security Advisories / Private vulnerability reporting (if enabled for this repo)</li> <li>Email: <code>security@recsys.app</code></li> </ol> <p>Include:</p> <ul> <li>A clear description of the issue and potential impact</li> <li>Steps to reproduce (PoC if possible)</li> <li>Affected versions/commit hashes</li> <li>Any suggested fixes or mitigations</li> </ul>"},{"location":"project/security/#coordinated-disclosure","title":"Coordinated disclosure","text":"<p>We follow coordinated disclosure:</p> <ul> <li>We will acknowledge receipt within 72 hours (best effort)</li> <li>We will work with you on a disclosure timeline where feasible</li> <li>We will credit reporters in release notes unless you prefer anonymity</li> </ul>"},{"location":"project/security/#supported-versions","title":"Supported versions","text":"<ul> <li>We aim to support the latest stable minor release line.</li> <li>Security fixes may be backported at our discretion, depending on severity and effort.</li> </ul>"},{"location":"project/security/#security-hardening-guidance-high-level","title":"Security hardening guidance (high level)","text":"<ul> <li>Run the service with least privilege</li> <li>Keep secrets out of images; use environment variables or a secrets manager</li> <li>Restrict network access; prefer private networking for internal deployments</li> <li>Monitor logs and metrics for anomalous traffic</li> </ul>"},{"location":"project/support/","title":"Support","text":"<p>This project supports self-serve adoption. We keep support lightweight and mostly asynchronous.</p>"},{"location":"project/support/#community-support-free","title":"Community support (free)","text":"<ul> <li>GitHub Issues for bugs and feature requests</li> <li>Discussions for questions</li> <li>RecSys Copilot (Custom GPT) for docs Q&amp;A: <code>chatgpt.com/g/.../recsys-copilot</code></li> </ul> <p>Do not paste secrets or customer data into external tools.</p> <p>We do not guarantee response times for free support.</p>"},{"location":"project/support/#commercial-support-paid","title":"Commercial support (paid)","text":"<p>Commercial customers get the support level defined in their agreement.</p> <p>Typical support channels include:</p> <ul> <li>Private support email which will be provided upon commercial agreement</li> <li>Private issue tracker or GitHub private issues</li> </ul> <p>No-meetings policy (default):</p> <ul> <li>Support is async-first</li> <li>Calls are only by exception and must be pre-agreed and time-boxed</li> </ul>"},{"location":"project/support/#what-we-can-help-with","title":"What we can help with","text":"<ul> <li>Installation and upgrade guidance</li> <li>Reproducible bug investigation (with logs/configs)</li> <li>Security patch guidance</li> </ul>"},{"location":"project/support/#what-we-do-not-provide-by-default","title":"What we do not provide by default","text":"<ul> <li>24/7 on-call</li> <li>Operating your infrastructure</li> <li>Unlimited custom development without a fixed scope</li> </ul>"},{"location":"project/support/#before-opening-an-issue","title":"Before opening an issue","text":"<p>Please include:</p> <ul> <li>Version/commit hash</li> <li>Deployment mode (docker compose / k8s / helm)</li> <li>Logs and minimal reproduction steps</li> </ul>"},{"location":"recsys-algo/","title":"recsys-algo","text":"<p>Deterministic recommendation engine with explainable scoring, optional personalization, and merchandising rules.</p> <p>This module is the ranking core of the suite. It consumes candidate sets (popularity, co-visitation, similarity, etc.), applies constraints/rules, and produces a ranked list with optional explain/trace details.</p>"},{"location":"recsys-algo/#start-here","title":"Start here","text":"<ul> <li>Concepts: <code>concepts.md</code></li> <li>Integration (store ports): <code>store-ports.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Releases: <code>releases.md</code></li> </ul>"},{"location":"recsys-algo/#where-this-fits","title":"Where this fits","text":"<ul> <li>recsys-service calls into <code>recsys-algo</code> to generate ranked outputs.</li> <li>recsys-pipelines produces artifacts/signals that the service exposes as stores.</li> <li>recsys-eval validates changes in ranking behavior and business KPIs.</li> </ul>"},{"location":"recsys-algo/concepts/","title":"Concepts","text":"<p><code>recsys-algo</code> is built for determinism, explainability, and safe operational behavior.</p>"},{"location":"recsys-algo/concepts/#signals-and-blending","title":"Signals and blending","text":"<p>The engine can blend multiple signals:</p> <ul> <li>Popularity (top-K)</li> <li>Co-visitation (users/items seen together)</li> <li>Similarity (embeddings / collaborative / content / session)</li> </ul> <p>A typical configuration exposes blending weights (often referred to as <code>BlendAlpha</code>, <code>BlendBeta</code>, <code>BlendGamma</code>) to control each signal's contribution.</p>"},{"location":"recsys-algo/concepts/#rules-and-constraints","title":"Rules and constraints","text":"<p>After scoring, the engine can apply:</p> <ul> <li>Merchandising rules: pin / boost / block</li> <li>Diversity and capping: MMR-style diversification, brand/category caps</li> <li>Hard limits: K bounds, exclusions, safety checks</li> </ul>"},{"location":"recsys-algo/concepts/#explainability","title":"Explainability","text":"<p>For debugging, audits, and safer rollouts, responses can include:</p> <ul> <li>Reasons (high-level explain blocks)</li> <li>Trace data (low-level diagnostics suitable for audit logs)</li> </ul> <p>Use explain/trace only when you need it \u2014 it can increase payload size and computation.</p>"},{"location":"recsys-algo/examples/","title":"Examples","text":"<p>The module ships runnable examples under <code>recsys-algo/examples/</code>.</p>"},{"location":"recsys-algo/examples/#install","title":"Install","text":"<pre><code>go get github.com/aatuh/recsys-suite/api/recsys-algo\n</code></pre>"},{"location":"recsys-algo/examples/#minimal-example-popularity-only","title":"Minimal example (popularity-only)","text":"<p>See <code>recsys-algo/examples/basic</code> for a runnable popularity-only pipeline.</p>"},{"location":"recsys-algo/examples/#full-examples","title":"Full examples","text":"<ul> <li><code>recsys-algo/examples/personalized</code> \u2014 user profile + personalization</li> <li><code>recsys-algo/examples/rules</code> \u2014 pin/boost/block rule application</li> </ul>"},{"location":"recsys-algo/releases/","title":"Releases","text":"<p>Tag releases with the module prefix, for example:</p> <ul> <li><code>recsys-algo/v0.2.0</code></li> </ul> <p>Each module in the suite can be versioned and released independently.</p>"},{"location":"recsys-algo/store-ports/","title":"Store ports","text":"<p><code>recsys-algo</code> follows a ports-and-adapters style:</p> <ul> <li><code>model</code> defines interfaces (ports) for data access.</li> <li><code>algorithm</code> consumes those ports to produce ranked outputs.</li> </ul> <p>This separation makes the engine testable and lets you plug in different storage/backends (Postgres, Redis, object store, in-memory, etc.).</p>"},{"location":"recsys-algo/store-ports/#minimal-required-ports","title":"Minimal required ports","text":"<p>At minimum, implement:</p> <ul> <li><code>model.PopularityStore</code> \u2014 provides popularity candidates</li> <li><code>model.TagStore</code> \u2014 provides item tags used for filtering/diversity/caps</li> </ul>"},{"location":"recsys-algo/store-ports/#optional-ports-enable-more-signals","title":"Optional ports (enable more signals)","text":"<p>Depending on which signals/features you want, implement one or more of:</p> <ul> <li><code>model.ProfileStore</code> \u2014 user profile for personalization</li> <li><code>model.CooccurrenceStore</code> / <code>model.HistoryStore</code> \u2014 co-visitation</li> <li><code>model.EmbeddingStore</code> \u2014 embedding similarity</li> <li><code>model.CollaborativeStore</code> \u2014 ALS/CF similarity</li> <li><code>model.ContentStore</code> \u2014 content similarity (tag overlap)</li> <li><code>model.SessionStore</code> \u2014 session sequences</li> <li><code>model.EventStore</code> \u2014 event-based exclusions</li> </ul> <p>If a capability is missing, the engine should treat the signal as unavailable and continue.</p>"},{"location":"recsys-algo/store-ports/#runtime-feature-disabling","title":"Runtime feature disabling","text":"<p>To disable a feature at runtime (even if the port exists), return <code>model.ErrFeatureUnavailable</code> from a method.</p>"},{"location":"recsys-eval/overview/","title":"recsys-eval","text":"<p>recsys-eval turns recommendation logs into reports that tell you whether a recommender change is better, worse, or unclear - globally and per segment - with guardrails.</p> <p>If you only read one thing: read <code>Concepts</code>.</p>"},{"location":"recsys-eval/overview/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers shipping recommender changes</li> <li>Analysts and DS folks validating impact</li> <li>Platform teams wiring evaluation into CI</li> <li>Anyone who wants a clear \"ship / hold / rollback\" decision trail</li> </ul>"},{"location":"recsys-eval/overview/#what-you-get","title":"What you get","text":"<ul> <li>Offline evaluation (fast regression gate)</li> <li>Experiment analysis (A/B from production logs)</li> <li>Off-policy evaluation (OPE) when experiments are hard</li> <li>Interleaving analysis for sensitive ranker comparisons</li> <li>JSON/Markdown/HTML reports + optional decision artifact</li> </ul>"},{"location":"recsys-eval/overview/#quick-start-jsonl","title":"Quick start (JSONL)","text":"<p>1) Validate your inputs (recommended):</p> <pre><code>recsys-eval validate \\\n  --schema exposure.v1 \\\n  --input testdata/datasets/tiny/exposures.jsonl\n</code></pre> <p>1) Run an evaluation (choose one mode):</p> <pre><code># Offline evaluation\nrecsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.default.yaml \\\n  --output /tmp/offline_report.json\n\n# Markdown report\nrecsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.default.yaml \\\n  --output /tmp/offline_report.md \\\n  --output-format markdown\n\n# Experiment analysis\nrecsys-eval run \\\n  --mode experiment \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/experiment.default.yaml \\\n  --output /tmp/experiment_report.json\n\n# Offline evaluation (signals sample dataset)\nrecsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.signals.yaml \\\n  --config configs/eval/offline.signals.yaml \\\n  --output /tmp/offline_signals_report.json\n\n# Off-policy evaluation (OPE)\nrecsys-eval run \\\n  --mode ope \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/ope.default.yaml \\\n  --output /tmp/ope_report.json\n\n# Interleaving analysis\nrecsys-eval run \\\n  --mode interleaving \\\n  --dataset configs/examples/dataset.interleaving.jsonl.yaml \\\n  --config configs/eval/interleaving.default.yaml \\\n  --output /tmp/interleaving_report.json\n</code></pre>"},{"location":"recsys-eval/overview/#outputs","title":"Outputs","text":"<p>The primary output is a JSON report that conforms to api/schemas/report.v1.json. You can also emit Markdown or HTML summaries for sharing. It always includes:</p> <ul> <li>run_id</li> <li>mode</li> <li>created_at</li> <li>version</li> <li>summary</li> </ul> <p>Mode-specific sections are included when relevant: offline, experiment, ope, interleaving, aa_check.</p> <p>Optionally, some modes can emit a decision artifact that conforms to api/schemas/decision.v1.json.</p>"},{"location":"recsys-eval/overview/#read-next","title":"Read next","text":"<ul> <li><code>Concepts</code>: what the system does and how to think about it</li> <li><code>Data contracts</code>: what your inputs must look like</li> <li><code>Interpreting results</code>: how to read reports and make decisions</li> </ul> <p>Company-grade additions:</p> <ul> <li><code>Integration</code>: how to emit logs from a serving system</li> <li><code>CI gates</code>: exit codes, gating, and recommended pipelines</li> <li><code>Scaling</code>: large datasets and stream mode</li> <li><code>Runbooks</code> and <code>Troubleshooting</code>: debug and operate it</li> <li><code>OPE</code> and <code>Interleaving</code>: deeper dives</li> <li><code>Architecture</code>: extension points and how to add features</li> </ul>"},{"location":"recsys-eval/overview/#releases","title":"Releases","text":"<p>Tag releases with the module prefix, e.g. <code>recsys-eval/v0.2.0</code>.</p>"},{"location":"recsys-eval/docs/","title":"Index","text":"<p>If you are new:</p> <ul> <li><code>RecSys Eval Overview</code></li> <li><code>Concepts</code></li> </ul> <p>If you need to integrate:</p> <ul> <li><code>Data Contracts</code></li> <li><code>Integration</code></li> </ul> <p>If you need to interpret results:</p> <ul> <li><code>Metrics</code></li> <li><code>Interpreting Results</code></li> </ul> <p>If you run this in CI or ops:</p> <ul> <li><code>CI Gates</code></li> <li><code>Scaling</code></li> <li><code>Runbooks</code></li> <li><code>Troubleshooting</code></li> </ul> <p>Deep dives:</p> <ul> <li><code>OPE</code></li> <li><code>Interleaving</code></li> <li><code>Architecture</code></li> </ul>"},{"location":"recsys-eval/docs/architecture/","title":"Architecture: how the code is organized and how to extend it","text":""},{"location":"recsys-eval/docs/architecture/#who-this-is-for","title":"Who this is for","text":"<p>Maintainers and contributors.</p>"},{"location":"recsys-eval/docs/architecture/#what-you-will-get","title":"What you will get","text":"<ul> <li>The boundaries (domain vs ports vs adapters)</li> <li>Where to add a new metric, datasource, or report writer</li> <li>How to avoid creating a god-package</li> </ul>"},{"location":"recsys-eval/docs/architecture/#high-level-structure","title":"High-level structure","text":"<ul> <li>cmd/:</li> </ul> <p>CLI entrypoints</p> <ul> <li>internal/domain/:</li> </ul> <p>pure logic: metrics, statistics, joining rules, report models</p> <ul> <li>internal/ports/:</li> </ul> <p>interfaces for IO: datasources, report writers, loggers</p> <ul> <li>internal/adapters/:</li> </ul> <p>concrete IO: JSONL readers, Postgres readers, writers</p> <ul> <li>internal/app/:</li> </ul> <p>usecases that orchestrate domain logic + ports</p> <p>If you keep domain pure, tests become easy and reliability improves.</p>"},{"location":"recsys-eval/docs/architecture/#add-a-new-metric","title":"Add a new metric","text":"<p>1) Implement the metric in internal/domain/metrics/... 2) Add it to the registry (internal/domain/metrics/registry.go) 3) Add tests with toy inputs and known outputs 4) Document it in <code>metrics.md</code></p>"},{"location":"recsys-eval/docs/architecture/#add-a-new-datasource","title":"Add a new datasource","text":"<p>1) Implement ports interfaces (ExposureReader, OutcomeReader, etc.) 2) Add adapter under internal/adapters/datasource/<code>yourtype</code>/ 3) Wire it into the datasource factory or provider registry (depending on repo)</p>"},{"location":"recsys-eval/docs/architecture/#add-a-new-report-format","title":"Add a new report format","text":"<p>1) Implement a writer adapter under internal/adapters/reporting/ 2) Ensure the JSON report stays canonical (other formats derive from it)</p>"},{"location":"recsys-eval/docs/architecture/#the-rule-of-thumb","title":"The rule of thumb","text":"<ul> <li>Domain code should not import adapters.</li> <li>Ports should not import adapters.</li> <li>Adapters can import ports and domain.</li> </ul> <p>This keeps the system testable and change-friendly.</p>"},{"location":"recsys-eval/docs/ci_gates/","title":"CI gates: using recsys-eval in automation","text":""},{"location":"recsys-eval/docs/ci_gates/#who-this-is-for","title":"Who this is for","text":"<p>Engineers wiring recsys-eval into CI/CD or scheduled pipelines.</p>"},{"location":"recsys-eval/docs/ci_gates/#what-you-will-get","title":"What you will get","text":"<ul> <li>A practical gating pattern</li> <li>How to use exit codes</li> <li>How to store artifacts and compare runs</li> </ul>"},{"location":"recsys-eval/docs/ci_gates/#the-pattern-validate-run-store-report-gate","title":"The pattern: validate -&gt; run -&gt; store report -&gt; gate","text":"<p>1) Validate data (optional but recommended) 2) Run evaluation 3) Upload report artifact 4) Fail the pipeline if gates fail</p> <p>Example (tiny dataset gate used in CI):</p> <pre><code>recsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.ci.yaml \\\n  --output /tmp/offline_report.json \\\n  --baseline testdata/golden/offline.json\n</code></pre>"},{"location":"recsys-eval/docs/ci_gates/#exit-codes","title":"Exit codes","text":"<p>recsys-eval is designed to be automation-friendly:</p> <ul> <li>configuration or schema errors should fail fast</li> <li>gate failures should fail deterministically</li> </ul> <p>Recommended practice:</p> <ul> <li>treat \"invalid input\" differently from \"metric regression\"</li> </ul> <p>If your build supports a decision artifact:</p> <ul> <li>fail if decision != ship</li> <li>attach decision.json and report.json to the build</li> </ul>"},{"location":"recsys-eval/docs/ci_gates/#artifact-storage","title":"Artifact storage","text":"<p>Store:</p> <ul> <li>report.json</li> <li>effective config (or config hash)</li> <li>dataset fingerprint / window</li> <li>the exact binary version (build info)</li> </ul> <p>This is what makes runs auditable.</p>"},{"location":"recsys-eval/docs/ci_gates/#golden-tests-vs-production-gates","title":"Golden tests vs production gates","text":"<p>Golden tests:</p> <ul> <li>use tiny datasets</li> <li>protect behavior and output stability</li> </ul> <p>Production gates:</p> <ul> <li>use real logs</li> <li>protect business impact and safety</li> </ul> <p>Do not confuse the two. Use both.</p>"},{"location":"recsys-eval/docs/concepts/","title":"Concepts: how to understand recsys-eval","text":""},{"location":"recsys-eval/docs/concepts/#who-this-is-for","title":"Who this is for","text":"<p>Anyone. This is the \"map\" of the system.</p>"},{"location":"recsys-eval/docs/concepts/#what-you-will-get","title":"What you will get","text":"<ul> <li>The core mental model in 5 minutes</li> <li>The four workflows and when to use each</li> <li>A small glossary so words like \"exposure\" stop being mysterious</li> </ul>"},{"location":"recsys-eval/docs/concepts/#the-mental-model-in-one-picture","title":"The mental model in one picture","text":"<p>You log:</p> <ul> <li>what you showed (exposures)</li> <li>what users did (outcomes)</li> <li>who was in A vs B (assignments, for experiments)</li> </ul> <p>recsys-eval reads those logs and produces a report and optional decision.</p> <pre><code>exposures (ranked list shown)\n        + outcomes (clicks, purchases, etc.)\n        + assignments (control vs candidate)\n-------------------------------------------&gt; recsys-eval\n-------------------------------------------&gt; report.json (+ optional decision.json)\n</code></pre>"},{"location":"recsys-eval/docs/concepts/#glossary","title":"Glossary","text":"<ul> <li>request_id:</li> </ul> <p>A single recommendation moment. One screen, one call, one \"ranked list shown\".   In recsys-eval, request_id is the main join key.</p> <ul> <li>exposure:</li> </ul> <p>What you showed to the user for a request_id: the ranked list of items plus   context (tenant, surface, etc.).</p> <ul> <li>outcome:</li> </ul> <p>What the user did after the exposure: click, conversion, revenue, etc.</p> <ul> <li>assignment:</li> </ul> <p>Which experiment variant a request/user belongs to (control or candidate).</p> <ul> <li>segment:</li> </ul> <p>A slice such as tenant + surface + device. Segments are where hidden problems   show up. Global averages lie.</p> <ul> <li>guardrail:</li> </ul> <p>A metric that must not regress even if a primary metric improves. Typical   guardrails: latency, errors, empty recommendation rate.</p> <ul> <li>propensity (OPE only):</li> </ul> <p>A probability that a policy would show an item in a position. If you do not   have correct propensities, OPE can confidently produce nonsense.</p>"},{"location":"recsys-eval/docs/concepts/#the-four-workflows-pick-the-right-tool","title":"The four workflows (pick the right tool)","text":""},{"location":"recsys-eval/docs/concepts/#1-offline-evaluation","title":"1) Offline evaluation","text":"<p>Question:</p> <ul> <li>\"If we rank differently, does it better match what users later did?\"</li> </ul> <p>Inputs:</p> <ul> <li>exposures + outcomes</li> </ul> <p>Outputs:</p> <ul> <li>ranking metrics (NDCG@K, Recall@K, MAP@K, etc.)</li> <li>segment breakdowns</li> <li>optional confidence intervals</li> </ul> <p>When to use:</p> <ul> <li>before shipping changes</li> <li>regression gate in CI</li> </ul> <p>Common pitfalls:</p> <ul> <li>your join from exposures to outcomes is broken</li> <li>your \"ground truth\" is too sparse or biased</li> </ul>"},{"location":"recsys-eval/docs/concepts/#2-experiment-analysis-ab","title":"2) Experiment analysis (A/B)","text":"<p>Question:</p> <ul> <li>\"In production, did variant B outperform A, and did we stay within guardrails?\"</li> </ul> <p>Inputs:</p> <ul> <li>exposures + outcomes + assignments</li> </ul> <p>Outputs:</p> <ul> <li>KPI deltas (CTR, conversion, etc.)</li> <li>confidence intervals or p-values (depending on config)</li> <li>guardrail checks</li> <li>optional decision artifact (ship/hold/rollback)</li> </ul> <p>When to use:</p> <ul> <li>shipping decisions</li> </ul> <p>Common pitfalls:</p> <ul> <li>SRM (sample ratio mismatch): buckets are not balanced</li> <li>too many segments: false positives</li> </ul>"},{"location":"recsys-eval/docs/concepts/#3-off-policy-evaluation-ope","title":"3) Off-policy evaluation (OPE)","text":"<p>Question:</p> <ul> <li>\"Can we estimate impact from logs without running an experiment?\"</li> </ul> <p>Inputs:</p> <ul> <li>exposures + outcomes + propensities</li> </ul> <p>Outputs:</p> <ul> <li>IPS/SNIPS/DR estimates and diagnostics</li> <li>warnings about variance and missing propensities</li> </ul> <p>When to use:</p> <ul> <li>directional iteration when A/B is expensive</li> </ul> <p>Common pitfalls:</p> <ul> <li>missing overlap: the new policy behaves outside the support of the logged one</li> <li>near-zero propensities: variance explodes</li> </ul>"},{"location":"recsys-eval/docs/concepts/#4-interleaving","title":"4) Interleaving","text":"<p>Question:</p> <ul> <li>\"Between ranker A and B, which one wins more often on the same traffic?\"</li> </ul> <p>Inputs:</p> <ul> <li>ranker A results + ranker B results + outcomes (often clicks)</li> </ul> <p>Outputs:</p> <ul> <li>win rates, tie rate, p-value</li> </ul> <p>When to use:</p> <ul> <li>comparing two rankers or weight sets quickly</li> <li>when A/B would be too slow or noisy</li> </ul> <p>Common pitfalls:</p> <ul> <li>you treat interleaving as a full business KPI replacement (it is not)</li> </ul>"},{"location":"recsys-eval/docs/concepts/#where-this-fits-in-the-bigger-system","title":"Where this fits in the bigger system","text":"<p>Typical stack:</p> <ul> <li>recsys-service: serves recs and logs exposures and outcomes</li> <li>recsys-pipelines: builds artifacts (popularity, co-occurrence, embeddings)</li> <li>recsys-algo: ranks and applies rules</li> <li>recsys-eval: measures and decides</li> </ul> <p>recsys-eval is the \"truth serum\": it turns change claims into evidence.</p>"},{"location":"recsys-eval/docs/data_contracts/","title":"Data contracts: what inputs look like","text":""},{"location":"recsys-eval/docs/data_contracts/#who-this-is-for","title":"Who this is for","text":"<p>Integrators and anyone who needs to produce valid input logs.</p>"},{"location":"recsys-eval/docs/data_contracts/#what-you-will-get","title":"What you will get","text":"<ul> <li>The minimum required fields for each input type</li> <li>How the joins work</li> <li>Small example records</li> </ul> <p>recsys-eval uses JSON Schemas for validation:</p> <ul> <li>schemas/exposure.v1.json</li> <li>schemas/outcome.v1.json</li> <li>schemas/assignment.v1.json</li> <li>api/schemas/report.v1.json</li> <li>api/schemas/decision.v1.json</li> </ul> <p>Use the validate command before doing anything else:</p> <pre><code>recsys-eval validate --schema exposure.v1 --input exposures.jsonl\nrecsys-eval validate --schema outcome.v1 --input outcomes.jsonl\nrecsys-eval validate --schema assignment.v1 --input assignments.jsonl\n</code></pre>"},{"location":"recsys-eval/docs/data_contracts/#record-formats","title":"Record formats","text":""},{"location":"recsys-eval/docs/data_contracts/#exposure-what-was-shown","title":"Exposure (what was shown)","text":"<p>Purpose:</p> <ul> <li>describes what items were recommended and in what order</li> <li>provides context for segment slicing</li> <li>acts as the \"left side\" of joins</li> </ul> <p>Join key:</p> <ul> <li>request_id (required)</li> </ul> <p>Minimal example (illustrative, not exhaustive):</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"tenant\": \"demo\",\n  \"surface\": \"home\",\n  \"user_id\": \"u_42\",\n  \"timestamp\": \"2026-01-27T12:00:00Z\",\n  \"items\": [\n    {\"item_id\": \"A\", \"rank\": 1},\n    {\"item_id\": \"B\", \"rank\": 2}\n  ]\n}\n</code></pre> <p>Notes:</p> <ul> <li>For OPE, exposures may also include propensities. See docs/OPE.md.</li> </ul>"},{"location":"recsys-eval/docs/data_contracts/#outcome-what-the-user-did","title":"Outcome (what the user did)","text":"<p>Purpose:</p> <ul> <li>records the behavior you care about: click, conversion, etc.</li> </ul> <p>Join key:</p> <ul> <li>request_id (required)</li> </ul> <p>Minimal example:</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"event\": \"click\",\n  \"item_id\": \"B\",\n  \"timestamp\": \"2026-01-27T12:00:05Z\"\n}\n</code></pre>"},{"location":"recsys-eval/docs/data_contracts/#assignment-experiment-bucket","title":"Assignment (experiment bucket)","text":"<p>Purpose:</p> <ul> <li>tells which variant a request/user belongs to (control vs candidate)</li> </ul> <p>Join key:</p> <ul> <li>request_id (required in this dataset contract)</li> </ul> <p>Minimal example:</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"experiment_id\": \"exp_home_rank_v3\",\n  \"variant\": \"control\"\n}\n</code></pre>"},{"location":"recsys-eval/docs/data_contracts/#interleaving-datasets","title":"Interleaving datasets","text":"<p>Interleaving mode uses a different dataset config:</p> <ul> <li>ranker_a results</li> <li>ranker_b results</li> <li>outcomes (often clicks)</li> </ul> <p>See configs/examples/dataset.interleaving.jsonl.yaml for the wiring.</p>"},{"location":"recsys-eval/docs/data_contracts/#join-expectations-and-quality-signals","title":"Join expectations and quality signals","text":"<p>Good joins are boring. Bad joins destroy trust.</p> <p>In reports, look for:</p> <ul> <li>match rate: how many exposures have outcomes</li> <li>duplicate request_id rates</li> <li>timestamp anomalies</li> <li>missing tenant/surface fields (kills segmentation)</li> </ul> <p>If joins look wrong, stop and fix instrumentation. Do not \"tune metrics\".</p>"},{"location":"recsys-eval/docs/integration/","title":"Integration: how to produce the inputs","text":""},{"location":"recsys-eval/docs/integration/#who-this-is-for","title":"Who this is for","text":"<p>Backend / platform engineers wiring recsys-eval into a real recommender stack.</p>"},{"location":"recsys-eval/docs/integration/#what-you-will-get","title":"What you will get","text":"<ul> <li>What you need to log in your serving system</li> <li>How to keep IDs stable and privacy-safe</li> <li>A minimal logging plan for each mode</li> </ul>"},{"location":"recsys-eval/docs/integration/#the-one-rule-always-log-exposures","title":"The one rule: always log exposures","text":"<p>If you want to measure recommendations, you must log \"what you showed\". Clicks without exposures are not evaluatable.</p>"},{"location":"recsys-eval/docs/integration/#exposure-logging-recommended-fields","title":"Exposure logging (recommended fields)","text":"<p>At recommendation time (serving):</p> <ul> <li>request_id: unique per recommendation request</li> <li>tenant, surface: required for segmentation</li> <li>user_id or session_id: pseudonymized</li> <li>timestamp (ISO-8601)</li> <li>the ranked list of items (item_id + rank)</li> <li>optional: latency_ms, model_version, config_version, algo_version</li> <li>optional for deeper analysis: per-item scores and reasons (if you have them)</li> </ul> <p>Minimal JSONL exposure record:</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"tenant\": \"demo\",\n  \"surface\": \"home\",\n  \"user_id\": \"u_hash_...\",\n  \"timestamp\": \"2026-01-27T12:00:00Z\",\n  \"items\": [{\"item_id\": \"A\", \"rank\": 1}]\n}\n</code></pre>"},{"location":"recsys-eval/docs/integration/#outcome-logging","title":"Outcome logging","text":"<p>After exposure, when the user acts:</p> <ul> <li>request_id (same one)</li> <li>event type: click, purchase, etc.</li> <li>item_id (the item clicked/converted)</li> <li>timestamp</li> </ul> <p>If you have revenue or value, log it. If you do not, do not invent it.</p>"},{"location":"recsys-eval/docs/integration/#assignment-logging-experiments","title":"Assignment logging (experiments)","text":"<p>When you run an experiment:</p> <ul> <li>assignment should be deterministic and consistent</li> <li>log control vs candidate in a way you can audit</li> </ul> <p>Minimum:</p> <ul> <li>request_id</li> <li>experiment_id</li> <li>variant</li> </ul>"},{"location":"recsys-eval/docs/integration/#ope-logging-advanced","title":"OPE logging (advanced)","text":"<p>If you want OPE:</p> <ul> <li>you must log propensities</li> <li>you must define what policy produced the logged exposures</li> </ul> <p>This is easy to get wrong. Read docs/OPE.md before attempting.</p>"},{"location":"recsys-eval/docs/integration/#privacy-and-ids","title":"Privacy and IDs","text":"<p>Guidelines:</p> <ul> <li>never log raw PII (email, phone)</li> <li>hash or pseudonymize user identifiers</li> <li>be consistent: the same user should map to the same pseudonymous ID</li> </ul>"},{"location":"recsys-eval/docs/integration/#minimal-viable-integration-by-mode","title":"\"Minimal viable integration\" by mode","text":"<p>Offline:</p> <ul> <li>exposures + outcomes</li> <li>no assignments needed</li> </ul> <p>Experiment:</p> <ul> <li>exposures + outcomes + assignments</li> </ul> <p>Interleaving:</p> <ul> <li>ranker_a results + ranker_b results + outcomes</li> </ul> <p>OPE:</p> <ul> <li>exposures + outcomes + propensities (hard requirement)</li> </ul>"},{"location":"recsys-eval/docs/integration/#operational-tip","title":"Operational tip","text":"<p>Start with the tiny dataset shipped in testdata. If you cannot make your production logs look like that, you will struggle later.</p>"},{"location":"recsys-eval/docs/interleaving/","title":"Interleaving: fast ranker comparison on the same traffic","text":""},{"location":"recsys-eval/docs/interleaving/#who-this-is-for","title":"Who this is for","text":"<p>Engineers comparing two rankers or weight sets.</p>"},{"location":"recsys-eval/docs/interleaving/#what-you-will-get","title":"What you will get","text":"<ul> <li>What interleaving measures</li> <li>When it is the right tool</li> <li>Common mistakes</li> </ul>"},{"location":"recsys-eval/docs/interleaving/#what-it-is","title":"What it is","text":"<p>Interleaving mixes two ranked lists (A and B) into one displayed list. Then it attributes user actions (often clicks) back to A or B.</p> <p>This can be more sensitive than a full A/B when you only care about ranking.</p>"},{"location":"recsys-eval/docs/interleaving/#what-it-is-not","title":"What it is not","text":"<p>Interleaving is not a full product KPI decision engine. It does not account for all downstream effects. Use it to choose between rankers, then validate with A/B.</p>"},{"location":"recsys-eval/docs/interleaving/#inputs","title":"Inputs","text":"<ul> <li>ranker_a results (per request_id)</li> <li>ranker_b results (per request_id)</li> <li>outcomes (clicks)</li> </ul> <p>Dataset wiring example: configs/examples/dataset.interleaving.jsonl.yaml</p>"},{"location":"recsys-eval/docs/interleaving/#output","title":"Output","text":"<ul> <li>A wins / B wins counts</li> <li>win rate and tie rate</li> <li>a significance estimate</li> </ul>"},{"location":"recsys-eval/docs/interleaving/#common-mistakes","title":"Common mistakes","text":"<ul> <li>comparing rankers trained on different candidate sets without noting it</li> <li>treating interleaving wins as business KPI wins</li> </ul>"},{"location":"recsys-eval/docs/interpreting_results/","title":"Interpreting results: how to go from report to decision","text":""},{"location":"recsys-eval/docs/interpreting_results/#who-this-is-for","title":"Who this is for","text":"<p>Anyone making ship/hold decisions (engineers, PMs, analysts).</p>"},{"location":"recsys-eval/docs/interpreting_results/#what-you-will-get","title":"What you will get","text":"<ul> <li>How to read a report</li> <li>How to decide \"ship / hold / rollback\" without fooling yourself</li> <li>What to do when results are unclear</li> </ul>"},{"location":"recsys-eval/docs/interpreting_results/#step-0-trust-the-data-before-trusting-the-metrics","title":"Step 0: Trust the data before trusting the metrics","text":"<p>Check:</p> <ul> <li>data_quality: missing fields, duplicates, anomalies</li> <li>join integrity: match rates, unexpected drops</li> <li>warnings: especially for OPE</li> </ul> <p>If these look bad, stop. Fix logging.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-1-start-with-the-summary","title":"Step 1: Start with the summary","text":"<p>The report includes a summary for quick scanning:</p> <ul> <li>mode</li> <li>main deltas (baseline vs candidate or control vs candidate)</li> <li>whether gates passed</li> </ul> <p>If the summary says \"inconclusive\", treat it as a real outcome.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-2-check-guardrails","title":"Step 2: Check guardrails","text":"<p>Even if the primary metric improves, do not ship if:</p> <ul> <li>empty rate regressed</li> <li>latency regressed outside budget</li> <li>error rate regressed</li> <li>a critical segment cliff appears</li> </ul> <p>Guardrails exist because \"winning slowly\" is losing.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-3-look-at-segments-as-a-radar-not-a-scoreboard","title":"Step 3: Look at segments as a radar, not a scoreboard","text":"<p>Segments answer:</p> <ul> <li>Who did this help?</li> <li>Who did this hurt?</li> <li>Is the impact consistent?</li> </ul> <p>Segments can also create false positives when you slice too much. Use segments as diagnostics unless you have power to claim segment wins.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-4-interpreting-uncertainty","title":"Step 4: Interpreting uncertainty","text":"<p>If you use confidence intervals or p-values:</p> <ul> <li>wide intervals mean you do not know yet</li> <li>small p-values can still happen by chance if you test too many things</li> </ul> <p>\"Inconclusive\" is not failure. It is a request for more data or a better experiment design.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-5-a-simple-decision-policy-you-can-adopt","title":"Step 5: A simple decision policy you can adopt","text":"<p>Suggested policy:</p> <ul> <li>SHIP:</li> </ul> <p>primary metric improves and guardrails hold and no major segment regressions</p> <ul> <li>HOLD:</li> </ul> <p>results are inconclusive or diagnostics warn about data quality</p> <ul> <li>ROLLBACK:</li> </ul> <p>primary regresses or guardrails regress or a major segment cliff appears</p> <p>This maps well to a decision artifact (api/schemas/decision.v1.json).</p>"},{"location":"recsys-eval/docs/interpreting_results/#what-to-do-when-it-is-unclear","title":"What to do when it is unclear","text":"<p>Choose one:</p> <ul> <li>run longer / collect more samples</li> <li>reduce variance (CUPED / better covariates)</li> <li>narrow the change (smaller delta)</li> <li>use interleaving for ranker comparison</li> <li>do offline gating first, then A/B</li> </ul>"},{"location":"recsys-eval/docs/interpreting_results/#common-pitfalls","title":"Common pitfalls","text":"<ul> <li>Confusing \"statistically significant\" with \"practically important\".</li> <li>Shipping a win that is isolated to a single surface and breaks another.</li> <li>Ignoring SRM warnings in experiments.</li> </ul> <p>Treat the report as a navigation tool, not a trophy.</p>"},{"location":"recsys-eval/docs/metrics/","title":"Metrics: what we measure and why","text":""},{"location":"recsys-eval/docs/metrics/#who-this-is-for","title":"Who this is for","text":"<p>Analysts, DS, and engineers who need to interpret the output correctly.</p>"},{"location":"recsys-eval/docs/metrics/#what-you-will-get","title":"What you will get","text":"<ul> <li>A practical description of the main metric families</li> <li>When each metric is useful</li> <li>What each metric can hide</li> </ul> <p>You do not need to love metrics. You just need to not be fooled by them.</p>"},{"location":"recsys-eval/docs/metrics/#offline-ranking-metrics-relevance-proxies","title":"Offline ranking metrics (relevance proxies)","text":"<p>Offline metrics compare the ranked list (exposure) against some notion of \"ground truth\" (outcomes). Common examples:</p> <ul> <li>HitRate@K:</li> </ul> <p>Did at least one relevant item appear in the top K?</p> <ul> <li>Precision@K:</li> </ul> <p>Of the top K items, how many were relevant?</p> <ul> <li>Recall@K:</li> </ul> <p>Of all relevant items, how many did we include in top K?</p> <ul> <li>MAP@K:</li> </ul> <p>Rewards putting relevant items early, averaged across requests.</p> <ul> <li>NDCG@K:</li> </ul> <p>A discounted gain metric: earlier is better; supports graded relevance.</p> <p>These are great for fast regression gating. They are not the same as business KPIs. They can disagree with online results.</p>"},{"location":"recsys-eval/docs/metrics/#experiment-metrics-business-facing","title":"Experiment metrics (business-facing)","text":"<p>Online metrics are computed from experiments (control vs candidate). Examples:</p> <ul> <li>CTR: clicks / exposures</li> <li>conversion rate: purchases / exposures</li> <li>revenue per exposure: sum(value) / exposures</li> <li>downstream engagement proxies (if you log them)</li> </ul> <p>These are closer to what the business cares about. They are noisier.</p>"},{"location":"recsys-eval/docs/metrics/#guardrails","title":"Guardrails","text":"<p>Guardrails exist to prevent you from shipping a \"win\" that breaks the system.</p> <p>Common guardrails:</p> <ul> <li>empty recommendation rate: response has zero items</li> <li>latency: p95/p99 changes</li> <li>error rate: HTTP failures or upstream store failures</li> <li>join integrity: if joins break, your metrics are fiction</li> </ul> <p>A typical decision policy:</p> <ul> <li>ship only if primary improves AND guardrails hold AND no segment cliffs</li> </ul>"},{"location":"recsys-eval/docs/metrics/#distribution-and-quality-metrics","title":"Distribution and quality metrics","text":"<p>These answer: \"Did we change what we show, even if CTR is stable?\"</p> <p>Examples:</p> <ul> <li>item coverage: how much of the catalog appears</li> <li>long-tail share: are we showing only popular items</li> <li>category shift: are we drifting away from desired category mix</li> <li>diversity: are top K items too similar</li> </ul> <p>These are especially useful when you care about discovery and fairness.</p>"},{"location":"recsys-eval/docs/metrics/#distribution-metrics-implemented-here","title":"Distribution metrics implemented here","text":"<p>These are proxy metrics derived from exposures and outcomes (no catalog metadata required):</p> <ul> <li>Coverage@K: unique items shown in top K across all requests divided by</li> </ul> <p>unique items seen anywhere in recommendations or outcomes. It answers   \"how much of the observed catalog is exposed in the top slots?\"</p> <ul> <li>Novelty@K: average <code>-log2(popularity)</code> for items shown in top K, where</li> </ul> <p>popularity is the global exposure frequency. Higher means \"less popular on   average\". This is a proxy for long\u2011tail exposure.</p> <ul> <li>Diversity@K: normalized entropy of the item distribution in top K</li> </ul> <p>recommendations across requests. Values near 1.0 mean a wide spread;   values near 0 mean concentration on a few items.</p> <p>If you have real catalog metadata (categories, embeddings), you should compute richer diversity/novelty metrics upstream and feed them as outcomes.</p>"},{"location":"recsys-eval/docs/metrics/#common-mistakes","title":"Common mistakes","text":"<ul> <li>\"CTR improved so we are done\":</li> </ul> <p>CTR can increase by getting click-bait-y or repeating popular items.</p> <ul> <li>\"Offline NDCG improved so it must ship\":</li> </ul> <p>Offline evaluation can be biased or too simplified.</p> <ul> <li>\"We looked at 50 segments and found 3 big wins\":</li> </ul> <p>This can be pure chance. Treat segments as diagnostics unless powered.</p>"},{"location":"recsys-eval/docs/metrics/#practical-recommendations","title":"Practical recommendations","text":"<p>Start with:</p> <ul> <li>1-2 primary metrics</li> <li>2-4 guardrails</li> <li>segment slicing limited to the top business cuts (tenant/surface/device)</li> </ul> <p>Add more only after you can run the basics reliably.</p>"},{"location":"recsys-eval/docs/ope/","title":"Off-policy evaluation (OPE): powerful and easy to misuse","text":""},{"location":"recsys-eval/docs/ope/#who-this-is-for","title":"Who this is for","text":"<p>Advanced users. Read this before using --mode ope in anything serious.</p>"},{"location":"recsys-eval/docs/ope/#what-you-will-get","title":"What you will get","text":"<ul> <li>What OPE tries to estimate</li> <li>What propensities are and why they matter</li> <li>When OPE results are trustworthy and when they are not</li> </ul>"},{"location":"recsys-eval/docs/ope/#the-promise","title":"The promise","text":"<p>OPE tries to answer:</p> <ul> <li>\"What would have happened if we used a different ranking policy?\"</li> </ul> <p>using logs collected from an old policy.</p> <p>This can save you from running an online experiment.</p>"},{"location":"recsys-eval/docs/ope/#the-catch","title":"The catch","text":"<p>OPE depends on assumptions that are easy to violate:</p> <ul> <li>correct propensity logging</li> <li>overlap between old and new policies (support)</li> <li>stable user behavior model</li> </ul> <p>If you violate these, OPE can confidently lie.</p>"},{"location":"recsys-eval/docs/ope/#propensities-in-plain-language","title":"Propensities in plain language","text":"<p>A propensity is the probability that a policy shows an item in a position.</p> <p>If an item never appears under the logging policy, you cannot reliably estimate how it would perform under a new policy. This is the \"no overlap\" problem.</p>"},{"location":"recsys-eval/docs/ope/#diagnostics-you-should-take-seriously","title":"Diagnostics you should take seriously","text":"<ul> <li>near-zero propensities:</li> </ul> <p>your estimator variance explodes</p> <ul> <li>missing target propensities:</li> </ul> <p>you are not evaluating the policy you think you are</p> <ul> <li>heavy clipping:</li> </ul> <p>your result is dominated by a few samples</p>"},{"location":"recsys-eval/docs/ope/#a-practical-when-to-use-checklist","title":"A practical \"when to use\" checklist","text":"<p>Use OPE when:</p> <ul> <li>you log propensities correctly</li> <li>your new policy is a mild change from the old</li> <li>you mainly want directional signal</li> </ul> <p>Do not use OPE when:</p> <ul> <li>the new policy changes candidate generation dramatically</li> <li>you have missing propensity fields</li> <li>you care about strict ship/no-ship</li> </ul>"},{"location":"recsys-eval/docs/ope/#recommended-practice","title":"Recommended practice","text":"<ul> <li>Use offline evaluation first.</li> <li>Use OPE as an early filter.</li> <li>Use A/B or interleaving for the final decision.</li> </ul>"},{"location":"recsys-eval/docs/roadmap/","title":"Roadmap (high level)","text":"<p>This doc is intentionally short. It exists to set expectations.</p>"},{"location":"recsys-eval/docs/roadmap/#now-stability-and-trust","title":"Now (stability and trust)","text":"<ul> <li>streaming-first for big logs</li> <li>structured logging and run correlation</li> <li>reproducibility: config and dataset fingerprints</li> </ul>"},{"location":"recsys-eval/docs/roadmap/#next-power-and-sensitivity","title":"Next (power and sensitivity)","text":"<ul> <li>stronger experiment analysis features (variance reduction)</li> <li>better segment regression surfacing</li> <li>richer guardrails</li> </ul>"},{"location":"recsys-eval/docs/roadmap/#later-advanced-evaluation","title":"Later (advanced evaluation)","text":"<ul> <li>more OPE diagnostics and ranking-specific estimators</li> <li>interleaving variants and deeper analysis</li> </ul>"},{"location":"recsys-eval/docs/roadmap/#non-goals","title":"Non-goals","text":"<ul> <li>training models</li> <li>serving recommendations</li> <li>replacing a full experimentation platform</li> </ul>"},{"location":"recsys-eval/docs/runbooks/","title":"Runbooks: operating recsys-eval","text":""},{"location":"recsys-eval/docs/runbooks/#who-this-is-for","title":"Who this is for","text":"<p>Maintainers and on-call engineers.</p>"},{"location":"recsys-eval/docs/runbooks/#what-you-will-get","title":"What you will get","text":"<ul> <li>The top failure modes and how to debug them quickly</li> <li>A repeatable \"triage\" flow</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#triage-flow","title":"Triage flow","text":"<ol> <li> <p>Identify the run:</p> </li> <li> <p>run_id</p> </li> <li>mode</li> <li>dataset window</li> <li> <p>binary version</p> </li> <li> <p>Check data quality:</p> </li> <li> <p>schema validation</p> </li> <li>duplicates</li> <li> <p>missing required fields</p> </li> <li> <p>Check joins:</p> </li> <li> <p>match rates</p> </li> <li> <p>timestamp anomalies</p> </li> <li> <p>Check gates and warnings:</p> </li> <li> <p>which metric triggered the gate</p> </li> <li> <p>which segment drove the regression</p> </li> <li> <p>Decide action:</p> </li> <li> <p>fix data</p> </li> <li>rerun</li> <li>rollback config/model</li> <li>escalate</li> </ol>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-schema-validation-fails","title":"Failure mode: schema validation fails","text":"<p>Symptoms:</p> <ul> <li>validate command reports missing fields or wrong types</li> </ul> <p>Fix:</p> <ul> <li>update logging to match schemas</li> <li>if schema changed, bump schema version and update producers</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-join-match-rate-collapses","title":"Failure mode: join match rate collapses","text":"<p>Symptoms:</p> <ul> <li>offline metrics drop to near zero</li> <li>report shows low join match</li> </ul> <p>Likely causes:</p> <ul> <li>request_id changed format</li> <li>producers stopped logging outcomes with request_id</li> <li>duplicate or missing request_id in exposures</li> </ul> <p>Fix:</p> <ul> <li>compare recent exposure and outcome samples</li> <li>confirm request_id consistency end-to-end</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-srm-warning-experiments","title":"Failure mode: SRM warning (experiments)","text":"<p>Symptoms:</p> <ul> <li>control vs candidate sample sizes are off</li> </ul> <p>Likely causes:</p> <ul> <li>bucket assignment bug</li> <li>logging bug</li> <li>rollout was not actually 50/50</li> </ul> <p>Fix:</p> <ul> <li>stop interpreting metrics</li> <li>fix assignment and rerun</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-ope-high-variance","title":"Failure mode: OPE high variance","text":"<p>Symptoms:</p> <ul> <li>warnings about near-zero propensities</li> <li>wildly unstable estimates</li> </ul> <p>Fix:</p> <ul> <li>do not ship based on OPE</li> <li>improve propensity logging and overlap</li> <li>prefer A/B or interleaving</li> </ul>"},{"location":"recsys-eval/docs/scaling/","title":"Scaling: large datasets and performance","text":""},{"location":"recsys-eval/docs/scaling/#who-this-is-for","title":"Who this is for","text":"<p>Anyone running recsys-eval on real production-sized logs.</p>"},{"location":"recsys-eval/docs/scaling/#what-you-will-get","title":"What you will get","text":"<ul> <li>When JSONL is enough and when to move to a warehouse</li> <li>How stream mode works and what it requires</li> <li>Practical tips to avoid OOM and slow runs</li> </ul>"},{"location":"recsys-eval/docs/scaling/#reality-check","title":"Reality check","text":"<p>If your logs are gigabytes:</p> <ul> <li>reading everything into memory is not acceptable</li> <li>joining exposures and outcomes is the main cost center</li> </ul> <p>Your goals:</p> <ul> <li>bounded memory</li> <li>stable runtime</li> <li>reproducible results</li> </ul>"},{"location":"recsys-eval/docs/scaling/#data-source-choices","title":"Data source choices","text":"<p>Small datasets:</p> <ul> <li>JSONL is fine</li> </ul> <p>Large datasets:</p> <ul> <li>prefer a warehouse-backed adapter (Postgres, etc.)</li> <li>let SQL do joins when possible</li> </ul>"},{"location":"recsys-eval/docs/scaling/#stream-mode-jsonl","title":"Stream mode (JSONL)","text":"<p>Offline mode can support stream mode for large presorted JSONL inputs:</p> <ul> <li>merge join by request_id</li> <li>requires exposures and outcomes sorted by request_id</li> </ul> <p>If inputs are not sorted, stream mode will not behave correctly. Note: dataset-level distribution metrics (coverage/novelty/diversity) are not available in stream mode.</p>"},{"location":"recsys-eval/docs/scaling/#practical-knobs-recommended","title":"Practical knobs (recommended)","text":"<ul> <li>Run per tenant and per surface, then aggregate.</li> <li>Reduce slice keys until you understand performance.</li> <li>Start without bootstrap; add it once the basics work.</li> </ul>"},{"location":"recsys-eval/docs/scaling/#performance-debugging-checklist","title":"Performance debugging checklist","text":"<ul> <li>Is join match rate unexpectedly low?</li> <li>Are there duplicate request_id values?</li> <li>Are you reading through network storage instead of local disk?</li> <li>Are you outputting huge reports because you enabled too much detail?</li> </ul> <p>When in doubt, reduce scope, confirm correctness, then scale up.</p>"},{"location":"recsys-eval/docs/security_privacy/","title":"Security and privacy notes","text":""},{"location":"recsys-eval/docs/security_privacy/#who-this-is-for","title":"Who this is for","text":"<p>Anyone handling real user data.</p>"},{"location":"recsys-eval/docs/security_privacy/#what-you-will-get","title":"What you will get","text":"<ul> <li>A safe baseline for logging and storage</li> <li>Common pitfalls</li> </ul>"},{"location":"recsys-eval/docs/security_privacy/#baseline","title":"Baseline","text":"<ul> <li>Do not log raw PII (email, phone, exact address).</li> <li>Prefer pseudonymous user IDs.</li> <li>Keep per-tenant boundaries strict.</li> <li>Limit report retention based on policy.</li> </ul>"},{"location":"recsys-eval/docs/security_privacy/#data-minimization","title":"Data minimization","text":"<p>Only log what you can justify measuring. If you do not need a field, do not collect it.</p>"},{"location":"recsys-eval/docs/security_privacy/#ope-and-privacy","title":"OPE and privacy","text":"<p>Propensity logging can include per-item scores. Treat them as sensitive. They can leak model behavior and business logic if exposed carelessly.</p>"},{"location":"recsys-eval/docs/style/","title":"Documentation style guide","text":"<p>This documentation is written to be:</p> <ul> <li>human-friendly</li> <li>practical and runnable</li> <li>honest about uncertainty</li> <li>consistent across files</li> </ul>"},{"location":"recsys-eval/docs/style/#voice","title":"Voice","text":"<ul> <li>Use \"you\" and \"we\".</li> <li>Prefer concrete examples over theory.</li> <li>Define terms the first time they appear.</li> <li>Avoid jargon unless it buys precision.</li> </ul>"},{"location":"recsys-eval/docs/style/#structure","title":"Structure","text":"<p>Every doc starts with:</p> <ul> <li>Who this is for</li> <li>What you will get</li> </ul> <p>Every doc contains:</p> <ul> <li>Examples (commands or JSON)</li> <li>Common pitfalls</li> </ul>"},{"location":"recsys-eval/docs/style/#line-width-and-typography","title":"Line width and typography","text":"<ul> <li>Keep lines reasonably short (about 80-100 chars).</li> <li>Use plain ASCII characters in code and examples.</li> </ul>"},{"location":"recsys-eval/docs/style/#terminology","title":"Terminology","text":"<p>Use these consistently:</p> <ul> <li>\"exposure\": what was shown (ranked list)</li> <li>\"outcome\": what the user did after exposure</li> <li>\"assignment\": experiment bucket (control vs candidate)</li> <li>\"segment\": a slice like tenant+surface+device</li> <li>\"guardrail\": a metric that must not regress</li> </ul> <p>Generated: 2026-01-27</p>"},{"location":"recsys-eval/docs/troubleshooting/","title":"Troubleshooting: symptom -&gt; cause -&gt; fix","text":""},{"location":"recsys-eval/docs/troubleshooting/#who-this-is-for","title":"Who this is for","text":"<p>Anyone stuck. Use this as a quick lookup.</p>"},{"location":"recsys-eval/docs/troubleshooting/#report-is-empty-or-missing-sections","title":"Report is empty or missing sections","text":"<p>Cause:</p> <ul> <li>wrong mode</li> <li>output path permission issue</li> </ul> <p>Fix:</p> <ul> <li>verify --mode and config</li> <li>write to a writable path</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#unknown-schema-in-validate","title":"\"unknown schema\" in validate","text":"<p>Cause:</p> <ul> <li>wrong schema name</li> </ul> <p>Fix:</p> <ul> <li>use exposure.v1, outcome.v1, assignment.v1</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#metrics-are-all-zero","title":"Metrics are all zero","text":"<p>Cause:</p> <ul> <li>outcomes not joined to exposures</li> <li>event types not matching expectations</li> </ul> <p>Fix:</p> <ul> <li>check request_id alignment</li> <li>inspect a few joined records</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#everything-looks-like-a-win","title":"Everything looks like a win","text":"<p>Cause:</p> <ul> <li>you compared the same dataset against itself</li> <li>you sliced too much and found random wins</li> </ul> <p>Fix:</p> <ul> <li>run AA-check or use a known baseline</li> <li>reduce slices and focus on primary metrics</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#interleaving-says-a-wins-but-ab-says-b-wins","title":"Interleaving says A wins but A/B says B wins","text":"<p>Cause:</p> <ul> <li>interleaving measures relative ranker preference on the same traffic</li> <li>A/B includes broader effects and guardrails</li> </ul> <p>Fix:</p> <ul> <li>use interleaving to choose between rankers</li> <li>use A/B to decide shipping</li> </ul>"},{"location":"recsys-pipelines/overview/","title":"recsys-pipelines","text":"<p>Filesystem-first pipelines that build versioned recommendation artifacts from raw exposure events.</p> <p>This repository is the offline factory of a recommender stack:</p> <ul> <li>It ingests raw exposure events (JSONL, Postgres, or S3 batch).</li> <li>It canonicalizes them into a deterministic, replayable dataset.</li> <li>It computes artifacts (v1: popularity, co-occurrence, implicit, content_sim, session_seq).</li> <li>It validates outputs and enforces hard resource limits.</li> <li>It publishes artifacts to a versioned object store and updates a</li> </ul> <p>single \"current\" manifest pointer.</p> <p>If you are new: start at <code>docs/start-here.md</code>.</p>"},{"location":"recsys-pipelines/overview/#quickstart","title":"Quickstart","text":"<p>Requirements:</p> <ul> <li>Go toolchain (see <code>go.mod</code>)</li> </ul> <p>Run the pipeline locally against the tiny sample dataset:</p> <pre><code>make test\nmake build\n\n./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-01\n</code></pre> <p>Outputs (default <code>.out/</code>):</p> <ul> <li>Canonical events: <code>.out/canonical/&lt;tenant&gt;/&lt;surface&gt;/exposures/YYYY-MM-DD.jsonl</code></li> <li>Staged artifacts: <code>.out/artifacts/&lt;tenant&gt;/&lt;surface&gt;/&lt;segment&gt;/&lt;type&gt;/&lt;window&gt;/...</code></li> <li>Published blobs: <code>.out/objectstore/&lt;tenant&gt;/&lt;surface&gt;/&lt;type&gt;/&lt;version&gt;.json</code></li> <li>Current manifest: <code>.out/registry/current/&lt;tenant&gt;/&lt;surface&gt;/manifest.json</code></li> </ul> <p>Run the smoke test (includes an idempotency check):</p> <pre><code>make smoke\n</code></pre>"},{"location":"recsys-pipelines/overview/#documentation","title":"Documentation","text":"<p>Docs are organized using the Diataxis approach (tutorials, how-to guides, explanations, and reference). See <code>docs/index.md</code> for the entry point.</p> <ul> <li>Start here: <code>docs/start-here.md</code></li> <li>Tutorials: <code>docs/tutorials/</code></li> <li>How-to: <code>docs/how-to/</code></li> <li>Explanations: <code>docs/explanation/</code></li> <li>Reference: <code>docs/reference/</code></li> <li>Operations: <code>docs/operations/</code></li> </ul>"},{"location":"recsys-pipelines/overview/#binaries","title":"Binaries","text":"<ul> <li><code>recsys-pipelines</code>: one-shot runner (local/dev, or simple cron)</li> <li><code>job_ingest</code>: ingest + canonicalize (job-per-container style)</li> <li><code>job_popularity</code>: compute + stage popularity artifact</li> <li><code>job_cooc</code>: compute + stage co-occurrence artifact</li> <li><code>job_implicit</code>: compute + stage implicit (collaborative) artifact</li> <li><code>job_content_sim</code>: compute + stage content similarity artifact</li> <li><code>job_session_seq</code>: compute + stage session sequence artifact</li> <li><code>job_validate</code>: validate canonical event quality for a window range</li> <li><code>job_publish</code>: publish staged artifacts + swap the current manifest</li> <li><code>job_db_signals</code>: write popularity + co-vis signals into Postgres</li> <li><code>job_catalog</code>: ingest item tags into Postgres</li> </ul> <p>See: <code>docs/tutorials/job-mode.md</code>.</p>"},{"location":"recsys-pipelines/overview/#contributing","title":"Contributing","text":"<p>See <code>docs/contributing/dev-workflow.md</code>.</p>"},{"location":"recsys-pipelines/overview/#releases","title":"Releases","text":"<p>Tag releases with the module prefix, e.g. <code>recsys-pipelines/v0.2.0</code>.</p>"},{"location":"recsys-pipelines/docs/","title":"Index","text":"<p>Welcome! This documentation explains what this system is, who it is for, and how to run and operate it.</p> <p>This repo builds versioned recommendation artifacts (currently popularity and co-occurrence) from raw exposure events.</p>"},{"location":"recsys-pipelines/docs/#start-here","title":"Start here","text":"<ul> <li>If you are new: Start Here: <code>start-here.md</code></li> <li>If you want to run it now: <code>tutorials/local-quickstart.md</code></li> </ul>"},{"location":"recsys-pipelines/docs/#choose-your-path","title":"Choose your path","text":"<ul> <li>Product / PM: <code>learning-paths/product.md</code></li> <li>Engineers: <code>learning-paths/engineer.md</code></li> <li>Data Engineering / Analytics: <code>learning-paths/data-engineer.md</code></li> <li>SRE / Platform: <code>learning-paths/sre-oncall.md</code></li> </ul>"},{"location":"recsys-pipelines/docs/#docs-map-diataxis","title":"Docs map (Diataxis)","text":"<ul> <li>Tutorials: learning by doing</li> <li>How-to guides: task-focused recipes</li> <li>Explanation: concepts and reasoning</li> <li>Reference: exact contracts and CLI/config details</li> </ul> <p>See <code>explanation/documentation-approach.md</code>.</p>"},{"location":"recsys-pipelines/docs/glossary/","title":"Glossary","text":"<p>Artifact : A precomputed data product used by the online recommender, such as popularity   lists or item neighbors.</p> <p>Canonical events : Events stored in a normalized format that the rest of the pipeline relies on.</p> <p>Tenant : A logical customer or environment namespace.</p> <p>Surface : A recommendation placement (e.g. \"home\", \"checkout\").</p> <p>Segment : Optional sub-grouping within a surface (e.g. \"new_users\").</p> <p>Window : A time range that a job processes. In v1, windows are daily UTC buckets.</p> <p>Version : A deterministic identifier (SHA-256 hex) of an artifact payload excluding   volatile build metadata.</p> <p>Manifest : A small JSON document that points to the current artifact URIs for a   (tenant, surface).</p> <p>Registry : Storage for artifact records and current manifests.</p> <p>Object store : Storage for artifact blobs. In local mode, this is the filesystem.</p> <p>Idempotent : Safe to run multiple times without changing the result.</p>"},{"location":"recsys-pipelines/docs/start-here/","title":"Start here","text":""},{"location":"recsys-pipelines/docs/start-here/#what-this-system-does-non-technical","title":"What this system does (non-technical)","text":"<p>Think of <code>recsys-pipelines</code> as a factory:</p> <ul> <li>It reads a stream of user activity events (\"people saw item X\")</li> <li>It cleans and stores them in a consistent format (canonical events)</li> <li>It computes simple recommendation building blocks (artifacts)</li> <li>It publishes those artifacts in a versioned and rollbackable way</li> </ul> <p>The output artifacts are meant to be consumed by an online recommender service.</p>"},{"location":"recsys-pipelines/docs/start-here/#what-this-system-does-technical","title":"What this system does (technical)","text":"<p><code>recsys-pipelines</code> builds deterministic, version-addressed artifacts from raw exposure events.</p> <p>Current v1 artifact types:</p> <ul> <li>popularity: top-N items by exposure count</li> <li>cooc: item-item co-occurrence neighbors within a session</li> <li>implicit: user\u2192item scores from implicit feedback</li> <li>content_sim: item tags for content-based similarity</li> <li>session_seq: user\u2192next-item sequence signals</li> </ul> <p>Key production properties:</p> <ul> <li>Idempotent canonicalization: reruns for the same day window do not</li> </ul> <p>duplicate events.</p> <ul> <li>Atomic writes: artifacts and pointers are written using temp+rename.</li> <li>Validation gates: publishing is blocked if validation fails.</li> <li>Guardrails: configurable limits prevent resource blowups.</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#who-uses-it","title":"Who uses it","text":"<p>This repo is designed to be useful for:</p> <ul> <li>Product / PM: understand artifacts, freshness, rollback</li> <li>Engineers: run locally, add artifact types, integrate storage</li> <li>Data Engineering: define event contracts, backfills, data quality</li> <li>SRE / Platform: operate daily runs, alert on freshness, handle incidents</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#how-it-fits-in-a-recommendation-stack","title":"How it fits in a recommendation stack","text":"<p>Typical stack (simplified):</p> <ul> <li><code>recsys-pipelines</code> (this repo): offline artifact builder</li> <li><code>recsys-algo</code>: ranking / scoring logic that consumes artifacts</li> <li><code>recsys-service</code>: online API that serves recommendations using the algo</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#mental-model-one-screen","title":"Mental model (one-screen)","text":"<p>Raw events (jsonl)    |    v Ingest + canonicalize (idempotent)    |    v Validate canonical data (gates)    |    v Compute artifacts (popularity, cooc, implicit, content_sim, session_seq)    |    v Stage artifacts (optional)    |    v Publish (atomic):</p> <ul> <li>write versioned blob</li> <li>write registry record</li> <li>update current manifest pointer</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#what-you-should-do-next","title":"What you should do next","text":"<ul> <li>Run locally: <code>tutorials/local-quickstart.md</code></li> <li>Understand artifacts: <code>explanation/artifacts-and-versioning.md</code></li> <li>Learn operations: <code>operations/slos-and-freshness.md</code></li> </ul> <p>If you are here because something broke, jump to:</p> <ul> <li><code>operations/runbooks/</code></li> </ul>"},{"location":"recsys-pipelines/docs/adr/","title":"Architecture Decision Records (ADR)","text":"<p>ADRs capture the \"why\" behind important decisions.</p> <p>Template: <code>adr/template.md</code></p> <p>When to add an ADR:</p> <ul> <li>new artifact type</li> <li>new storage backend (S3/GCS)</li> <li>change in windowing or versioning</li> <li>new validation policy</li> </ul>"},{"location":"recsys-pipelines/docs/adr/template/","title":"ADR-XXXX: <code>title</code>","text":"<p>Date: YYYY-MM-DD</p>"},{"location":"recsys-pipelines/docs/adr/template/#status","title":"Status","text":"<p>Proposed | Accepted | Deprecated | Superseded</p>"},{"location":"recsys-pipelines/docs/adr/template/#context","title":"Context","text":"<p>What problem are we solving?</p>"},{"location":"recsys-pipelines/docs/adr/template/#decision","title":"Decision","text":"<p>What did we decide?</p>"},{"location":"recsys-pipelines/docs/adr/template/#consequences","title":"Consequences","text":"<ul> <li>Positive</li> <li>Negative</li> <li>Neutral</li> </ul>"},{"location":"recsys-pipelines/docs/adr/template/#alternatives-considered","title":"Alternatives considered","text":"<p>List alternatives and why they were rejected.</p>"},{"location":"recsys-pipelines/docs/contributing/dev-workflow/","title":"Developer workflow","text":""},{"location":"recsys-pipelines/docs/contributing/dev-workflow/#local-commands","title":"Local commands","text":"<pre><code>make fmt\nmake test\nmake build\nmake smoke\n</code></pre>"},{"location":"recsys-pipelines/docs/contributing/dev-workflow/#code-structure-rules","title":"Code structure rules","text":"<ul> <li>Keep domain logic deterministic (no IO)</li> <li>Keep adapters behind ports</li> <li>Add unit tests for domain and usecases</li> </ul>"},{"location":"recsys-pipelines/docs/contributing/dev-workflow/#adding-docs","title":"Adding docs","text":"<p>Docs live under <code>docs/</code> and follow Diataxis.</p> <ul> <li>tutorials: <code>docs/tutorials/</code></li> <li>how-to: <code>docs/how-to/</code></li> <li>explanation: <code>docs/explanation/</code></li> <li>reference: <code>docs/reference/</code></li> </ul>"},{"location":"recsys-pipelines/docs/contributing/releasing/","title":"Releasing","text":"<p>This repo includes a <code>CHANGELOG.md</code> and uses tags for releases.</p> <p>Recommended practice:</p> <ul> <li>Keep a human-written changelog entry per release</li> <li>Use SemVer for tags</li> </ul> <p>Local build:</p> <pre><code>make build\n</code></pre>"},{"location":"recsys-pipelines/docs/contributing/style/","title":"Style guide","text":"<ul> <li>Keep comments ASCII.</li> <li>Prefer small focused packages.</li> <li>Avoid cleverness; optimize for readability.</li> <li>Keep public APIs minimal.</li> </ul> <p>Documentation:</p> <ul> <li>Prefer short sections.</li> <li>Use concrete examples.</li> <li>Explain the \"why\" in explanation docs.</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/architecture/","title":"Architecture","text":""},{"location":"recsys-pipelines/docs/explanation/architecture/#code-organization","title":"Code organization","text":"<ul> <li><code>internal/domain</code>: pure, deterministic domain logic</li> <li><code>internal/app/usecase</code>: orchestration of domain logic through ports</li> <li><code>internal/ports</code>: interfaces the app depends on</li> <li><code>internal/adapters</code>: IO implementations (filesystem, logging, etc.)</li> <li><code>cmd/*</code>: binaries (all-in-one CLI and job-per-step)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/architecture/#system-interactions-c4-inspired-ascii","title":"System interactions (C4-inspired, ASCII)","text":"<p>Level 1: context</p> <p>+---------------------+           +------------------+ |  Offline scheduler  |  runs     | recsys-pipelines | | (cron/airflow/k8s)  +----------&gt;+ (this repo)      | +---------------------+           +---------+--------+                                             |                                             | publishes                                             v                                     +-------+--------+                                     | Artifact store  |                                     | + Registry      |                                     +-------+--------+                                             |                                             | consumed by                                             v                                     +-------+--------+                                     | Online service  |                                     | (recsys-service)|                                     +-----------------+</p> <p>Level 2: containers within this repo</p> <ul> <li>CLI and jobs in <code>cmd/*</code></li> <li>Filesystem adapters</li> <li>Usecases (ingest/validate/compute/publish)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/architecture/#why-portsadapters","title":"Why ports/adapters","text":"<ul> <li>Keeps domain logic deterministic and testable</li> <li>Makes storage pluggable (filesystem now, S3/GCS later)</li> <li>Makes validation pluggable (builtin now, GE/dbt later)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/","title":"Artifacts and versioning","text":""},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#what-is-an-artifact","title":"What is an artifact?","text":"<p>A file (JSON) that the online recommender uses to make decisions quickly. Artifacts are precomputed offline so serving stays fast.</p>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#versioning","title":"Versioning","text":"<p>Artifacts are version-addressed:</p> <ul> <li>Compute the payload</li> <li>Remove volatile build metadata</li> <li>Hash the remaining JSON (SHA-256 hex)</li> <li>Embed the version into the final artifact</li> </ul> <p>If the canonical input does not change, the version should not change.</p>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#publishing-protocol-two-phase","title":"Publishing protocol (two-phase)","text":"<p>Publishing is ordered to keep serving safe:</p> <p>1) Write the versioned blob 1) Validate the artifact (including version recompute) 1) Write the version record 1) Swap the manifest pointer last</p> <p>This means a failed publish does not break \"current\".</p>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#rollback","title":"Rollback","text":"<p>Rollback is changing the manifest pointer to an older URI. The older versioned blob remains available.</p> <p>See <code>how-to/rollback-manifest.md</code>.</p>"},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/","title":"Data lifecycle","text":""},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/#stages","title":"Stages","text":"<ol> <li> <p>Raw events</p> </li> <li> <p>Input is JSON Lines files (jsonl)</p> </li> <li> <p>Schema: <code>schemas/events/exposure.v1.json</code></p> </li> <li> <p>Canonical events</p> </li> <li> <p>Stored per day (UTC) per tenant/surface</p> </li> <li> <p>Written idempotently (replace per partition)</p> </li> <li> <p>Validation</p> </li> <li> <p>Canonical is validated before any artifacts are computed/published</p> </li> <li> <p>Artifact compute</p> </li> <li> <p>popularity: counts by item</p> </li> <li> <p>cooc: session-level co-occurrence</p> </li> <li> <p>Staging (optional)</p> </li> <li> <p>Compute jobs can stage artifacts to <code>artifacts_dir</code></p> </li> <li> <p>Publish</p> </li> <li> <p>Versioned blob written to object store</p> </li> <li>Registry record written</li> <li>Current manifest pointer updated last</li> </ol>"},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/#why-canonicalization-exists","title":"Why canonicalization exists","text":"<ul> <li>Raw data is messy (missing fields, inconsistent formatting)</li> <li>Canonical events define a stable boundary</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/#why-validation-gates-exist","title":"Why validation gates exist","text":"<p>If you publish a bad artifact, you can degrade user experience immediately. Validation prevents \"bad data\" from reaching serving.</p>"},{"location":"recsys-pipelines/docs/explanation/documentation-approach/","title":"Documentation approach (Diataxis)","text":"<p>This documentation is organized around four different user needs:</p> <ul> <li>Tutorials: learn by doing</li> <li>How-to guides: solve a specific task</li> <li>Explanation: understand concepts and tradeoffs</li> <li>Reference: exact details</li> </ul> <p>This structure is based on the Diataxis documentation framework.</p>"},{"location":"recsys-pipelines/docs/explanation/validation-and-guardrails/","title":"Validation and guardrails","text":""},{"location":"recsys-pipelines/docs/explanation/validation-and-guardrails/#validation-gate","title":"Validation gate","text":"<p>The pipeline validates canonical data before computing/publishing.</p> <p>Builtin checks include:</p> <ul> <li>event parsing and required fields</li> <li>timestamp inside the window</li> <li>maximum events processed</li> <li>maximum distinct sessions/items</li> </ul> <p>Artifacts are also validated:</p> <ul> <li>correct type/version/window</li> <li>version matches recomputed hash</li> <li>maximum sizes (items/neighbors)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/validation-and-guardrails/#guardrails","title":"Guardrails","text":"<p>Resource limits protect the pipeline from unbounded inputs:</p> <ul> <li>max events per run</li> <li>max sessions per run</li> <li>max items per session</li> <li>max distinct items per run</li> <li>max neighbors per item</li> <li>max items per artifact</li> </ul> <p>If you see \"limit exceeded\", raise limits only after understanding why.</p> <p>Operational guidance: <code>operations/runbooks/limit-exceeded.md</code>.</p>"},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/","title":"Windows and backfills","text":""},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/#window-semantics","title":"Window semantics","text":"<p>This repo uses daily windows in UTC:</p> <ul> <li>A day window is [00:00, 24:00) UTC</li> <li>Backfills iterate start..end (inclusive end date)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/#why-daily-windows","title":"Why daily windows","text":"<ul> <li>Easy operational model</li> <li>Simple freshness SLOs</li> <li>Deterministic partitioning</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/#backfill-safety","title":"Backfill safety","text":"<p>Backfills should be safe because:</p> <ul> <li>canonical partitions are replaced idempotently</li> <li>publishing updates the pointer last</li> </ul> <p>Still, you should backfill gradually and watch limits.</p> <p>See <code>how-to/run-backfill.md</code>.</p>"},{"location":"recsys-pipelines/docs/how-to/add-artifact-type/","title":"How-to: Add a new artifact type","text":"<p>This repo uses ports/adapters and a workflow pipeline.</p>"},{"location":"recsys-pipelines/docs/how-to/add-artifact-type/#checklist","title":"Checklist","text":"<ol> <li> <p>Define the domain model</p> </li> <li> <p>Add a new <code>artifacts.Type</code> value</p> </li> <li> <p>Add a v1 model struct and constructor</p> </li> <li> <p>Implement a compute usecase</p> </li> <li> <p>IO via <code>datasource.CanonicalStore</code></p> </li> <li> <p>Deterministic version hash (exclude build info)</p> </li> <li> <p>Update validation</p> </li> <li> <p>Extend builtin validator: schema checks + version recompute</p> </li> <li> <p>Wire into workflow</p> </li> <li> <p>Add to <code>workflow.Pipeline.RunDay</code></p> </li> <li> <p>Add to job mode (compute job + publish job)</p> </li> <li> <p>Add reference docs</p> </li> <li> <p>Add schema under <code>schemas/artifacts/</code></p> </li> <li>Update <code>reference/output-layout.md</code></li> </ol>"},{"location":"recsys-pipelines/docs/how-to/add-artifact-type/#non-negotiables","title":"Non-negotiables","text":"<ul> <li>Deterministic output for same canonical inputs</li> <li>Bounded resource usage</li> <li>Publish pointer updated last</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/add-event-field/","title":"How-to: Add a new field to exposure events","text":""},{"location":"recsys-pipelines/docs/how-to/add-event-field/#rules","title":"Rules","text":"<ul> <li>Keep old readers working (backwards compatible)</li> <li>Do not reuse field meanings</li> <li>Update schema and examples</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/add-event-field/#steps","title":"Steps","text":"<p>1) Update JSON schema: <code>schemas/events/exposure.v1.json</code> 1) Update domain event struct: <code>internal/domain/events/exposure.go</code> 1) Update raw event decoder if needed 1) Update canonical writer/reader tests 1) Update docs: <code>reference/schemas-events.md</code></p>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/","title":"How-to: Debug a failed pipeline run","text":""},{"location":"recsys-pipelines/docs/how-to/debug-failures/#1-identify-the-step","title":"1) Identify the step","text":"<p>Look at logs for one of:</p> <ul> <li>ingest</li> <li>validate</li> <li>popularity</li> <li>cooc</li> <li>publish</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/#2-common-root-causes","title":"2) Common root causes","text":"<ul> <li>Input files missing or wrong path</li> <li>Bad JSON in raw event files</li> <li>Validation fails (out-of-window timestamps, too many events)</li> <li>Resource limit exceeded (sessions/items)</li> <li>Disk permission errors</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/#3-useful-commands","title":"3) Useful commands","text":"<pre><code># Re-run one day\n./bin/recsys-pipelines run --config configs/env/local.json --tenant demo \\\n  --surface home --start 2026-01-01 --end 2026-01-01\n\n# Check manifest\ncat .out/registry/current/demo/home/manifest.json\n\n# Inspect canonical files\nfind .out/canonical -type f | sort\n</code></pre>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/#4-if-publish-failed","title":"4) If publish failed","text":"<p>Publishing is ordered so that the manifest pointer updates last. This means serving should still point to the previous version.</p> <p>See <code>operations/runbooks/pipeline-failed.md</code>.</p>"},{"location":"recsys-pipelines/docs/how-to/rollback-manifest/","title":"How-to: Roll back to a previous artifact version","text":"<p>This repo intentionally separates:</p> <ul> <li>versioned blobs (immutable)</li> <li>a small manifest pointer (mutable)</li> </ul> <p>Rollback is therefore a pointer change.</p>"},{"location":"recsys-pipelines/docs/how-to/rollback-manifest/#local-filesystem-example","title":"Local filesystem example","text":"<p>1) Find previous versions:</p> <pre><code>ls -1 .out/registry/records/demo/home/popularity | head\nls -1 .out/registry/records/demo/home/cooc | head\n</code></pre> <p>1) Pick a version record and get its <code>URI</code>.</p> <p>1) Edit the manifest file:</p> <p><code>.out/registry/current/demo/home/manifest.json</code></p> <p>Change <code>current.popularity</code> and/or <code>current.cooc</code> to point to the older URIs.</p>"},{"location":"recsys-pipelines/docs/how-to/rollback-manifest/#production-guidance","title":"Production guidance","text":"<p>In production, implement a dedicated rollback command in your operator tooling that:</p> <ul> <li>validates the target blob exists</li> <li>writes an audit record</li> <li>swaps the pointer atomically</li> </ul> <p>See <code>explanation/artifacts-and-versioning.md</code>.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/","title":"How-to: Run a backfill safely","text":"<p>Backfills re-run the pipeline for a date range. This repo uses daily UTC windows and includes a maximum range limit.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#safe-approach","title":"Safe approach","text":"<p>1) Start small: one day. 1) Expand gradually. 1) Monitor validation and resource limits.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#using-the-all-in-one-cli","title":"Using the all-in-one CLI","text":"<pre><code>./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-07\n</code></pre>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#using-job-mode","title":"Using job mode","text":"<p>Run jobs for the same date range and publish last.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#notes","title":"Notes","text":"<ul> <li>End date is inclusive.</li> <li>Canonicalization is idempotent per day partition.</li> <li>Publishing updates the manifest pointer last.</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/run-incremental/","title":"How-to: Run incremental pipelines","text":"<p>Incremental runs use a checkpoint so you can process only new days.</p>"},{"location":"recsys-pipelines/docs/how-to/run-incremental/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>checkpoint_dir</code> configured (defaults to <code>.out/checkpoints</code>)</li> <li><code>raw_source</code> configured</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/run-incremental/#run","title":"Run","text":"<pre><code>recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --end 2026-02-01 \\\n  --incremental\n</code></pre> <p>First run: pass <code>--start</code> once to seed the checkpoint:</p> <pre><code>recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-07 \\\n  --incremental\n</code></pre> <p>After each successful day, the checkpoint is updated automatically.</p>"},{"location":"recsys-pipelines/docs/how-to/schedule-pipelines/","title":"How-to: Schedule pipelines with CronJob","text":"<p>This project ships CLI jobs; schedule them with Kubernetes CronJobs or system cron.</p>"},{"location":"recsys-pipelines/docs/how-to/schedule-pipelines/#example-kubernetes-cronjob","title":"Example Kubernetes CronJob","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: recsys-pipelines-nightly\nspec:\n  schedule: \"0 2 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: recsys-pipelines\n              image: ghcr.io/aatuh/recsys-pipelines:latest\n              args:\n                - \"run\"\n                - \"--config\"\n                - \"/etc/recsys/config.json\"\n                - \"--tenant\"\n                - \"demo\"\n                - \"--surface\"\n                - \"home\"\n                - \"--end\"\n                - \"2026-02-01\"\n                - \"--incremental\"\n              volumeMounts:\n                - name: recsys-config\n                  mountPath: /etc/recsys\n          restartPolicy: OnFailure\n          volumes:\n            - name: recsys-config\n              configMap:\n                name: recsys-pipelines-config\n</code></pre> <p>Use <code>--incremental</code> for daily runs and <code>--start/--end</code> for backfills.</p>"},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/","title":"Learning path: Data Engineering","text":""},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/#goals","title":"Goals","text":"<ul> <li>Understand event schemas and file layouts</li> <li>Run backfills safely</li> <li>Operate data quality gates</li> <li>Define evolution rules for new fields</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>reference/schemas-events.md</code> 1) <code>explanation/data-lifecycle.md</code> 1) <code>how-to/run-backfill.md</code> 1) <code>how-to/add-event-field.md</code> 1) <code>reference/output-layout.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/#key-practical-advice","title":"Key practical advice","text":"<ul> <li>Treat canonical events as the contract boundary.</li> <li>Keep schema evolution backwards compatible.</li> <li>Always validate before publishing.</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/engineer/","title":"Learning path: Engineers","text":""},{"location":"recsys-pipelines/docs/learning-paths/engineer/#goals","title":"Goals","text":"<ul> <li>Run the pipeline locally</li> <li>Understand code structure (ports/adapters/usecases)</li> <li>Add a new artifact type safely</li> <li>Debug failures</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/engineer/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>tutorials/local-quickstart.md</code> 1) <code>reference/cli.md</code> 1) <code>reference/config.md</code> 1) <code>explanation/architecture.md</code> 1) <code>how-to/add-artifact-type.md</code> 1) <code>contributing/dev-workflow.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/engineer/#golden-rules","title":"Golden rules","text":"<ul> <li>Domain must stay IO-free and deterministic.</li> <li>Publishing must be atomic.</li> <li>Every step must be safe to retry.</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/product/","title":"Learning path: Product / PM","text":""},{"location":"recsys-pipelines/docs/learning-paths/product/#what-you-care-about","title":"What you care about","text":"<ul> <li>What artifacts exist and what they mean</li> <li>How freshness works (daily windows)</li> <li>How to roll back if something goes wrong</li> <li>What \"data quality\" means in practice</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/product/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>start-here.md</code> 1) <code>explanation/artifacts-and-versioning.md</code> 1) <code>operations/slos-and-freshness.md</code> 1) <code>operations/runbooks/pipeline-failed.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/product/#key-concepts","title":"Key concepts","text":"<ul> <li>Artifacts are versioned and rollbackable because production needs safe</li> </ul> <p>recovery.</p> <ul> <li>Manifest pointers are updated last so serving never points to missing blobs.</li> <li>Validation gates exist to prevent bad artifacts from reaching users.</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/product/#practical-questions-and-where-answered","title":"Practical questions (and where answered)","text":"<ul> <li>\"How often do recommendations update?\"</li> <li><code>operations/slos-and-freshness.md</code></li> <li>\"Can we revert to yesterday's artifact?\"</li> <li><code>how-to/rollback-manifest.md</code></li> <li>\"What if data is missing for a day?\"</li> <li><code>explanation/data-lifecycle.md</code></li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/","title":"Learning path: SRE / On-call","text":""},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/#goals","title":"Goals","text":"<ul> <li>Know what \"healthy\" looks like</li> <li>Detect stale artifacts</li> <li>Triage failures quickly</li> <li>Roll back safely</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>operations/slos-and-freshness.md</code> 1) <code>operations/runbooks/pipeline-failed.md</code> 1) <code>operations/runbooks/stale-artifacts.md</code> 1) <code>operations/runbooks/limit-exceeded.md</code> 1) <code>how-to/rollback-manifest.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/#what-to-alert-on","title":"What to alert on","text":"<ul> <li>No successful publish within expected window (freshness)</li> <li>Validation failures</li> <li>Limit exceeded errors (resource protection)</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/","title":"SLOs and freshness","text":""},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#freshness-definition","title":"Freshness definition","text":"<p>A surface is \"fresh\" if the manifest for (tenant, surface) was updated within an expected time window.</p> <p>Example daily schedule:</p> <ul> <li>Run for previous UTC day at 01:00 UTC</li> <li>Expect publish to finish by 01:30 UTC</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#what-to-measure","title":"What to measure","text":"<p>At minimum:</p> <ul> <li>last successful publish timestamp per tenant/surface</li> <li>validation failures count</li> <li>limit exceeded failures count</li> <li>runtime per job</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#alert-suggestions","title":"Alert suggestions","text":"<ul> <li>Stale manifest: no update within 2x schedule interval</li> <li>Persistent validation failures</li> <li>Persistent limit exceeded</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#where-to-find-the-signal-in-local-mode","title":"Where to find the signal in local mode","text":"<ul> <li>Manifest <code>updated_at</code>:</li> </ul> <p><code>.out/registry/current/&lt;tenant&gt;/&lt;surface&gt;/manifest.json</code></p>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/","title":"Runbook: Limit exceeded","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#symptoms","title":"Symptoms","text":"<ul> <li>Error message includes \"limit exceeded\"</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#why-this-exists","title":"Why this exists","text":"<p>Limits prevent resource blowups from pathological inputs. Raising limits blindly can cause OOM or slowdowns.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#triage","title":"Triage","text":"<p>1) Identify which limit triggered (events/sessions/items/neighbors) 1) Inspect raw event volume for the window 1) Look for data bugs (duplicate events, runaway session ids)</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#recovery","title":"Recovery","text":"<ul> <li>Fix upstream data if it's a bug</li> <li>For genuine growth, raise limits gradually and benchmark</li> </ul> <p>See <code>reference/config.md</code> and <code>explanation/validation-and-guardrails.md</code>.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/","title":"Runbook: Pipeline failed","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#symptoms","title":"Symptoms","text":"<ul> <li><code>recsys-pipelines run</code> exits non-zero</li> <li>job binary exits non-zero</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#immediate-safety-check","title":"Immediate safety check","text":"<p>Publishing updates the manifest pointer last. If publish failed mid-run, serving should still point to the previous version.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#triage-checklist","title":"Triage checklist","text":"<p>1) Identify which step failed (logs): ingest / validate / compute / publish 1) Check disk paths and permissions 1) Check raw input presence and format 1) If validation failed, inspect the reported rule 1) If limit exceeded, see <code>runbooks/limit-exceeded.md</code></p>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#recovery","title":"Recovery","text":"<ul> <li>Fix root cause</li> <li>Re-run the affected day only</li> <li>If publish already updated to a bad version, roll back the manifest</li> </ul> <p>See <code>how-to/rollback-manifest.md</code>.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/","title":"Runbook: Stale artifacts","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/#symptoms","title":"Symptoms","text":"<ul> <li>Manifest <code>updated_at</code> is older than expected</li> <li>Serving still uses old URIs</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/#triage","title":"Triage","text":"<p>1) Confirm scheduler ran 1) Confirm pipeline completed successfully 1) Check for validation failures or limit exceeded</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/#recovery","title":"Recovery","text":"<ul> <li>Re-run the missing day</li> <li>If inputs are missing, decide whether to publish empty artifacts or skip</li> </ul> <p>See <code>how-to/run-backfill.md</code>.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/","title":"Runbook: Validation failed","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/#symptoms","title":"Symptoms","text":"<ul> <li>Pipeline stops before publish</li> <li>Error indicates validation failure</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/#common-causes","title":"Common causes","text":"<ul> <li>Events outside the window (timestamp issues)</li> <li>Bad JSON / schema mismatch</li> <li>Unexpected spike/drop in event volume</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/#recovery","title":"Recovery","text":"<ul> <li>Fix data at source if possible</li> <li>Re-run the affected day</li> <li>If needed, roll back serving to previous artifacts</li> </ul> <p>See <code>explanation/data-lifecycle.md</code>.</p>"},{"location":"recsys-pipelines/docs/reference/cli/","title":"CLI reference","text":""},{"location":"recsys-pipelines/docs/reference/cli/#recsys-pipelines","title":"recsys-pipelines","text":"<p>Commands:</p> <ul> <li><code>run</code> : ingest + validate + compute + publish</li> <li><code>version</code></li> </ul>"},{"location":"recsys-pipelines/docs/reference/cli/#run","title":"run","text":"<pre><code>recsys-pipelines run \\\n  --config &lt;path&gt; \\\n  --tenant &lt;tenant&gt; \\\n  --surface &lt;surface&gt; \\\n  --segment &lt;segment optional&gt; \\\n  --start YYYY-MM-DD \\\n  --end YYYY-MM-DD\n</code></pre> <p>Notes:</p> <ul> <li>end date is inclusive</li> <li>windows are daily UTC</li> </ul> <p>Incremental (checkpointed) example:</p> <pre><code>recsys-pipelines run \\\n  --config &lt;path&gt; \\\n  --tenant &lt;tenant&gt; \\\n  --surface &lt;surface&gt; \\\n  --end YYYY-MM-DD \\\n  --incremental\n</code></pre>"},{"location":"recsys-pipelines/docs/reference/cli/#job-binaries","title":"Job binaries","text":"<p>All jobs take <code>--config --tenant --surface --start --end</code>. Some also take <code>--segment</code> or extra inputs.</p> <ul> <li><code>job_ingest</code></li> <li><code>job_validate</code></li> <li><code>job_popularity</code> (segment optional)</li> <li><code>job_cooc</code> (segment optional)</li> <li><code>job_implicit</code> (segment optional)</li> <li><code>job_content_sim</code> (segment optional, requires <code>--input</code>)</li> <li><code>job_session_seq</code> (segment optional)</li> <li><code>job_publish</code> (segment optional)</li> </ul> <p><code>job_content_sim</code> usage:</p> <pre><code>job_content_sim \\\n  --config &lt;path&gt; \\\n  --tenant &lt;tenant&gt; \\\n  --surface &lt;surface&gt; \\\n  --input &lt;catalog.csv|catalog.jsonl&gt; \\\n  --start YYYY-MM-DD \\\n  --end YYYY-MM-DD\n</code></pre>"},{"location":"recsys-pipelines/docs/reference/config/","title":"Config reference","text":"<p>Config is JSON. Example: <code>configs/env/local.json</code>.</p> <p>Top-level fields:</p> <ul> <li><code>out_dir</code>: base output directory (local runs)</li> <li><code>raw_events_dir</code>: input events directory</li> <li><code>canonical_dir</code>: canonical output directory</li> <li><code>checkpoint_dir</code>: checkpoint storage for incremental runs</li> <li><code>raw_source</code>: raw ingestion source configuration</li> <li><code>artifacts_dir</code>: staging directory (job mode and pipeline staging)</li> <li><code>object_store_dir</code>: where published blobs are written (local fs mode)</li> <li><code>object_store</code>: object store configuration (fs or s3/minio)</li> <li><code>registry_dir</code>: where manifests and records are written</li> <li><code>db</code>: optional Postgres connection for DB-backed signals</li> </ul>"},{"location":"recsys-pipelines/docs/reference/config/#object_store","title":"object_store","text":"<pre><code>{\n  \"type\": \"fs | s3 | minio\",\n  \"dir\": \".out/objectstore\",\n  \"s3\": {\n    \"endpoint\": \"localhost:9000\",\n    \"bucket\": \"recsys-artifacts\",\n    \"access_key\": \"minioadmin\",\n    \"secret_key\": \"minioadmin\",\n    \"prefix\": \"recsys\",\n    \"use_ssl\": false\n  }\n}\n</code></pre>"},{"location":"recsys-pipelines/docs/reference/config/#db","title":"db","text":"<pre><code>{\n  \"dsn\": \"postgres://user:pass@localhost:5432/db?sslmode=disable\",\n  \"auto_create_tenant\": true,\n  \"statement_timeout_s\": 5\n}\n</code></pre>"},{"location":"recsys-pipelines/docs/reference/config/#limits","title":"limits","text":"<ul> <li><code>max_days_backfill</code></li> <li><code>max_events_per_run</code></li> <li><code>max_sessions_per_run</code></li> <li><code>max_items_per_session</code></li> <li><code>max_distinct_items_per_run</code></li> <li><code>max_neighbors_per_item</code></li> <li><code>max_items_per_artifact</code></li> <li><code>min_cooc_support</code></li> <li><code>max_users_per_run</code></li> <li><code>max_items_per_user</code></li> </ul> <p>See <code>explanation/validation-and-guardrails.md</code>.</p>"},{"location":"recsys-pipelines/docs/reference/config/#raw_source","title":"raw_source","text":"<pre><code>{\n  \"type\": \"fs | s3 | minio | postgres | kafka\",\n  \"dir\": \"testdata/events\",\n  \"s3\": {\n    \"endpoint\": \"localhost:9000\",\n    \"bucket\": \"recsys-raw\",\n    \"access_key\": \"minioadmin\",\n    \"secret_key\": \"minioadmin\",\n    \"prefix\": \"raw/events\",\n    \"use_ssl\": false\n  },\n  \"postgres\": {\n    \"dsn\": \"postgres://user:pass@localhost:5432/db?sslmode=disable\",\n    \"tenant_table\": \"tenants\",\n    \"exposure_table\": \"exposure_events\"\n  },\n  \"kafka\": {\n    \"brokers\": [\"localhost:9092\"],\n    \"topic\": \"recsys-exposures\",\n    \"group_id\": \"recsys-pipelines\"\n  }\n}\n</code></pre> <p>Note: the Kafka connector is scaffolded and returns a clear error until it is implemented with a streaming consumer.</p>"},{"location":"recsys-pipelines/docs/reference/exit-codes/","title":"Exit codes","text":"<p>This repo uses conventional exit codes:</p> <ul> <li>0: success</li> <li>1: runtime failure (pipeline step failed)</li> <li>2: usage/config error (missing flags, invalid config)</li> </ul> <p>Job binaries follow the same pattern.</p>"},{"location":"recsys-pipelines/docs/reference/output-layout/","title":"Output layout (local filesystem)","text":"<p>With default local config, outputs go under <code>.out/</code>.</p>"},{"location":"recsys-pipelines/docs/reference/output-layout/#canonical","title":"Canonical","text":"<p><code>.out/canonical/&lt;tenant&gt;/&lt;surface&gt;/exposures/YYYY-MM-DD.jsonl</code></p>"},{"location":"recsys-pipelines/docs/reference/output-layout/#staged-artifacts","title":"Staged artifacts","text":"<p><code>.out/artifacts/&lt;tenant&gt;/&lt;surface&gt;/&lt;segment&gt;/&lt;type&gt;/&lt;start&gt;_&lt;end&gt;/</code></p> <ul> <li><code>&lt;version&gt;.json</code></li> <li><code>current.version</code></li> </ul>"},{"location":"recsys-pipelines/docs/reference/output-layout/#object-store","title":"Object store","text":"<p><code>.out/objectstore/&lt;tenant&gt;/&lt;surface&gt;/&lt;kind&gt;/&lt;version&gt;.json</code></p>"},{"location":"recsys-pipelines/docs/reference/output-layout/#registry","title":"Registry","text":"<p>Current manifest:</p> <ul> <li><code>.out/registry/current/&lt;tenant&gt;/&lt;surface&gt;/manifest.json</code></li> </ul> <p>Version records:</p> <ul> <li><code>.out/registry/records/&lt;tenant&gt;/&lt;surface&gt;/&lt;type&gt;/&lt;version&gt;.json</code></li> </ul>"},{"location":"recsys-pipelines/docs/reference/output-layout/#notes","title":"Notes","text":"<ul> <li>Records are append-only and version-addressed.</li> <li>Manifest points to URIs (<code>file://...</code> in local mode).</li> </ul>"},{"location":"recsys-pipelines/docs/reference/schemas-artifacts/","title":"Artifact schemas","text":"<p>Artifacts are JSON documents intended for serving systems.</p> <p>Currently:</p> <ul> <li>Popularity artifact v1</li> <li>Co-occurrence artifact v1</li> <li>Implicit artifact v1 (collaborative)</li> <li>Content similarity artifact v1</li> <li>Session sequence artifact v1</li> <li>Manifest v1</li> </ul> <p>Schemas:</p> <ul> <li><code>schemas/artifacts/manifest.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/popularity.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/cooc.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/implicit.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/content_sim.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/session_seq.v1.json</code></li> </ul> <p>The builtin validator enforces structural rules. See <code>explanation/artifacts-and-versioning.md</code>.</p>"},{"location":"recsys-pipelines/docs/reference/schemas-events/","title":"Event schemas","text":""},{"location":"recsys-pipelines/docs/reference/schemas-events/#exposureeventv1","title":"ExposureEventV1","text":"<p>Schema file:</p> <ul> <li><code>schemas/events/exposure.v1.json</code></li> </ul> <p>Format:</p> <ul> <li>JSON Lines (one JSON object per line)</li> </ul> <p>Required fields:</p> <ul> <li><code>v</code>: must be 1</li> <li><code>ts</code>: RFC3339 timestamp</li> <li><code>tenant</code>: string</li> <li><code>surface</code>: string</li> <li><code>session_id</code>: string</li> <li><code>item_id</code>: string</li> </ul> <p>Optional fields:</p> <ul> <li><code>user_id</code></li> <li><code>request_id</code></li> <li><code>rank</code></li> </ul> <p>See also: <code>testdata/events/</code>.</p>"},{"location":"recsys-pipelines/docs/tutorials/job-mode/","title":"Tutorial: Run in job-per-step mode","text":"<p>Some teams prefer orchestration where each step runs as a separate job (Airflow, K8s CronJobs, etc.). This repo includes job binaries:</p> <ul> <li><code>job_ingest</code></li> <li><code>job_validate</code></li> <li><code>job_popularity</code></li> <li><code>job_cooc</code></li> <li><code>job_publish</code></li> </ul>"},{"location":"recsys-pipelines/docs/tutorials/job-mode/#example-one-day","title":"Example: one day","text":"<pre><code>make build\n\n./bin/job_ingest --config configs/env/local.json --tenant demo --surface home \\\n  --start 2026-01-01 --end 2026-01-01\n\n./bin/job_validate --config configs/env/local.json --tenant demo --surface home \\\n  --start 2026-01-01 --end 2026-01-01\n\n./bin/job_popularity --config configs/env/local.json --tenant demo --surface home \\\n  --segment '' --start 2026-01-01 --end 2026-01-01\n\n./bin/job_cooc --config configs/env/local.json --tenant demo --surface home \\\n  --segment '' --start 2026-01-01 --end 2026-01-01\n\n./bin/job_publish --config configs/env/local.json --tenant demo --surface home \\\n  --segment '' --start 2026-01-01 --end 2026-01-01\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/job-mode/#why-split-jobs","title":"Why split jobs?","text":"<ul> <li>Different compute profiles per step</li> <li>Independent retries</li> <li>Separate scaling policies</li> </ul> <p>Next: <code>operations/slos-and-freshness.md</code>.</p>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/","title":"Tutorial: Run locally (filesystem mode)","text":"<p>This tutorial assumes you want to run the pipeline on the included tiny dataset.</p>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#1-build","title":"1) Build","text":"<pre><code>make test\nmake build\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#2-run-one-day","title":"2) Run one day","text":"<pre><code>./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-01\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#3-inspect-outputs","title":"3) Inspect outputs","text":"<pre><code>find .out -type f | sort\ncat .out/registry/current/demo/home/manifest.json\n</code></pre> <p>You should see:</p> <ul> <li>canonical events under <code>.out/canonical/demo/home/exposures/</code></li> <li>versioned blobs under <code>.out/objectstore/demo/home/...</code></li> <li>a manifest pointer under <code>.out/registry/current/demo/home/manifest.json</code></li> </ul>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#4-prove-idempotency","title":"4) Prove idempotency","text":"<p>Run the same command again. Output should not change.</p> <p>A smoke script exists:</p> <pre><code>make smoke\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#what-you-learned","title":"What you learned","text":"<ul> <li>How to build and run the pipeline locally</li> <li>Where the outputs land</li> <li>Why reruns are safe</li> </ul> <p>Next: <code>tutorials/job-mode.md</code> or <code>explanation/artifacts-and-versioning.md</code>.</p>"},{"location":"reference/api/admin/","title":"Admin API + local bootstrap (recsys-service)","text":"<p>This page documents the admin/control-plane endpoints and the minimum bootstrap steps required to call <code>/v1/recommend</code> and <code>/v1/similar</code>.</p> <p>Why this exists:</p> <ul> <li>The OpenAPI file (<code>reference/api/openapi.yaml</code>) documents the HTTP surface.</li> <li>This page adds bootstrap guidance, examples, and operational notes for admin/control-plane usage.</li> </ul>"},{"location":"reference/api/admin/#0-prereqs","title":"0) Prereqs","text":"<ul> <li>Postgres is running and migrations are applied.</li> <li>recsys-service is running and reachable (e.g. <code>http://localhost:8000</code>).</li> </ul>"},{"location":"reference/api/admin/#1-create-a-tenant-row-db-bootstrap","title":"1) Create a tenant row (DB bootstrap)","text":"<p>Admin endpoints require a tenant record in <code>tenants</code>. There is no admin API to create tenants yet, so insert directly in Postgres:</p> <pre><code>insert into tenants (external_id, name)\nvalues ('demo', 'Demo Tenant')\non conflict (external_id) do nothing;\n</code></pre> <p>Notes:</p> <ul> <li><code>external_id</code> should match the tenant/org claim in your JWT, or the dev tenant</li> </ul> <p>header value (see below).</p> <ul> <li>You can also use the tenant UUID in admin paths; <code>external_id</code> is preferred.</li> </ul>"},{"location":"reference/api/admin/#2-auth-tenancy-local-dev","title":"2) Auth + tenancy (local dev)","text":"<p>Local dev can use dev headers instead of JWT:</p> <p>Set in <code>.env</code>:</p> <pre><code>AUTH_REQUIRED=true\nAUTH_REQUIRE_TENANT_CLAIM=false\nDEV_AUTH_ENABLED=true\nDEV_AUTH_USER_ID_HEADER=X-Dev-User-Id\nDEV_AUTH_TENANT_HEADER=X-Dev-Org-Id\nAUTH_ADMIN_ROLE=   # empty to disable admin role checks locally\n</code></pre> <p>Then send headers on every request:</p> <pre><code>X-Dev-User-Id: dev-user-1\nX-Dev-Org-Id: demo\nX-Org-Id: demo   # must match tenant scope\n</code></pre> <p>Why two tenant headers?</p> <ul> <li><code>X-Dev-Org-Id</code> is used to derive tenant context in local/dev mode.</li> <li><code>X-Org-Id</code> is the tenant header enforced by the tenant middleware.</li> </ul> <p>Tip (single header in local dev):</p> <ul> <li>Set <code>DEV_AUTH_TENANT_HEADER=X-Org-Id</code> to use one header for both dev auth</li> </ul> <p>and tenant scope.</p> <p>If you prefer JWT:</p> <ul> <li>Provide a bearer token with a tenant claim (see <code>AUTH_TENANT_CLAIMS</code>).</li> <li>Include an admin role (default <code>admin</code>) under a role claim (see</li> </ul> <p><code>AUTH_ROLE_CLAIMS</code>) to access admin endpoints.</p> <p>RBAC roles (JWT or API keys):</p> <ul> <li><code>viewer</code>: read-only admin access (GET config/rules/audit).</li> <li><code>operator</code>: config/rules updates + cache invalidation.</li> <li><code>admin</code>: full admin access (includes operator + viewer).</li> </ul>"},{"location":"reference/api/admin/#3-admin-endpoints","title":"3) Admin endpoints","text":"<p>All admin endpoints are under <code>/v1/admin</code>.</p> <p>The <code>tenant_id</code> path parameter accepts external_id or UUID.</p>"},{"location":"reference/api/admin/#get-v1admintenantstenant_idconfig","title":"GET /v1/admin/tenants/{tenant_id}/config","text":"<p>Returns current tenant config and <code>config_version</code>.</p>"},{"location":"reference/api/admin/#put-v1admintenantstenant_idconfig","title":"PUT /v1/admin/tenants/{tenant_id}/config","text":"<p>Updates tenant config (optimistic concurrency).</p> <p>Headers:</p> <ul> <li><code>If-Match</code>: optional. Use the <code>config_version</code> from the latest GET response.</li> </ul> <p>Omit for the first insert.</p> <p>Payload (minimal example):</p> <pre><code>{\n  \"weights\": { \"pop\": 0.7, \"cooc\": 0.2, \"emb\": 0.1 },\n  \"flags\": { \"enable_rules\": true },\n  \"limits\": { \"max_k\": 50, \"max_exclude_ids\": 200 }\n}\n</code></pre> <p>Validation notes:</p> <ul> <li>weights must be non\u2011negative</li> <li>limits must be non\u2011negative</li> </ul> <p>Common config keys (current behavior):</p> <ul> <li><code>weights.pop</code>, <code>weights.cooc</code>, <code>weights.emb</code></li> <li><code>flags</code> (boolean map, free-form)</li> <li><code>limits.max_k</code>, <code>limits.max_exclude_ids</code></li> </ul>"},{"location":"reference/api/admin/#get-v1admintenantstenant_idrules","title":"GET /v1/admin/tenants/{tenant_id}/rules","text":"<p>Returns current tenant rules and <code>rules_version</code>.</p>"},{"location":"reference/api/admin/#put-v1admintenantstenant_idrules","title":"PUT /v1/admin/tenants/{tenant_id}/rules","text":"<p>Updates tenant rules (optimistic concurrency).</p> <p>Headers:</p> <ul> <li><code>If-Match</code>: optional. Use the <code>rules_version</code> from the latest GET response.</li> </ul> <p>Omit for the first insert.</p> <p>Payload (minimal example array):</p> <pre><code>[\n  {\n    \"action\": \"pin\",\n    \"target_type\": \"item\",\n    \"item_ids\": [\"item_1\", \"item_2\"],\n    \"surface\": \"home\",\n    \"priority\": 10\n  },\n  {\n    \"action\": \"block\",\n    \"target_type\": \"tag\",\n    \"target_key\": \"brand:nike\"\n  }\n]\n</code></pre> <p>Supported actions: <code>pin</code>, <code>boost</code>, <code>block</code> (aliases allowed: <code>promote</code>, <code>exclude</code>, etc). Supported targets: <code>item</code>, <code>tag</code>, <code>brand</code>, <code>category</code>.</p> <p>Common rule keys (current parser):</p> <ul> <li><code>action</code>: <code>pin</code> | <code>boost</code> | <code>block</code></li> <li><code>target_type</code>: <code>item</code> | <code>tag</code> | <code>brand</code> | <code>category</code></li> <li><code>target_key</code>: string (for tag/brand/category)</li> <li><code>item_ids</code>: array of item ids (for item targeting)</li> <li><code>namespace</code> (optional), <code>surface</code> (optional), <code>segment</code> (optional)</li> <li><code>priority</code> (int), <code>enabled</code> (bool)</li> <li><code>valid_from</code>, <code>valid_until</code> (RFC3339 timestamps)</li> <li><code>boost_value</code> (number, when <code>action=boost</code>)</li> <li><code>max_pins</code> (int, when <code>action=pin</code>)</li> </ul>"},{"location":"reference/api/admin/#post-v1admintenantstenant_idcacheinvalidate","title":"POST /v1/admin/tenants/{tenant_id}/cache/invalidate","text":"<p>Payload:</p> <pre><code>{ \"targets\": [\"config\", \"rules\"], \"surface\": \"home\" }\n</code></pre> <p>Valid targets: <code>config</code>, <code>rules</code>, <code>popularity</code>.</p> <p>Notes:</p> <ul> <li><code>surface</code> is optional. If provided, invalidation is scoped to that surface.</li> <li><code>popularity</code> invalidates artifact/manifest caches (no\u2011op in DB\u2011only mode).</li> </ul>"},{"location":"reference/api/admin/#get-v1admintenantstenant_idaudit","title":"GET /v1/admin/tenants/{tenant_id}/audit","text":"<p>Returns recent audit log entries for admin actions (write operations).</p> <p>Query parameters:</p> <ul> <li><code>limit</code> (optional, default 100, max 200)</li> <li><code>before</code> (optional, RFC3339 timestamp for pagination)</li> <li><code>before_id</code> (optional, numeric id for pagination tie\u2011break)</li> </ul> <p>Example:</p> <pre><code>GET /v1/admin/tenants/demo/audit?limit=50\n</code></pre> <p>Response includes <code>entries</code> and optional <code>next_before</code>/<code>next_before_id</code> cursor.</p>"},{"location":"reference/api/admin/#4-call-the-api","title":"4) Call the API","text":"<p>Once config and rules exist, you can call <code>/v1/recommend</code> or <code>/v1/similar</code> using the same tenant headers/token.</p> <p>See also:</p> <ul> <li><code>reference/api/examples/admin-config.http</code></li> <li><code>tutorials/local-end-to-end.md</code></li> </ul>"},{"location":"reference/api/api-reference/","title":"API Reference","text":"<p>This page is the integration hub for <code>recsys-service</code>:</p> <ul> <li>Full schema: <code>openapi.yaml</code></li> <li>Practical examples: <code>examples.md</code></li> <li>Error handling &amp; troubleshooting: <code>errors.md</code></li> <li>Admin/control-plane + local bootstrap: <code>admin.md</code></li> </ul>"},{"location":"reference/api/api-reference/#base-url-and-versioning","title":"Base URL and versioning","text":"<ul> <li>All API endpoints are under <code>/v1</code>.</li> <li>Health endpoints:</li> <li><code>/healthz</code> (liveness)</li> <li><code>/readyz</code> (readiness)</li> <li><code>/health/detailed</code> (debugging)</li> </ul>"},{"location":"reference/api/api-reference/#auth-and-tenancy-high-level","title":"Auth and tenancy (high level)","text":"<p>The service supports:</p> <ul> <li><code>Authorization: Bearer &lt;token&gt;</code> (JWT)</li> <li><code>X-API-Key: &lt;key&gt;</code> (API keys)</li> </ul> <p>Local development can also use dev headers (see <code>admin.md</code>).</p> <p>Tenant scope:</p> <ul> <li>In production, tenant context typically comes from a JWT claim (see <code>AUTH_TENANT_CLAIMS</code>).</li> <li>When tenant scope is not derived from auth, send the tenant header (default <code>X-Org-Id</code>).</li> </ul>"},{"location":"reference/api/api-reference/#requestresponse-conventions","title":"Request/response conventions","text":"<ul> <li>Requests and responses use JSON.</li> <li>Recommendation responses include <code>meta</code>:</li> <li><code>config_version</code>, <code>rules_version</code> (ETags derived from JSON payloads)</li> <li><code>algo_version</code> (effective algorithm version label)</li> <li><code>request_id</code> (for support and log correlation)</li> <li>Responses may include non-fatal <code>warnings[]</code> (for example: missing signals or filtered candidates).</li> </ul>"},{"location":"reference/api/api-reference/#versioning","title":"Versioning","text":"<ul> <li>Endpoints are versioned via the <code>/v1</code> path prefix.</li> <li>When you integrate, treat the response body as the contract (don\u2019t depend on field ordering).</li> </ul>"},{"location":"reference/api/api-reference/#retries-and-idempotency","title":"Retries and idempotency","text":"<ul> <li><code>POST /v1/recommend</code> and <code>POST /v1/similar</code> are read-only, but may have side effects (for example: exposure logging).</li> <li>If you implement retries, ensure your integration does not accidentally double-count events downstream.</li> </ul>"},{"location":"reference/api/api-reference/#errors","title":"Errors","text":"<p>Errors use Problem Details with content type <code>application/problem+json</code>.</p> <p>Common status codes you should handle:</p> <ul> <li><code>400</code> invalid JSON</li> <li><code>401/403</code> auth or scope failure</li> <li><code>409</code> optimistic concurrency conflict (<code>If-Match</code> mismatch)</li> <li><code>422</code> validation failure (semantically invalid request)</li> <li><code>429</code> rate limit</li> <li><code>503</code> overloaded or not ready</li> </ul>"},{"location":"reference/api/api-reference/#swagger-ui","title":"Swagger UI","text":""},{"location":"reference/api/errors/","title":"Error handling &amp; troubleshooting API calls","text":""},{"location":"reference/api/errors/#who-this-is-for","title":"Who this is for","text":"<p>Integrators and on-call engineers who need to diagnose failed requests quickly and safely.</p>"},{"location":"reference/api/errors/#what-you-will-get","title":"What you will get","text":"<ul> <li>The error format (<code>application/problem+json</code>)</li> <li>What the common HTTP status codes mean in this service</li> <li>Endpoint-specific \u201cwhat to do next\u201d</li> </ul>"},{"location":"reference/api/errors/#error-format-problem-details","title":"Error format (Problem Details)","text":"<p>Errors use RFC 7807 with content type <code>application/problem+json</code>.</p> <p>Typical fields:</p> <ul> <li><code>type</code>, <code>title</code>, <code>status</code> (always present)</li> <li><code>detail</code> (human-readable explanation; should be safe to show to end users)</li> <li><code>code</code> (machine-readable error category, when available)</li> <li><code>request_id</code> (for correlation)</li> </ul> <p>Example:</p> <pre><code>{\n  \"type\": \"about:blank\",\n  \"title\": \"validation failed\",\n  \"status\": 422,\n  \"detail\": \"surface is required\",\n  \"code\": \"VALIDATION_FAILED\",\n  \"request_id\": \"a2e38779dfbe/nmiLt982Mq-000004\"\n}\n</code></pre> <p>Operational tip: include <code>request_id</code> in client logs and support tickets. It is the fastest way to find the matching server log line.</p>"},{"location":"reference/api/errors/#common-status-codes-what-to-do","title":"Common status codes (what to do)","text":"<ul> <li>400: invalid JSON or wrong content type</li> <li>Check you send <code>Content-Type: application/json</code> and valid JSON.</li> <li>401/403: authentication/authorization/tenant scope failure</li> <li>Check auth headers, tenant header (<code>X-Org-Id</code>), and role requirements for admin endpoints.</li> <li>404 (admin endpoints): tenant not found</li> <li>Tenant creation is DB-only today; see <code>reference/api/admin.md</code> and     <code>start-here/known-limitations.md</code>.</li> <li>409 (admin <code>PUT</code>): optimistic concurrency conflict</li> <li>Fetch the latest resource, take its ETag, and retry with <code>If-Match</code>.</li> <li>422: validation failure (semantically invalid request)</li> <li>Call <code>POST /v1/recommend/validate</code> to see the normalized request + warnings.</li> <li>429: rate limited</li> <li>Back off and retry. If this is unexpected, review per-tenant rate limits.</li> <li>503: not ready / overloaded</li> <li>Check <code>GET /readyz</code> and verify dependencies (DB, artifact store if enabled).</li> <li>500: internal error</li> <li>Use <code>request_id</code> to locate server logs; follow the relevant runbook.</li> </ul>"},{"location":"reference/api/errors/#endpoint-notes","title":"Endpoint notes","text":""},{"location":"reference/api/errors/#post-v1recommend-and-post-v1similar","title":"<code>POST /v1/recommend</code> (and <code>POST /v1/similar</code>)","text":"<p>Expected error responses (see OpenAPI):</p> <ul> <li><code>400</code>, <code>401</code>, <code>403</code>, <code>422</code>, <code>429</code>, <code>500</code>, <code>503</code></li> </ul> <p>What to do first:</p> <ol> <li>Call <code>POST /v1/recommend/validate</code> with the same payload to surface normalization and warnings.</li> <li>Confirm tenant scope (JWT claims or <code>X-Org-Id</code> header).</li> <li>If you see empty results, use the \u201cempty recs\u201d runbook:    <code>operations/runbooks/empty-recs.md</code></li> </ol>"},{"location":"reference/api/errors/#post-v1recommendvalidate","title":"<code>POST /v1/recommend/validate</code>","text":"<p>This endpoint is your fastest \u201cis my request shape sane?\u201d tool.</p> <p>Expected error responses:</p> <ul> <li><code>400</code>, <code>401</code>, <code>403</code>, <code>422</code>, <code>429</code></li> </ul> <p>If you get <code>422</code>, fix the request payload before calling <code>/v1/recommend</code>.</p>"},{"location":"reference/api/errors/#admin-endpoints-v1admin","title":"Admin endpoints (<code>/v1/admin/...</code>)","text":"<p>These endpoints are for operators (config, rules, cache invalidation, audit).</p> <p>Common pitfalls:</p> <ul> <li><code>401/403</code>: missing operator/admin privileges (or dev auth is not enabled)</li> <li><code>409</code> on <code>PUT</code>: you updated with a stale version; retry with the latest <code>If-Match</code></li> <li><code>404</code>: tenant does not exist (bootstrap is DB-first today)</li> </ul> <p>See: <code>reference/api/admin.md</code></p>"},{"location":"reference/api/errors/#health-endpoints-get-healthz-get-readyz","title":"Health endpoints (<code>GET /healthz</code>, <code>GET /readyz</code>)","text":"<ul> <li><code>/healthz</code> is a liveness probe (is the process up?)</li> <li><code>/readyz</code> is a readiness probe (are dependencies reachable?)</li> </ul> <p>If <code>/readyz</code> returns <code>503</code>, use the \u201cservice not ready\u201d runbook: <code>operations/runbooks/service-not-ready.md</code></p>"},{"location":"reference/api/examples/","title":"API examples (HTTP files)","text":"<p>These examples are written in <code>.http</code> format for tools like:</p> <ul> <li>JetBrains HTTP Client (built into IntelliJ/GoLand)</li> <li>VS Code REST Client (or similar)</li> </ul> <p>They are also useful as copy/paste reference for curl clients.</p>"},{"location":"reference/api/examples/#recommend","title":"Recommend","text":"<pre><code>POST https://example.com/v1/recommend\nAuthorization: Bearer {{token}}\nContent-Type: application/json\n\n{ \"surface\": \"home\", \"k\": 20, \"user\": { \"user_id\": \"u_1\", \"anonymous_id\": null, \"session_id\": \"s_1\" } }\n</code></pre> <p>Notes:</p> <ul> <li><code>surface</code> selects the surface namespace (and typically maps to a UI placement like <code>home</code>, <code>pdp</code>, etc).</li> <li><code>k</code> is the number of items requested.</li> <li><code>user</code> can carry one or more identifiers. Prefer a stable <code>user_id</code> when available.</li> <li>Tenant scope + <code>surface</code> determine which config/rules/signals are used.</li> <li>Use <code>POST /v1/recommend/validate</code> during development to normalize requests and surface warnings early.</li> </ul>"},{"location":"reference/api/examples/#similar-items","title":"Similar items","text":"<pre><code>POST https://example.com/v1/similar\nAuthorization: Bearer {{token}}\nContent-Type: application/json\n\n{ \"surface\": \"pdp\", \"item_id\": \"item_1\", \"k\": 20 }\n</code></pre> <p>Notes:</p> <ul> <li><code>item_id</code> is the anchor item you want neighbors for.</li> <li>Similarity requires similarity/co-vis signals. If unavailable, the API may return warnings or empty results depending   on the configured algorithm and available signals.</li> </ul>"},{"location":"reference/api/examples/#admin-config-rules-cache-invalidation","title":"Admin: config, rules, cache invalidation","text":"<p>These endpoints are for operators (bootstrap + config management).</p> <p>See also: <code>admin.md</code>.</p> <pre><code>### Get config (admin)\nGET https://example.com/v1/admin/tenants/demo/config\nAuthorization: Bearer {{admin_token}}\n\n### Update config (admin)\nPUT https://example.com/v1/admin/tenants/demo/config\nAuthorization: Bearer {{admin_token}}\nContent-Type: application/json\nIf-Match: {{etag}}\n\n{ \"weights\": { \"pop\": 0.5, \"cooc\": 0.2, \"emb\": 0.3 } }\n\n### Get rules (admin)\nGET https://example.com/v1/admin/tenants/demo/rules\nAuthorization: Bearer {{admin_token}}\n\n### Update rules (admin)\nPUT https://example.com/v1/admin/tenants/demo/rules\nAuthorization: Bearer {{admin_token}}\nContent-Type: application/json\nIf-Match: {{etag}}\n\n[\n  {\n    \"action\": \"pin\",\n    \"target_type\": \"item\",\n    \"item_ids\": [\"item_1\", \"item_2\"],\n    \"surface\": \"home\",\n    \"priority\": 10\n  },\n  {\n    \"action\": \"block\",\n    \"target_type\": \"tag\",\n    \"target_key\": \"brand:nike\"\n  }\n]\n\n### Invalidate caches (admin)\nPOST https://example.com/v1/admin/tenants/demo/cache/invalidate\nAuthorization: Bearer {{admin_token}}\nContent-Type: application/json\n\n{ \"targets\": [\"config\", \"rules\"], \"surface\": \"home\" }\n</code></pre> <p>Notes:</p> <ul> <li>Admin endpoints require elevated scope (viewer/operator/admin roles in JWT mode).</li> <li><code>If-Match</code> enables optimistic concurrency using the current <code>ETag</code>/version value.</li> <li>Cache invalidation is safe to run after updates to reduce \u201cstale config\u201d confusion during incidents.</li> </ul>"},{"location":"reference/cli/","title":"CLI reference","text":""},{"location":"reference/cli/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers running <code>recsys-eval</code> and <code>recsys-pipelines</code> locally or in CI</li> <li>Operators needing the exact flags and exit codes for automation</li> </ul>"},{"location":"reference/cli/#what-you-will-get","title":"What you will get","text":"<ul> <li>The canonical CLI usage for the suite tools</li> <li>Links to module docs for deeper operational guides</li> </ul>"},{"location":"reference/cli/#reference","title":"Reference","text":"<ul> <li><code>recsys-eval</code></li> <li><code>recsys-pipelines</code></li> </ul>"},{"location":"reference/cli/#read-next","title":"Read next","text":"<ul> <li>Run eval and ship: <code>how-to/run-eval-and-ship.md</code></li> </ul>"},{"location":"reference/cli/recsys-eval/","title":"CLI: recsys-eval","text":"<p>Commands:</p> <ul> <li>offline</li> <li>experiment</li> <li>ope (optional)</li> </ul>"},{"location":"reference/cli/recsys-pipelines/","title":"CLI: recsys-pipelines","text":"<p>Suggested commands:</p> <ul> <li>ingest</li> <li>canonicalize</li> <li>popularity</li> <li>publish</li> <li>validate</li> <li>backfill</li> </ul> <p>Note:</p> <ul> <li>The CLI currently expects JSON config files.</li> </ul>"},{"location":"reference/config/","title":"Configuration reference","text":""},{"location":"reference/config/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Operators configuring <code>recsys-service</code> and pipelines in an environment</li> <li>Engineers needing the canonical env var list and meanings</li> </ul>"},{"location":"reference/config/#what-you-will-get","title":"What you will get","text":"<ul> <li>Links to the per-module configuration references</li> <li>The recommended starting point for local vs production configs</li> </ul>"},{"location":"reference/config/#reference","title":"Reference","text":"<ul> <li><code>recsys-service</code></li> <li><code>recsys-eval</code></li> <li><code>recsys-pipelines</code></li> </ul>"},{"location":"reference/config/#read-next","title":"Read next","text":"<ul> <li>Local end-to-end tutorial (a known-good baseline): <code>tutorials/local-end-to-end.md</code></li> </ul>"},{"location":"reference/config/recsys-eval/","title":"recsys-eval configuration","text":"<ul> <li>offline.primary_metric: e.g. ndcg@20</li> <li>offline.fail_threshold: relative drop threshold</li> <li>experiment.primary_kpi: e.g. ctr</li> <li>output.format: json|md|html</li> </ul>"},{"location":"reference/config/recsys-pipelines/","title":"recsys-pipelines configuration","text":"<p>Note: the current CLI expects JSON configs.</p> <p>Core knobs you will likely set:</p> <ul> <li>raw_source.type: fs|s3|minio|postgres|kafka</li> <li>object_store.type: fs|s3|minio</li> <li>registry_dir: manifest registry location (fs)</li> <li>db.dsn: Postgres DSN (optional, for DB-backed signals)</li> <li>limits.max_users_per_run, limits.max_items_per_user (implicit/session jobs)</li> <li>limits.max_items_per_artifact, limits.max_neighbors_per_item</li> </ul> <p>Artifacts produced (v1):</p> <ul> <li>popularity</li> <li>cooc</li> <li>implicit (collaborative)</li> <li>content_sim</li> <li>session_seq</li> </ul>"},{"location":"reference/config/recsys-service/","title":"recsys-service configuration","text":"<p>Canonical env var list: <code>api/.env.example</code>.</p> <ul> <li>db.dsn: Postgres DSN</li> <li>auth.required: enable auth on protected routes</li> <li>auth.tenant_claim: claim used for tenant id (JWT mode)</li> <li>auth.viewer_role: role that can read admin resources (default: viewer)</li> <li>auth.operator_role: role that can mutate admin resources (default: operator)</li> <li>auth.admin_role: role with full admin access (default: admin)</li> <li>auth.dev_headers: enable dev headers (local)</li> <li>auth.dev_tenant_header: tenant header used with dev auth</li> <li>limits.rps_per_tenant: per-tenant rate limit</li> <li>audit.log_path: file path for optional audit JSONL log</li> <li>audit.log_fsync: fsync on each audit write (default: false)</li> <li>cache.config_ttl_seconds: config cache TTL</li> <li>cache.rules_ttl_seconds: rules cache TTL</li> <li>exposure.log_path: file path (JSONL)</li> <li>exposure.log_format: service_v1 | eval_v1</li> <li>algo.mode: blend | popularity | cooc | implicit | content_sim | session_seq (default: blend)</li> <li>algo.plugin_enabled: enable Go plugin loading (dev only)</li> <li>algo.plugin_path: filesystem path to .so plugin (dev only)</li> <li>artifacts.enabled: enable artifact/manifest mode</li> <li>artifacts.manifest_template: manifest URI template (supports {tenant} and {surface})</li> <li>artifacts.manifest_ttl_seconds: manifest cache TTL</li> <li>artifacts.cache_ttl_seconds: artifact cache TTL</li> <li>artifacts.max_bytes: max artifact size in bytes</li> <li>artifacts.s3.endpoint: S3/MinIO endpoint (host:port)</li> <li>artifacts.s3.access_key: S3 access key</li> <li>artifacts.s3.secret_key: S3 secret key</li> <li>artifacts.s3.region: S3 region</li> <li>artifacts.s3.use_ssl: use TLS for S3 (true/false)</li> </ul> <p>Notes:</p> <ul> <li>content_sim and session_seq modes require corresponding artifacts in the manifest.</li> <li>auth.tenant_claim and auth.role_claims support dotted keys (e.g., realm_access.roles).</li> </ul>"},{"location":"reference/data-contracts/","title":"Data contracts","text":""},{"location":"reference/data-contracts/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Lead developers and data engineers implementing logging, pipelines, and data validation</li> <li>Analysts and recommendation engineers running <code>recsys-eval</code></li> <li>Operators who need to reason about \u201cwhat was served\u201d vs \u201cwhat was clicked\u201d vs \u201cwhat artifact version is   live\u201d</li> </ul>"},{"location":"reference/data-contracts/#what-you-will-get","title":"What you will get","text":"<ul> <li>The contract types used across the suite (serving, evaluation, pipelines)</li> <li>Minimal examples you can copy/paste</li> <li>Where the canonical schemas live and how they are versioned</li> </ul>"},{"location":"reference/data-contracts/#overview-three-contract-families","title":"Overview: three contract families","text":"<ul> <li>Evaluation events (for <code>recsys-eval</code>)</li> <li>Purpose: measure quality (offline regression, experiments).</li> <li>Join key: <code>request_id</code> (exposures \u2194 outcomes \u2194 assignments).</li> <li>Details + examples: <code>Eval events</code></li> <li> <p>Join semantics: <code>Event join logic</code></p> </li> <li> <p>Serving logs (what the service emitted)</p> </li> <li>Purpose: auditable \u201cwhat was served\u201d record.</li> <li> <p>Canonical schema: <code>exposures.schema.json</code></p> </li> <li> <p>Pipelines + artifacts (what pipelines consume/publish)</p> </li> <li>Purpose: convert interactions into versioned artifacts and a manifest pointer.</li> <li>Interaction schema: <code>interactions.schema.json</code></li> <li>Manifest schema: <code>artifacts/manifest.schema.json</code></li> </ul>"},{"location":"reference/data-contracts/#evaluation-events-recsys-eval-what-you-must-be-able-to-produce","title":"Evaluation events (recsys-eval): what you must be able to produce","text":"<p>If your goal is \u201cmeasure lift\u201d or \u201cdecide what to ship\u201d, implement these:</p> <ul> <li><code>exposure.v1</code> (what you showed)</li> <li><code>outcome.v1</code> (what the user did)</li> <li><code>assignment.v1</code> (optional; experiment bucket)</li> </ul> <p>Minimal JSONL examples (one object per line):</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"u_1\",\"ts\":\"2026-02-05T10:00:00Z\",\"items\":[{\"item_id\":\"item_1\",\"rank\":1},{\"item_id\":\"item_2\",\"rank\":2}],\"context\":{\"tenant_id\":\"demo\",\"surface\":\"home\"}}\n{\"request_id\":\"req-1\",\"user_id\":\"u_1\",\"item_id\":\"item_2\",\"event_type\":\"click\",\"ts\":\"2026-02-05T10:00:02Z\"}\n{\"experiment_id\":\"exp-1\",\"variant\":\"A\",\"request_id\":\"req-1\",\"user_id\":\"u_1\",\"ts\":\"2026-02-05T10:00:00Z\",\"context\":{\"tenant_id\":\"demo\",\"surface\":\"home\"}}\n</code></pre> <p>Validation:</p> <pre><code>recsys-eval validate --schema exposure.v1 --input exposures.jsonl\nrecsys-eval validate --schema outcome.v1 --input outcomes.jsonl\nrecsys-eval validate --schema assignment.v1 --input assignments.jsonl\n</code></pre> <p>Tip: <code>recsys-service</code> can emit eval-compatible exposures directly. See \u201cService exposure logs vs eval schema\u201d in <code>Eval events</code>.</p>"},{"location":"reference/data-contracts/#serving-exposure-events-service-native-what-was-actually-served","title":"Serving exposure events (service-native): what was actually served","text":"<p>This event shape is useful for auditability, debugging, and building derived datasets. It is not the same as the <code>recsys-eval</code> exposure schema (which is stricter and optimized for evaluation).</p> <p>Canonical schema: <code>exposures.schema.json</code></p> <p>Minimal example:</p> <pre><code>{\n  \"schema_version\": \"exposure.v1\",\n  \"occurred_at\": \"2026-02-05T10:00:00Z\",\n  \"tenant_id\": \"demo\",\n  \"request_id\": \"00000000-0000-0000-0000-000000000000\",\n  \"surface\": \"home\",\n  \"segment\": \"default\",\n  \"served\": [{ \"item_id\": \"item_1\", \"rank\": 1, \"score\": 0.12 }]\n}\n</code></pre>"},{"location":"reference/data-contracts/#interaction-events-pipelines-what-happened-in-the-product","title":"Interaction events (pipelines): what happened in the product","text":"<p>This is the minimal \u201csomething happened\u201d record used by pipelines.</p> <p>Canonical schema: <code>interactions.schema.json</code></p> <p>Minimal example:</p> <pre><code>{\n  \"schema_version\": \"interaction.v1\",\n  \"occurred_at\": \"2026-02-05T10:00:02Z\",\n  \"tenant_id\": \"demo\",\n  \"event_type\": \"click\",\n  \"item_id\": \"item_2\"\n}\n</code></pre> <p>If you need reliable evaluation joins, produce <code>outcome.v1</code> for <code>recsys-eval</code> (it requires <code>request_id</code> and <code>user_id</code>).</p>"},{"location":"reference/data-contracts/#artifact-manifest-pipelines-service-what-version-is-live","title":"Artifact manifest (pipelines \u2192 service): what version is live","text":"<p>In artifact/manifest mode, pipelines publish artifacts and update a manifest pointer. The service reads the current manifest and fetches referenced blobs.</p> <p>Canonical schema: <code>artifacts/manifest.schema.json</code></p> <p>Minimal example:</p> <pre><code>{\n  \"schema_version\": \"manifest.v1\",\n  \"tenant_id\": \"demo\",\n  \"created_at\": \"2026-02-05T10:05:00Z\",\n  \"version\": \"2026-02-05T10:05:00Z\",\n  \"artifacts\": {}\n}\n</code></pre>"},{"location":"reference/data-contracts/#versioning-rules-practical","title":"Versioning rules (practical)","text":"<ul> <li>Never change the meaning of an existing version.</li> <li>Add a new version instead (for example: <code>interaction.v2</code>), and keep transforms explicit.</li> <li>Treat schemas as strict by default.</li> <li><code>recsys-eval validate</code> uses JSON Schema with strictness that will reject missing required fields and unexpected keys.</li> <li>Keep IDs stable and privacy-safe.</li> <li>Use pseudonymous user IDs; do not log raw PII.</li> </ul>"},{"location":"reference/data-contracts/#read-next","title":"Read next","text":"<ul> <li>Exposure logging and attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> <li>How shipping/rollback ties to contracts: <code>explanation/suite-architecture.md</code></li> <li>Data modes (DB-only vs artifact/manifest): <code>explanation/data-modes.md</code></li> </ul>"},{"location":"reference/data-contracts/eval-events/","title":"recsys-eval event schemas (v1)","text":"<p><code>recsys-eval validate</code> uses strict JSON schemas with <code>additionalProperties: false</code>. If your JSONL includes extra keys or misses required fields, validation fails even if <code>recsys-eval run</code> produced a report.</p> <p>Schema sources (repo):</p> <ul> <li><code>recsys-eval/schemas/exposure.v1.json</code></li> <li><code>recsys-eval/schemas/outcome.v1.json</code></li> <li><code>recsys-eval/schemas/assignment.v1.json</code></li> </ul>"},{"location":"reference/data-contracts/eval-events/#exposurev1-required-fields","title":"exposure.v1 (required fields)","text":"<p>Required:</p> <ul> <li><code>request_id</code> (string, non-empty)</li> <li><code>user_id</code> (string, non-empty)</li> <li><code>ts</code> (RFC3339 date-time)</li> <li><code>items</code> (array of <code>{ item_id, rank }</code>)</li> </ul> <p>Allowed optional fields:</p> <ul> <li><code>context</code> (object of string values)</li> <li><code>latency_ms</code> (number &gt;= 0)</li> <li><code>error</code> (boolean)</li> <li><code>items[].propensity</code>, <code>items[].logging_propensity</code>, <code>items[].target_propensity</code></li> </ul> <p>Examples (JSONL; one object per line):</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"ts\":\"2026-01-30T12:00:00Z\",\"items\":[{\"item_id\":\"item-1\",\"rank\":1},{\"item_id\":\"item-2\",\"rank\":2}],\"context\":{\"surface\":\"home\",\"tenant_id\":\"demo\"}}\n{\"request_id\":\"req-2\",\"user_id\":\"user-2\",\"ts\":\"2026-01-30T12:05:00Z\",\"items\":[{\"item_id\":\"sku-9\",\"rank\":1,\"propensity\":0.42,\"logging_propensity\":0.5,\"target_propensity\":0.6},{\"item_id\":\"sku-3\",\"rank\":2}],\"context\":{\"surface\":\"home\",\"segment\":\"default\",\"tenant_id\":\"demo\",\"locale\":\"en-US\"},\"latency_ms\":12.4,\"error\":false}\n</code></pre>"},{"location":"reference/data-contracts/eval-events/#outcomev1-required-fields","title":"outcome.v1 (required fields)","text":"<p>Required:</p> <ul> <li><code>request_id</code> (string, non-empty)</li> <li><code>user_id</code> (string, non-empty)</li> <li><code>item_id</code> (string, non-empty)</li> <li><code>event_type</code> (<code>click</code> or <code>conversion</code>)</li> <li><code>ts</code> (RFC3339 date-time)</li> </ul> <p>Allowed optional fields:</p> <ul> <li><code>value</code> (number)</li> </ul> <p>Examples (JSONL; one object per line):</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"item_id\":\"item-2\",\"event_type\":\"click\",\"ts\":\"2026-01-30T12:00:03Z\"}\n{\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"item_id\":\"item-2\",\"event_type\":\"conversion\",\"value\":49.90,\"ts\":\"2026-01-30T12:00:20Z\"}\n{\"request_id\":\"req-2\",\"user_id\":\"user-2\",\"item_id\":\"sku-9\",\"event_type\":\"click\",\"ts\":\"2026-01-30T12:05:02Z\"}\n</code></pre>"},{"location":"reference/data-contracts/eval-events/#assignmentv1-required-fields","title":"assignment.v1 (required fields)","text":"<p>Required:</p> <ul> <li><code>experiment_id</code> (string, non-empty)</li> <li><code>variant</code> (string, non-empty)</li> <li><code>request_id</code> (string, non-empty)</li> <li><code>user_id</code> (string, non-empty)</li> <li><code>ts</code> (RFC3339 date-time)</li> </ul> <p>Allowed optional fields:</p> <ul> <li><code>context</code> (object of string values)</li> </ul> <p>Examples (JSONL; one object per line):</p> <pre><code>{\"experiment_id\":\"exp-1\",\"variant\":\"A\",\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"ts\":\"2026-01-30T12:00:00Z\",\"context\":{\"surface\":\"home\"}}\n{\"experiment_id\":\"exp-1\",\"variant\":\"B\",\"request_id\":\"req-2\",\"user_id\":\"user-2\",\"ts\":\"2026-01-30T12:05:00Z\",\"context\":{\"surface\":\"home\",\"tenant_id\":\"demo\"}}\n</code></pre>"},{"location":"reference/data-contracts/eval-events/#how-to-avoid-validation-failures","title":"How to avoid validation failures","text":"<ul> <li>Ensure every record contains exactly the required fields (no extras).</li> <li>Use RFC3339 timestamps for <code>ts</code>.</li> <li><code>user_id</code> must be non-empty (use a stable pseudonymous ID if needed).</li> <li>Join key is request_id: outcomes and assignments must use the same</li> </ul> <p><code>request_id</code> as the exposure.</p>"},{"location":"reference/data-contracts/eval-events/#service-exposure-logs-vs-eval-schema","title":"Service exposure logs vs eval schema","text":"<p><code>recsys-service</code> logs exposures in its native format by default. To emit <code>exposure.v1</code> directly for recsys-eval, set:</p> <pre><code>EXPOSURE_LOG_FORMAT=eval_v1\n</code></pre> <p>If you keep <code>service_v1</code>, you must transform logs before running <code>recsys-eval validate</code>.</p>"},{"location":"reference/data-contracts/field-catalog/","title":"Field catalog","text":"<p>exposure.v1:</p> <ul> <li>request_id: join key for outcomes</li> <li>served[].rank: 1-based ranking position</li> </ul> <p>interaction.v1:</p> <ul> <li>request_id: recommended when available</li> <li>event_type: click/purchase/etc.</li> </ul> <p>recsys-eval datasets (strict schemas):</p> <ul> <li>exposure.v1 / outcome.v1 / assignment.v1 required fields and examples:</li> </ul> <p><code>reference/data-contracts/eval-events.md</code></p>"},{"location":"reference/data-contracts/join-logic/","title":"Event join logic (exposures \u2194 outcomes \u2194 assignments)","text":""},{"location":"reference/data-contracts/join-logic/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Data engineers and analysts building an evaluation dataset</li> <li>Integrators wiring <code>request_id</code> propagation end-to-end</li> <li>Recommendation engineers validating offline evaluation quality</li> </ul>"},{"location":"reference/data-contracts/join-logic/#what-you-will-get","title":"What you will get","text":"<ul> <li>The exact join key used by <code>recsys-eval</code></li> <li>The invariants your logging must satisfy for valid attribution</li> <li>A checklist to debug low join rates</li> </ul>"},{"location":"reference/data-contracts/join-logic/#mental-model","title":"Mental model","text":"<p>Think of each recommendation response as a \u201ccase\u201d:</p> <ul> <li>Exposure: the ranked list you showed</li> <li>Outcomes: what the user did after seeing it (click, conversion)</li> <li>Assignment (optional): the experiment bucket for that request/user</li> </ul> <p><code>recsys-eval</code> attributes outcomes to exposures by joining on <code>request_id</code>.</p>"},{"location":"reference/data-contracts/join-logic/#join-key-and-invariants","title":"Join key and invariants","text":""},{"location":"reference/data-contracts/join-logic/#required-request_id","title":"Required: <code>request_id</code>","text":"<p>For evaluation, <code>request_id</code> must be present in:</p> <ul> <li><code>exposure.v1</code> (<code>request_id</code> on the exposure record)</li> <li><code>outcome.v1</code> (<code>request_id</code> on every outcome record you want to attribute)</li> <li><code>assignment.v1</code> (if you analyze experiments)</li> </ul> <p>Invariants to enforce:</p> <ul> <li>Uniqueness: one exposure list per <code>request_id</code> (do not reuse IDs across requests).</li> <li>Propagation: the same <code>request_id</code> flows serving \u2192 outcome event.</li> <li>Stability: do not change the <code>request_id</code> after you render a list (or you will split attribution).</li> </ul>"},{"location":"reference/data-contracts/join-logic/#strongly-recommended-stable-user_id","title":"Strongly recommended: stable <code>user_id</code>","text":"<p><code>recsys-eval</code> joins by <code>request_id</code>, but you should still ensure <code>user_id</code> is stable and consistent across exposures and outcomes:</p> <ul> <li>it improves slice quality and sanity checks</li> <li>it helps detect \u201cwrong request_id\u201d bugs early</li> <li>it enables user-level analyses outside of strict request attribution</li> </ul> <p>Do not log raw PII; use pseudonymous IDs.</p>"},{"location":"reference/data-contracts/join-logic/#how-recsys-eval-joins","title":"How <code>recsys-eval</code> joins","text":"<p>At a high level, <code>recsys-eval</code>:</p> <ol> <li>groups all outcomes by <code>request_id</code></li> <li>attaches that outcome list to the exposure with the same <code>request_id</code></li> </ol> <p>This is a many-to-one join: one exposure \u2192 many outcomes.</p> <p>Important implication: if your exposure stream contains multiple exposure records with the same <code>request_id</code>, later records can overwrite earlier ones (so treat duplicates as a data quality bug).</p>"},{"location":"reference/data-contracts/join-logic/#join-integrity-what-to-measure","title":"Join integrity: what to measure","text":"<p><code>recsys-eval</code> reports join integrity as part of \u201cData Quality\u201d:</p> <ul> <li>Exposure join rate: fraction of exposures that have at least one matching outcome</li> <li>Outcome join rate: fraction of outcomes that match an exposure</li> <li>Assignment join rate: fraction of assignments that match an exposure (when analyzing experiments)</li> </ul> <p>In addition, compute a simple join rate in your warehouse (by surface and platform) to catch integration issues early.</p> <p>Pseudo-SQL pattern:</p> <pre><code>select\n  surface,\n  count(*) as exposures,\n  count(*) filter (\n    where exists (\n      select 1 from outcomes o\n      where o.request_id = e.request_id\n    )\n  ) as exposures_with_outcomes\nfrom exposures e\ngroup by surface;\n</code></pre>"},{"location":"reference/data-contracts/join-logic/#common-failure-patterns-and-fixes","title":"Common failure patterns (and fixes)","text":"<ul> <li>Outcomes missing <code>request_id</code></li> <li>Fix: propagate the ID you used when calling <code>/v1/recommend</code>, or store <code>meta.request_id</code> from the response.</li> <li>Request IDs generated twice</li> <li>Symptom: exposure log uses one ID, outcome uses another.</li> <li>Fix: centralize request ID generation; add an automated test that asserts \u201csame request_id everywhere\u201d.</li> <li>Reusing the same <code>request_id</code> for multiple lists</li> <li>Symptom: attribution is \u201csmeared\u201d across requests; debugging becomes impossible.</li> <li>Fix: generate a fresh ID per rendered list.</li> <li>Exposure logged but list never rendered</li> <li>Symptom: exposure join rate drops even though outcomes are correct.</li> <li>Fix: if you log exposures server-side, ensure the request corresponds to an actual render (or log exposures client-side).</li> </ul>"},{"location":"reference/data-contracts/join-logic/#read-next","title":"Read next","text":"<ul> <li>Data contracts hub: <code>index.md</code></li> <li>Exposure logging and attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> <li>Eval events schemas: <code>eval-events.md</code></li> </ul>"},{"location":"reference/database/","title":"Database reference","text":""},{"location":"reference/database/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers running migrations and seeding local data</li> <li>Operators debugging \u201cempty recs\u201d and signal availability incidents</li> </ul>"},{"location":"reference/database/#what-you-will-get","title":"What you will get","text":"<ul> <li>The schema and migrations that back DB-only mode and control-plane state</li> <li>A DB-only seeding guide for fast pilots</li> </ul>"},{"location":"reference/database/#reference","title":"Reference","text":"<ul> <li><code>Schema</code></li> <li><code>Migrations</code></li> <li><code>DB-only seeding</code></li> </ul>"},{"location":"reference/database/#read-next","title":"Read next","text":"<ul> <li>Empty recs runbook: <code>operations/runbooks/empty-recs.md</code></li> </ul>"},{"location":"reference/database/db-only-seeding/","title":"DB-only signals: schema + seed examples","text":"<p>Use these tables when running recsys-service in DB-only mode (no artifacts).</p>"},{"location":"reference/database/db-only-seeding/#1-resolve-tenant-uuid","title":"1) Resolve tenant UUID","text":"<p><code>external_id</code> should match your tenant claim or dev header value.</p> <pre><code>select id from tenants where external_id = 'demo';\n</code></pre> <p>Assume the result is <code>:tenant_id</code>.</p>"},{"location":"reference/database/db-only-seeding/#2-item_tags","title":"2) item_tags","text":"<p>Columns:</p> <ul> <li>tenant_id (uuid)</li> <li>namespace (surface, text)</li> <li>item_id (text)</li> <li>tags (text[])</li> <li>price (numeric, optional)</li> <li>created_at (timestamptz)</li> </ul> <pre><code>insert into item_tags (tenant_id, namespace, item_id, tags, price, created_at)\nvalues\n  (:tenant_id, 'home', 'item-1', array['brand:nike','category:shoes'], 99.90, now()),\n  (:tenant_id, 'home', 'item-2', array['brand:nike','category:shoes'], 79.00, now())\non conflict (tenant_id, namespace, item_id)\ndo update set tags = excluded.tags,\n              price = excluded.price,\n              created_at = excluded.created_at;\n</code></pre>"},{"location":"reference/database/db-only-seeding/#3-item_popularity_daily","title":"3) item_popularity_daily","text":"<p>Columns:</p> <ul> <li>tenant_id (uuid)</li> <li>namespace (surface, text)</li> <li>item_id (text)</li> <li>day (date)</li> <li>score (numeric)</li> </ul> <pre><code>insert into item_popularity_daily (tenant_id, namespace, item_id, day, score)\nvalues\n  (:tenant_id, 'home', 'item-1', '2026-01-30', 10),\n  (:tenant_id, 'home', 'item-2', '2026-01-30', 8)\non conflict (tenant_id, namespace, item_id, day)\ndo update set score = excluded.score;\n</code></pre> <p>Note: popularity is a decayed sum across days, so newer days dominate when multiple days are present.</p>"},{"location":"reference/database/db-only-seeding/#4-item_covisit_daily-for-v1similar","title":"4) item_covisit_daily (for /v1/similar)","text":"<p>Columns:</p> <ul> <li>tenant_id (uuid)</li> <li>namespace (surface, text)</li> <li>item_id (anchor)</li> <li>neighbor_id</li> <li>day (date)</li> <li>score (numeric)</li> </ul> <pre><code>insert into item_covisit_daily (tenant_id, namespace, item_id, neighbor_id, day, score)\nvalues\n  (:tenant_id, 'home', 'item-1', 'item-2', '2026-01-30', 3),\n  (:tenant_id, 'home', 'item-1', 'item-3', '2026-01-30', 1)\non conflict (tenant_id, namespace, item_id, neighbor_id, day)\ndo update set score = excluded.score;\n</code></pre> <p>If <code>/v1/similar</code> returns empty:</p> <ul> <li>ensure co-vis rows exist for the same surface (namespace)</li> <li>ensure the anchor item exists in <code>item_covisit_daily</code></li> </ul>"},{"location":"reference/database/migrations/","title":"Migrations (safe upgrade)","text":""},{"location":"reference/database/migrations/#policy","title":"Policy","text":"<ul> <li>Migrations are versioned, append-only. Never edit a migration after it has</li> </ul> <p>shipped; create a new one instead.</p> <ul> <li><code>down</code> migrations are disabled by default in production. Use only in</li> </ul> <p>controlled rollback scenarios.</p>"},{"location":"reference/database/migrations/#preflight-checks","title":"Preflight checks","text":"<p>Before upgrading from N\u20111 to N, run:</p> <pre><code>cd api\ngo run ./cmd/migrate preflight\n</code></pre> <p>Docker/compose shortcut:</p> <pre><code>cd api\nmake migrate-preflight\n</code></pre> <p>This verifies:</p> <ul> <li>DB connectivity</li> <li>No failed migrations in <code>schema_migrations</code></li> <li>Checksums match the local migration files</li> </ul>"},{"location":"reference/database/migrations/#upgrade-steps-n1-n","title":"Upgrade steps (N\u20111 \u2192 N)","text":"<ol> <li>Take a DB snapshot/backup.</li> <li>Run preflight checks.</li> <li>Apply migrations:</li> </ol> <pre><code>go run ./cmd/migrate up\n</code></pre> <ol> <li>Verify status:</li> </ol> <pre><code>go run ./cmd/migrate status\n</code></pre> <ol> <li>Roll forward with application deploy.</li> </ol>"},{"location":"reference/database/migrations/#rollback-story","title":"Rollback story","text":"<p>If a migration introduces issues:</p> <ol> <li>Roll back the application to N\u20111.</li> <li>Use the config/rules rollback runbook:</li> </ol> <p><code>docs/operations/runbooks/rollback-config-rules.md</code></p> <ol> <li>Only if absolutely required, apply a controlled <code>down</code> migration:</li> </ol> <pre><code>go run ./cmd/migrate --allow-down down\n</code></pre>"},{"location":"reference/database/migrations/#recommended-order-fresh-install","title":"Recommended order (fresh install)","text":"<ol> <li>extensions</li> <li>tenants</li> <li>config/rules version tables + current pointers</li> <li>audit log</li> <li>exposure_events (partitioned)</li> </ol>"},{"location":"reference/database/schema/","title":"Database schema","text":"<p>Use Postgres for:</p> <ul> <li>tenant config/rules (versioned + current pointers)</li> <li>exposure logging</li> <li>audit log</li> <li>signal tables (DB-only mode): item_tags, item_popularity_daily, item_covisit_daily</li> </ul> <p>Partition high-volume exposure tables by time.</p> <p>DB-only seed examples:</p> <ul> <li><code>reference/database/db-only-seeding.md</code></li> </ul>"},{"location":"start-here/","title":"Start here","text":"<p>This site documents the RecSys suite: a production-ready set of modules for building, shipping, and operating a recommendation system.</p>"},{"location":"start-here/#who-this-is-for","title":"Who this is for","text":"<ul> <li>New evaluators of the RecSys suite</li> <li>Engineers who want the shortest path to a runnable local setup</li> <li>Stakeholders who need the \u201cwhat do we get, what do we need?\u201d overview</li> </ul>"},{"location":"start-here/#what-you-will-get","title":"What you will get","text":"<ul> <li>A recommended reading and execution path (tutorial \u2192 concepts \u2192 integration)</li> <li>Role-based entry points (lead dev, recsys engineer, stakeholder, SRE)</li> <li>Links to the canonical contracts, API, and operational runbooks</li> </ul>"},{"location":"start-here/#recommended-path","title":"Recommended path","text":"<ol> <li>Run the suite locally end-to-end</li> <li>Tutorial: <code>tutorials/local-end-to-end.md</code></li> <li> <p>Optional: production-like artifacts + ship/rollback: <code>tutorials/production-like-run.md</code></p> </li> <li> <p>Understand the architecture and data flow</p> </li> <li>Diagram: <code>start-here/diagrams/suite-context.md</code></li> <li>Explanation: <code>explanation/suite-architecture.md</code></li> <li>Repo layout: <code>start-here/repo-layout.md</code></li> <li> <p>Known limitations: <code>start-here/known-limitations.md</code></p> </li> <li> <p>Integrate, operate, and validate</p> </li> <li>Integrate the API: <code>how-to/integrate-recsys-service.md</code></li> <li>Operate pipelines: <code>how-to/operate-pipelines.md</code></li> <li>Run evaluation and ship decisions: <code>how-to/run-eval-and-ship.md</code></li> </ol>"},{"location":"start-here/#role-based-entry-points","title":"Role-based entry points","text":""},{"location":"start-here/#lead-developer-platform-engineer","title":"Lead developer / platform engineer","text":"<ul> <li>Suite architecture and contracts:</li> <li><code>explanation/suite-architecture.md</code></li> <li><code>reference/data-contracts/index.md</code></li> <li><code>reference/config/index.md</code></li> <li><code>reference/api/openapi.yaml</code></li> <li>Security overview: <code>start-here/security-privacy-compliance.md</code></li> </ul>"},{"location":"start-here/#recommendation-engineer-ml-engineer","title":"Recommendation engineer / ML engineer","text":"<ul> <li>Ranking core:</li> <li><code>recsys-algo/index.md</code></li> <li>Pipelines outputs:</li> <li><code>recsys-pipelines/docs/reference/output-layout.md</code></li> </ul>"},{"location":"start-here/#product-business-stakeholder","title":"Product / business stakeholder","text":"<ul> <li>What the suite is and what it takes to pilot:</li> <li><code>start-here/what-is-recsys.md</code></li> <li><code>start-here/pilot-plan.md</code></li> <li><code>start-here/responsibilities.md</code></li> <li> <p>Security and privacy overview: <code>start-here/security-privacy-compliance.md</code></p> </li> <li> <p>What to expect from evaluation and decisions:</p> </li> <li><code>recsys-eval/docs/interpreting_results.md</code></li> <li><code>recsys-eval/docs/metrics.md</code></li> </ul>"},{"location":"start-here/#sre-on-call","title":"SRE / on-call","text":"<ul> <li>Operational runbooks:</li> <li><code>operations/runbooks/service-not-ready.md</code></li> <li><code>operations/runbooks/empty-recs.md</code></li> <li><code>operations/runbooks/rollback-config-rules.md</code></li> <li>Security overview: <code>start-here/security-privacy-compliance.md</code></li> <li><code>recsys-pipelines/docs/operations/runbooks/pipeline-failed.md</code></li> <li><code>recsys-pipelines/docs/operations/runbooks/validation-failed.md</code></li> <li><code>recsys-pipelines/docs/operations/runbooks/limit-exceeded.md</code></li> <li><code>recsys-pipelines/docs/operations/runbooks/stale-artifacts.md</code></li> </ul>"},{"location":"start-here/#read-next","title":"Read next","text":"<ul> <li>Local end-to-end tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>Stakeholder overview: <code>start-here/what-is-recsys.md</code></li> <li>Suite architecture: <code>explanation/suite-architecture.md</code></li> </ul>"},{"location":"start-here/customer-onboarding-checklist/","title":"Customer onboarding checklist","text":""},{"location":"start-here/customer-onboarding-checklist/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Customer lead developer / platform engineer</li> <li>Security/compliance reviewer</li> <li>Data engineer / analytics owner</li> <li>SRE / on-call owner</li> <li>Product owner / stakeholder</li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#what-you-will-get","title":"What you will get","text":"<ul> <li>A practical checklist you can use to run a pilot and move to production safely</li> <li>Links to the exact docs pages that answer \u201chow do we do that?\u201d</li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#checklist","title":"Checklist","text":""},{"location":"start-here/customer-onboarding-checklist/#1-scope-and-ownership","title":"1) Scope and ownership","text":"<ul> <li>[ ] Agree on the first surface(s) and success metrics (CTR, conversion, revenue, retention).</li> <li>[ ] Confirm roles and responsibilities (RACI):</li> <li><code>start-here/responsibilities.md</code></li> <li>[ ] Pick a pilot plan and timeline:</li> <li><code>start-here/pilot-plan.md</code></li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#2-security-and-privacy","title":"2) Security and privacy","text":"<ul> <li>[ ] Confirm PII handling and retention expectations.</li> <li>[ ] Decide where exposure/outcome logs live and who can access them.</li> <li>[ ] Review the suite security overview:</li> <li><code>start-here/security-privacy-compliance.md</code></li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#3-integration-serving-api","title":"3) Integration (serving API)","text":"<ul> <li>[ ] Run the local end-to-end tutorial once (proves the loop):</li> <li><code>tutorials/local-end-to-end.md</code></li> <li>[ ] Implement <code>request_id</code> propagation and exposure/outcome logging:</li> <li><code>explanation/exposure-logging-and-attribution.md</code></li> <li>[ ] Integrate <code>/v1/recommend</code> into your product:</li> <li><code>how-to/integrate-recsys-service.md</code></li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#4-data-and-pipelines","title":"4) Data and pipelines","text":"<ul> <li>[ ] Decide DB-only vs artifact/manifest mode:</li> <li><code>explanation/data-modes.md</code></li> <li>[ ] If using pipelines, run the pipelines quickstart and confirm artifacts/manifest publishing:</li> <li><code>recsys-pipelines/docs/tutorials/local-quickstart.md</code></li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#5-operations","title":"5) Operations","text":"<ul> <li>[ ] Deploy strategy agreed (Helm, manifests, secrets):</li> <li><code>how-to/deploy-helm.md</code></li> <li>[ ] Run the production readiness checklist:</li> <li><code>operations/production-readiness-checklist.md</code></li> <li>[ ] Ensure on-call has the runbooks bookmarked:</li> <li><code>operations/runbooks/service-not-ready.md</code></li> <li><code>operations/runbooks/empty-recs.md</code></li> <li><code>operations/runbooks/stale-manifest.md</code></li> </ul>"},{"location":"start-here/customer-onboarding-checklist/#read-next","title":"Read next","text":"<ul> <li>Docs map: <code>start-here/docs-map.md</code></li> <li>Start here (overview): <code>start-here/index.md</code></li> </ul>"},{"location":"start-here/docs-map/","title":"Docs map","text":""},{"location":"start-here/docs-map/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Anyone evaluating the RecSys suite for adoption</li> <li>Teams onboarding new engineers, analysts, or on-call staff</li> </ul>"},{"location":"start-here/docs-map/#what-you-will-get","title":"What you will get","text":"<ul> <li>A \u201cpick your path\u201d map: if you are X, read Y</li> <li>The shortest links to the tutorial, core explanations, and integration/operations references</li> </ul>"},{"location":"start-here/docs-map/#pick-your-path-by-goal","title":"Pick your path (by goal)","text":"<ul> <li>Prove the loop locally (copy/paste): <code>tutorials/local-end-to-end.md</code></li> <li>Do a production-like ship/rollback run: <code>tutorials/production-like-run.md</code></li> <li>Integrate the API into your product: <code>how-to/integrate-recsys-service.md</code></li> <li>Deploy on Kubernetes (Helm): <code>how-to/deploy-helm.md</code></li> <li>Operate pipelines day-to-day: <code>how-to/operate-pipelines.md</code></li> <li>Evaluate and make ship/rollback decisions: <code>how-to/run-eval-and-ship.md</code></li> </ul>"},{"location":"start-here/docs-map/#pick-your-path-by-role","title":"Pick your path (by role)","text":""},{"location":"start-here/docs-map/#lead-developer-platform-engineer","title":"Lead developer / platform engineer","text":"<ul> <li>Architecture + boundaries: <code>explanation/suite-architecture.md</code></li> <li>Config + contracts:</li> <li><code>reference/config/index.md</code></li> <li><code>reference/data-contracts/index.md</code></li> <li>API schema (canonical): <code>reference/api/openapi.yaml</code></li> </ul>"},{"location":"start-here/docs-map/#recommendation-engineer-ml-engineer","title":"Recommendation engineer / ML engineer","text":"<ul> <li>Ranking core (ports/adapters, signals): <code>recsys-algo/index.md</code></li> <li>Pipelines lifecycle + artifacts: <code>recsys-pipelines/docs/index.md</code></li> </ul>"},{"location":"start-here/docs-map/#product-business-stakeholder","title":"Product / business stakeholder","text":"<ul> <li>What you get + what you need: <code>start-here/what-is-recsys.md</code></li> <li>Pilot plan and ownership: <code>start-here/pilot-plan.md</code> and <code>start-here/responsibilities.md</code></li> <li>How success is measured: <code>recsys-eval/docs/metrics.md</code></li> </ul>"},{"location":"start-here/docs-map/#sre-on-call","title":"SRE / on-call","text":"<ul> <li>Suite runbooks: <code>operations/runbooks/service-not-ready.md</code></li> <li>Pipeline runbooks: <code>recsys-pipelines/docs/operations/runbooks/pipeline-failed.md</code></li> <li>Capacity guidance: <code>operations/performance-and-capacity.md</code></li> </ul>"},{"location":"start-here/docs-map/#read-next","title":"Read next","text":"<ul> <li>Start here (overview): <code>start-here/index.md</code></li> <li>Stakeholder overview: <code>start-here/what-is-recsys.md</code></li> </ul>"},{"location":"start-here/faq/","title":"FAQ (for stakeholders)","text":""},{"location":"start-here/faq/#who-this-is-for","title":"Who this is for","text":"<ul> <li>PMs, engineering leaders, and procurement stakeholders evaluating RecSys</li> <li>Anyone who needs \u201cplain English\u201d answers before diving into the technical docs</li> </ul>"},{"location":"start-here/faq/#what-this-answers","title":"What this answers","text":"<ul> <li>What RecSys does (and does not) replace</li> <li>What you need to run a pilot</li> <li>How you control results and measure lift</li> <li>How rollbacks and safety work operationally</li> </ul>"},{"location":"start-here/faq/#questions","title":"Questions","text":"Will this replace our search?  No. Search is **intent-driven** (\u201cI want X\u201d), while recommendations are typically **discovery-driven** (\u201cyou might like Y\u201d). In most products, they work together:  - Search solves \u201cfind what I asked for\u201d. - Recommendations solve \u201chelp me decide / help me discover\u201d.   How do we control what shows up?  The suite provides a control plane and policy hooks:  - **Rules**: pin / boost / block by surface and segment. - **Constraints**: required/forbidden tags and per-tag caps. - **Allow-lists / exclude lists**: constrain candidate sets per request when needed.  For \u201cwhy did we show this?\u201d, use explainability options during development (`options.include_reasons` / `options.explain`).  How do we measure lift and make shipping decisions?  You measure recommendations with logs:  - log exposures (what you showed) - log outcomes (click/conversion) - join by `request_id`  Then choose an evaluation mode:  - **Offline evaluation**: fast regression gate before shipping. - **A/B experiments**: business KPI lift and guardrails for shipping decisions. - **Interleaving / OPE**: advanced options when experiments are slow or hard.   What do we need for a pilot?  Minimum viable pilot (DB-only mode):  - a small **catalog** (items + tags) - a minimal **popularity signal** (daily rows) - exposure + outcome logging for evaluation  This is intentionally lightweight so teams can validate the end-to-end loop before adding pipelines and artifact mode.  How do rollbacks work?  Two rollback levers exist:  - **Config/rules rollback**: versioned control-plane documents stored in Postgres. - **Manifest rollback** (artifact mode): \u201cship\u201d and \u201crollback\u201d are manifest pointer updates; artifacts are immutable.   What about privacy and compliance?  RecSys is designed to work with **pseudonymous identifiers**. The service can hash identifiers for exposure logging (do not log raw PII), and you can configure retention policies for logs."},{"location":"start-here/faq/#read-next","title":"Read next","text":"<ul> <li>Stakeholder overview: <code>start-here/what-is-recsys.md</code></li> <li>Pilot plan (4\u20136 weeks): <code>start-here/pilot-plan.md</code></li> <li>Security, privacy, compliance: <code>start-here/security-privacy-compliance.md</code></li> <li>Experimentation model: <code>explanation/experimentation-model.md</code></li> </ul>"},{"location":"start-here/known-limitations/","title":"Known limitations and non-goals (current)","text":"<p>This page is intentionally blunt. It exists so evaluators and operators can set expectations early.</p>"},{"location":"start-here/known-limitations/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Evaluators deciding whether this suite fits their current stage</li> <li>Lead developers planning adoption and integration scope</li> <li>Operators who need to avoid \u201csurprise missing feature\u201d incidents</li> </ul>"},{"location":"start-here/known-limitations/#what-you-will-get","title":"What you will get","text":"<ul> <li>The current product boundaries: what is supported vs intentionally not included</li> <li>Concrete limitations that affect pilots and production rollouts</li> <li>Pointers to the relevant docs for workarounds and operational safety</li> </ul>"},{"location":"start-here/known-limitations/#limitations","title":"Limitations","text":"<ul> <li> <p>Tenant creation is DB-only today. There is no admin API to create tenants yet; bootstrap requires a SQL insert.   See: <code>reference/api/admin.md</code></p> </li> <li> <p>Pipelines manifest registry is filesystem-based. <code>recsys-pipelines</code> writes the \u201ccurrent manifest pointer\u201d to its   configured <code>registry_dir</code> on the filesystem. Artifacts can be published to S3/MinIO, but publishing the manifest to   object storage requires an explicit upload step (or serving from a file-based manifest template).</p> </li> <li> <p>Kafka ingestion is scaffolded. The <code>raw_source.type = kafka</code> connector is present as a config option but is not   implemented as a streaming consumer yet.</p> </li> <li> <p>Dev headers don\u2019t carry roles. If you enable admin RBAC roles, admin endpoints require roles from JWT/API keys.   For local dev with dev headers, either disable RBAC roles or use JWT.</p> </li> </ul>"},{"location":"start-here/known-limitations/#non-goals-by-default","title":"Non-goals (by default)","text":"<ul> <li>Running your infrastructure for you (managed hosting is not implied by this repo)</li> <li>\u201cMagic\u201d model training inside the serving stack (the suite is designed for deterministic, auditable behavior first)</li> </ul>"},{"location":"start-here/known-limitations/#read-next","title":"Read next","text":"<ul> <li>Pilot plan (what to do first): <code>start-here/pilot-plan.md</code></li> <li>Data modes (DB-only vs artifact/manifest): <code>explanation/data-modes.md</code></li> <li>Local end-to-end tutorial (known-good baseline): <code>tutorials/local-end-to-end.md</code></li> </ul>"},{"location":"start-here/pilot-plan/","title":"Pilot plan (4\u20136 weeks)","text":""},{"location":"start-here/pilot-plan/#who-this-is-for","title":"Who this is for","text":"<p>Product owners, engineering leads, and delivery teams planning a pilot of the RecSys suite.</p>"},{"location":"start-here/pilot-plan/#what-you-will-get","title":"What you will get","text":"<ul> <li>A realistic timeline for a first pilot (from \u201chello world\u201d to production readiness)</li> <li>Clear deliverables and exit criteria per phase</li> <li>The minimum instrumentation needed to measure impact</li> </ul>"},{"location":"start-here/pilot-plan/#what-success-looks-like","title":"What \u201csuccess\u201d looks like","text":"<p>At the end of a pilot, you should be able to answer:</p> <ul> <li>Can we serve recommendations reliably for our key surfaces (latency, availability, no \u201cempty recs\u201d)?</li> <li>Can we explain and roll back changes (config/rules/artifacts) without drama?</li> <li>Can we measure quality and impact from real logs (offline + online)?</li> </ul> <p>If you cannot measure impact, you are not \u201cpiloting a recommender\u201d yet\u2014you are only integrating an endpoint.</p>"},{"location":"start-here/pilot-plan/#prerequisites-non-negotiable","title":"Prerequisites (non-negotiable)","text":"<p>You need the ability to produce:</p> <ul> <li>exposure logs (what was served, with ranks)</li> <li>outcome logs (what the user did)</li> <li>stable IDs for joins (a <code>request_id</code>, plus a pseudonymous <code>user_id</code> or session identifier)</li> </ul> <p>See: <code>reference/data-contracts/index.md</code></p>"},{"location":"start-here/pilot-plan/#phase-1-week-1-baseline-instrumentation","title":"Phase 1 (Week 1): baseline + instrumentation","text":"<p>Goal: ship a safe baseline and prove you can measure it.</p> <p>Deliverables:</p> <ul> <li>One surface integrated end-to-end (client \u2192 <code>recsys-service</code> \u2192 response rendered)</li> <li>Exposure + outcome logging wired from production-like traffic (even if small)</li> <li>First <code>recsys-eval</code> report generated from real logs (joins validated)</li> <li>Runbooks exercised once: \u201cservice not ready\u201d, \u201cempty recs\u201d</li> </ul> <p>Recommended scope:</p> <ul> <li>Start in DB-only mode to minimize moving parts.</li> <li>Use a deterministic baseline algorithm (popularity is fine).</li> </ul> <p>Exit criteria:</p> <ul> <li><code>recsys-eval validate</code> succeeds for your logs</li> <li>P95 latency and error rate are within acceptable bounds for your product</li> </ul>"},{"location":"start-here/pilot-plan/#phase-2-weeks-23-improve-relevance-safely","title":"Phase 2 (Weeks 2\u20133): improve relevance safely","text":"<p>Goal: add one higher-signal candidate source and gain iteration speed.</p> <p>Typical upgrades:</p> <ul> <li>similarity/co-visitation signals (often high ROI with modest complexity)</li> <li>basic business rules (pin/exclude, constraints) for control and trust</li> <li>segmentation (by surface, locale, tenant, or other stable context keys)</li> </ul> <p>Deliverables:</p> <ul> <li>A second algorithm/config version evaluated against baseline (offline)</li> <li>A small \u201cship checklist\u201d used before rollout (what changed, how to roll back)</li> <li>A rollback drill completed once (config/rules and/or artifact manifest)</li> </ul> <p>Exit criteria:</p> <ul> <li>Offline evaluation shows a consistent improvement (or a clear tradeoff you accept)</li> <li>You can roll back within minutes with a known procedure</li> </ul>"},{"location":"start-here/pilot-plan/#phase-3-weeks-46-production-hardening-experimentation","title":"Phase 3 (Weeks 4\u20136): production hardening + experimentation","text":"<p>Goal: move from \u201cworks\u201d to \u201coperationally safe\u201d.</p> <p>Typical additions:</p> <ul> <li>artifact/manifest mode (pipelines publish versioned artifacts; service reads a manifest pointer)</li> <li>A/B experiments for key surfaces with clear guardrails</li> <li>SLOs and alerting: latency, error rate, empty-recs rate, artifact freshness</li> </ul> <p>Deliverables:</p> <ul> <li>A documented on-call playbook and escalation path</li> <li>Production readiness checklist completed</li> <li>One controlled experiment run (even if only to validate instrumentation)</li> </ul> <p>Exit criteria:</p> <ul> <li>On-call can triage common failures from runbooks</li> <li>Changes are shipped with gates and are reversible</li> </ul>"},{"location":"start-here/pilot-plan/#read-next","title":"Read next","text":"<ul> <li>Stakeholder overview: <code>start-here/what-is-recsys.md</code></li> <li>Responsibilities (RACI): <code>start-here/responsibilities.md</code></li> <li>Security and privacy overview: <code>start-here/security-privacy-compliance.md</code></li> <li>Local end-to-end tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>Production readiness checklist: <code>operations/production-readiness-checklist.md</code></li> </ul>"},{"location":"start-here/repo-layout/","title":"Repo layout and Go module paths","text":"<p>This repository is hosted at <code>github.com/aatuh/recsys</code>, but the Go module import paths currently use the <code>github.com/aatuh/recsys-suite/...</code> prefix. This page explains how to navigate the repo and how to use the modules.</p>"},{"location":"start-here/repo-layout/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers reading the codebase for the first time</li> <li>Integrators who want to build/bump module versions independently</li> <li>Anyone confused by repo name vs Go module import paths</li> </ul>"},{"location":"start-here/repo-layout/#what-you-will-get","title":"What you will get","text":"<ul> <li>Where each module lives in the repo</li> <li>The Go import paths to use in each module</li> <li>The release/tagging convention used by the suite</li> </ul>"},{"location":"start-here/repo-layout/#repo-layout-what-lives-where","title":"Repo layout (what lives where)","text":"<ul> <li><code>api/</code>: <code>recsys-service</code> (the online HTTP API)</li> <li><code>recsys-algo/</code>: <code>recsys-algo</code> (the deterministic ranking core)</li> <li><code>recsys-pipelines/</code>: <code>recsys-pipelines</code> (offline pipelines that build artifacts/signals)</li> <li><code>recsys-eval/</code>: <code>recsys-eval</code> (evaluation tooling and report generation)</li> </ul> <p>Each module is a standalone Go module with its own <code>go.mod</code>, tests, and <code>Makefile</code>.</p>"},{"location":"start-here/repo-layout/#go-module-paths-what-you-go-get","title":"Go module paths (what you <code>go get</code>)","text":"<ul> <li><code>recsys-service</code> module: <code>github.com/aatuh/recsys-suite/api</code></li> <li><code>recsys-algo</code> module: <code>github.com/aatuh/recsys-suite/api/recsys-algo</code></li> <li><code>recsys-pipelines</code> module: <code>github.com/aatuh/recsys-suite/recsys-pipelines</code></li> <li><code>recsys-eval</code> module: <code>github.com/aatuh/recsys-suite/recsys-eval</code></li> </ul>"},{"location":"start-here/repo-layout/#versioning-and-tags","title":"Versioning and tags","text":"<p>Each module is versioned independently. Tags are module-prefixed, for example:</p> <ul> <li><code>recsys-eval/v0.2.0</code></li> <li><code>recsys-pipelines/v0.2.0</code></li> <li><code>recsys-algo/v0.2.0</code></li> </ul>"},{"location":"start-here/repo-layout/#developing-locally-no-gowork-required","title":"Developing locally (no <code>go.work</code> required)","text":"<p>There is no repo-level <code>go.work</code> today. The recommended workflow is:</p> <ul> <li>run builds/tests from within each module directory (e.g., <code>cd recsys-eval &amp;&amp; make test</code>)</li> <li>use Docker Compose for the service when you want the full local stack (<code>make dev</code>)</li> </ul> <p>The <code>api/</code> module uses <code>replace</code> directives for local development (for example, to use the local <code>../recsys-algo</code>).</p>"},{"location":"start-here/repo-layout/#read-next","title":"Read next","text":"<ul> <li>Suite architecture (what runs where): <code>explanation/suite-architecture.md</code></li> <li>Local end-to-end tutorial: <code>tutorials/local-end-to-end.md</code></li> </ul>"},{"location":"start-here/responsibilities/","title":"Responsibilities (RACI): who owns what","text":""},{"location":"start-here/responsibilities/#who-this-is-for","title":"Who this is for","text":"<p>Engineering leads, product owners, SRE/on-call, and security reviewers planning a pilot or production rollout of the RecSys suite.</p>"},{"location":"start-here/responsibilities/#what-you-will-get","title":"What you will get","text":"<ul> <li>A shared-responsibility model for adopting the RecSys suite</li> <li>A RACI matrix you can use during procurement and delivery planning</li> <li>Clear handoffs between integration, data, and operations</li> </ul>"},{"location":"start-here/responsibilities/#default-responsibility-model","title":"Default responsibility model","text":"<p>By default, the RecSys suite is self-hosted: your organization runs the infrastructure and owns the data. The maintainers provide the software, documentation, and support channels.</p> <p>If you operate the suite as a managed service, the same responsibilities exist but the owner per row may change.</p>"},{"location":"start-here/responsibilities/#roles-used-in-the-raci","title":"Roles used in the RACI","text":"<ul> <li>PO: Product owner (business outcomes, prioritization)</li> <li>App: Application team (frontend/backend integration)</li> <li>Data: Data engineering / analytics (events, pipelines, evaluation)</li> <li>SRE: Platform / SRE / on-call (infra, deploys, monitoring, incidents)</li> <li>Sec: Security / compliance (PII, access controls, risk review)</li> <li>RecSys: RecSys suite maintainers/support (product expertise, reviews, escalation)</li> </ul> <p>Legend:</p> <ul> <li>R = Responsible (does the work)</li> <li>A = Accountable (owns the outcome)</li> <li>C = Consulted (gives input)</li> <li>I = Informed (kept in the loop)</li> </ul>"},{"location":"start-here/responsibilities/#pilot-raci-db-only-mode","title":"Pilot RACI (DB-only mode)","text":"<p>In DB-only mode you can validate the full \u201cserve \u2192 log \u2192 eval\u201d loop without object storage or pipelines.</p> Activity PO App Data SRE Sec RecSys Define surfaces and success metrics A/R C C I I C Provision dev/staging environments (DB, deploy) I I C A/R C C Integrate <code>recsys-service</code> API into one surface C A/R C C I C Propagate <code>request_id</code> and stable IDs C A/R C C I C Emit exposure logs and outcome logs C R A/R C C C Run offline evaluation (<code>recsys-eval</code>) and review results C C A/R I I C Operate runbooks (empty recs / not ready) I C C A/R I C Decide what to ship (gate/rollout plan) A/R C C C C C"},{"location":"start-here/responsibilities/#production-raci-artifactmanifest-pipelines","title":"Production RACI (artifact/manifest + pipelines)","text":"<p>Artifact/manifest mode adds a second \u201csupply chain\u201d: pipelines publish versioned signals and a manifest; the service reads the manifest pointer.</p> Activity PO App Data SRE Sec RecSys Deploy <code>recsys-service</code> to production (auth, tenancy, limits) I C C A/R C C Run pipelines on schedule and publish manifests I I A/R C I C Monitor freshness, latency, and empty-recs rate I I C A/R I C Roll back config/rules and/or manifest on incident I C C A/R I C Security review (PII, retention, access, audit) I C C C A/R C Post-incident review and follow-ups A/R C C C C I"},{"location":"start-here/responsibilities/#read-next","title":"Read next","text":"<ul> <li>Pilot plan: <code>start-here/pilot-plan.md</code></li> <li>Security and privacy overview: <code>start-here/security-privacy-compliance.md</code></li> <li>Local end-to-end tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>Production readiness checklist: <code>operations/production-readiness-checklist.md</code></li> </ul>"},{"location":"start-here/security-privacy-compliance/","title":"Security, privacy, and compliance (overview)","text":""},{"location":"start-here/security-privacy-compliance/#who-this-is-for","title":"Who this is for","text":"<p>Engineering leads, product owners, SRE/on-call, and security/compliance reviewers evaluating or adopting the RecSys suite.</p>"},{"location":"start-here/security-privacy-compliance/#what-you-will-get","title":"What you will get","text":"<ul> <li>A practical \u201cshared responsibility\u201d view for running the suite</li> <li>The minimum privacy posture needed for a pilot (and what changes for production)</li> <li>A checklist for security review starting points</li> </ul>"},{"location":"start-here/security-privacy-compliance/#scope-what-the-suite-is-and-is-not","title":"Scope: what the suite is (and is not)","text":"<ul> <li>The RecSys suite is typically self-hosted: you run the infrastructure and own the data.</li> <li>The suite does not attempt to be a full privacy/compliance program. You still need org-level policies for:</li> <li>data classification and retention</li> <li>access control and auditing</li> <li>data subject requests (GDPR/CCPA) and deletion workflows</li> </ul>"},{"location":"start-here/security-privacy-compliance/#data-you-will-handle","title":"Data you will handle","text":"<p>At a minimum, adopting the suite introduces these data flows:</p> <ul> <li>Serving requests: <code>tenant_id</code>, <code>surface</code>, and a pseudonymous <code>user_id</code>/<code>session_id</code> context</li> <li>Exposure logs: the ranked list served, with ranks and a <code>request_id</code> for attribution</li> <li>Outcome logs: clicks/conversions with the same <code>request_id</code></li> <li>Artifacts (optional): aggregated signals (popularity, co-visitation, etc.) stored in object storage</li> </ul> <p>Treat exposure and outcome logs as sensitive. Even if identifiers are pseudonymous, they are often still considered personal data under many policies.</p>"},{"location":"start-here/security-privacy-compliance/#identity-and-pii-guidance-baseline","title":"Identity and PII guidance (baseline)","text":"<ul> <li>Do not send or log raw PII (email, phone, address).</li> <li>Prefer pseudonymous, stable identifiers (for example: an internal UUID or a one-way hash you control).</li> <li>If you enable eval-compatible exposure logs in <code>recsys-service</code>, set a secret salt:</li> <li><code>EXPOSURE_HASH_SALT=&lt;secret&gt;</code></li> </ul> <p>Changing the salt breaks joins over time; rotate intentionally (and treat it like a credential).</p>"},{"location":"start-here/security-privacy-compliance/#access-control-and-hardening","title":"Access control and hardening","text":""},{"location":"start-here/security-privacy-compliance/#auth-modes","title":"Auth modes","text":"<p><code>recsys-service</code> supports JWT and API keys. For local development it can also accept dev headers.</p> <p>Production guidance:</p> <ul> <li>Disable dev headers: <code>DEV_AUTH_ENABLED=false</code></li> <li>Require production auth (<code>JWT_AUTH_ENABLED=true</code> and/or <code>API_KEY_ENABLED=true</code>)</li> <li>Ensure tenant scope comes from trusted auth claims (<code>AUTH_TENANT_CLAIMS</code>) or a trusted gateway</li> </ul>"},{"location":"start-here/security-privacy-compliance/#admin-endpoints","title":"Admin endpoints","text":"<p>Admin endpoints can change configuration/rules and invalidate caches. Treat them as control-plane:</p> <ul> <li>restrict network access (private ingress / allow-list / VPN)</li> <li>require admin roles (<code>AUTH_ADMIN_ROLE</code>) and strong identity</li> <li>enable audit logging for admin actions (<code>AUDIT_LOG_ENABLED=true</code>)</li> </ul>"},{"location":"start-here/security-privacy-compliance/#rate-limiting-and-abuse","title":"Rate limiting and abuse","text":"<p>Enable per-tenant rate limiting in production and monitor throttling:</p> <ul> <li><code>TENANT_RATE_LIMIT_ENABLED=true</code></li> </ul>"},{"location":"start-here/security-privacy-compliance/#logging-and-retention","title":"Logging and retention","text":"<ul> <li>Configure exposure logging intentionally:</li> <li><code>EXPOSURE_LOG_ENABLED=true</code></li> <li>set retention (<code>EXPOSURE_LOG_RETENTION_DAYS</code>) and storage controls (permissions, encryption, backups)</li> <li>Treat evaluation outputs as sensitive artifacts:</li> <li>reports may reveal behavior patterns or business logic</li> <li>store them with appropriate access control and retention</li> </ul>"},{"location":"start-here/security-privacy-compliance/#compliance-notes-high-level","title":"Compliance notes (high level)","text":"<ul> <li>GDPR/CCPA: pseudonymous identifiers can still be personal data. Plan for deletion and retention limits.</li> <li>Data residency: choose DB/object store regions consistent with your policy.</li> <li>Auditability: enable audit logs and keep <code>request_id</code> propagation end-to-end for investigations.</li> </ul>"},{"location":"start-here/security-privacy-compliance/#quick-checklist-start-here","title":"Quick checklist (start here)","text":"<ul> <li>[ ] Use pseudonymous IDs; do not log raw PII.</li> <li>[ ] Set <code>EXPOSURE_HASH_SALT</code> when logging exposures for evaluation.</li> <li>[ ] Disable dev auth headers in production (<code>DEV_AUTH_ENABLED=false</code>).</li> <li>[ ] Restrict admin endpoints (network + roles) and enable audit logging.</li> <li>[ ] Define retention for exposure/outcome logs and evaluation reports.</li> </ul>"},{"location":"start-here/security-privacy-compliance/#read-next","title":"Read next","text":"<ul> <li>Responsibilities (RACI): <code>start-here/responsibilities.md</code></li> <li>Production readiness checklist: <code>operations/production-readiness-checklist.md</code></li> <li>Exposure logging and attribution: <code>explanation/exposure-logging-and-attribution.md</code></li> <li>Security policy (reporting vulnerabilities): <code>project/security.md</code></li> </ul>"},{"location":"start-here/what-is-recsys/","title":"What the RecSys suite is (stakeholder overview)","text":""},{"location":"start-here/what-is-recsys/#who-this-is-for","title":"Who this is for","text":"<p>Product managers, business stakeholders, and engineering leads evaluating whether to adopt the RecSys suite.</p>"},{"location":"start-here/what-is-recsys/#what-you-will-get","title":"What you will get","text":"<ul> <li>A plain-language description of what the suite does (and does not do)</li> <li>Typical use cases and success metrics</li> <li>The minimum data you must provide</li> <li>A realistic pilot \u2192 production timeline</li> </ul>"},{"location":"start-here/what-is-recsys/#what-the-recsys-suite-is","title":"What the RecSys suite is","text":"<p>The RecSys suite is an end-to-end, production-oriented recommendation system toolkit:</p> <ul> <li><code>recsys-service</code>: the online HTTP API (auth, tenancy, caching, limits, exposure logging)</li> <li><code>recsys-algo</code>: the deterministic ranking core (candidate merge, scoring, constraints, rules)</li> <li><code>recsys-pipelines</code>: offline pipelines that turn events into versioned signals/artifacts</li> <li><code>recsys-eval</code>: evaluation tooling to measure quality and decide what to ship</li> </ul> <p>Design intent: predictable, auditable behavior before \u201cblack-box\u201d modeling. You can roll out changes safely, explain what changed, and roll back by version.</p>"},{"location":"start-here/what-is-recsys/#what-you-can-build-with-it","title":"What you can build with it","text":"<p>Common product placements:</p> <ul> <li>Homepage / feed recommendations (\u201cfor you\u201d, \u201cpopular now\u201d)</li> <li>PDP \u201csimilar items\u201d</li> <li>\u201cRelated content\u201d blocks (articles, videos, collections)</li> </ul> <p>Common operational needs it supports:</p> <ul> <li>Controlled outcomes via rules (pin/exclude, constraints)</li> <li>Multi-tenant operation (per-org configuration and isolation)</li> <li>\u201cShip/rollback\u201d discipline (versioned config/rules/manifests)</li> </ul>"},{"location":"start-here/what-is-recsys/#how-success-is-measured","title":"How success is measured","text":"<p>You typically measure success in two layers:</p> <p>1) Business metrics (what leadership cares about)    - click-through rate (CTR), conversion rate (CVR), revenue per session    - retention / repeat visits (when applicable)</p> <p>2) Recommendation metrics (what helps you iterate safely)    - offline metrics like hitrate@k and precision@k (in <code>recsys-eval</code>)    - online experiments (A/B) to validate impact in production</p> <p>Operationally, you also track:</p> <ul> <li>P95/P99 latency and error rate</li> <li>\u201cempty recs\u201d rate (a key indicator of data/config issues)</li> </ul>"},{"location":"start-here/what-is-recsys/#what-data-you-need-minimum","title":"What data you need (minimum)","text":"<p>You need identifiers and events that can connect \u201cwhat was served\u201d to \u201cwhat the user did\u201d.</p> <p>Minimum inputs:</p> <ul> <li>An item catalog (<code>item_id</code> + basic metadata/tags)</li> <li>Interaction events (click/purchase/etc) with:</li> <li><code>tenant_id</code> (org/account)</li> <li><code>item_id</code></li> <li><code>event_type</code></li> <li>timestamp (<code>occurred_at</code>)</li> </ul> <p>Strongly recommended for evaluation:</p> <ul> <li>A stable, pseudonymous <code>user_id</code> (do not log raw PII)</li> <li>A <code>request_id</code> you can propagate from serving \u2192 outcomes so evaluation can join correctly</li> <li>Exposure logs (the ranked list you showed, with ranks)</li> </ul> <p>See: <code>reference/data-contracts/index.md</code></p>"},{"location":"start-here/what-is-recsys/#timeline-pilot-production-typical","title":"Timeline: pilot \u2192 production (typical)","text":"<p>Every company\u2019s data readiness differs, but a realistic plan is:</p> <ul> <li>Week 1: baseline + instrumentation</li> <li>stand up the service in a dev environment (DB-only mode is the fastest start)</li> <li>integrate a placement and log exposures + outcomes</li> <li> <p>run <code>recsys-eval</code> on real logs to validate joins and sanity metrics</p> </li> <li> <p>Weeks 2\u20133: improve relevance safely</p> </li> <li>add similarity/co-visitation signals via pipelines (optional but high ROI)</li> <li>introduce simple rules (pin/exclude) for business control</li> <li> <p>iterate with offline evaluation, then ship to a small audience</p> </li> <li> <p>Weeks 4\u20136: production hardening + experimentation</p> </li> <li>set SLOs and add runbooks to on-call rotation</li> <li>enable controlled A/B tests for key surfaces</li> <li>expand to more placements and segments</li> </ul>"},{"location":"start-here/what-is-recsys/#read-next","title":"Read next","text":"<ul> <li>Start here (engineers): <code>start-here/index.md</code></li> <li>Pilot plan: <code>start-here/pilot-plan.md</code></li> <li>Local end-to-end tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>Known limitations: <code>start-here/known-limitations.md</code></li> </ul>"},{"location":"start-here/diagrams/suite-context/","title":"Suite Context","text":"<p><code>mermaid flowchart LR   C[Client] --&gt; S[recsys-service]   S --&gt; A[recsys-algo]   S --&gt; E[(Exposures)]   C --&gt; O[(Outcomes)]   E --&gt; P[recsys-pipelines]   O --&gt; P   P --&gt; M[(Manifest)]   M --&gt; S   E --&gt; V[recsys-eval]   O --&gt; V   V --&gt; D[Decision]   D --&gt; S</code></p>"},{"location":"tutorials/local-end-to-end/","title":"Tutorial: local end-to-end (service \u2192 logging \u2192 eval)","text":"<p>Goal: serve non-empty recommendations locally, emit an eval-compatible exposure log, and generate a <code>recsys-eval</code> report.</p> <p>This tutorial uses DB-only mode (fastest way to prove the loop locally). Artifact/manifest mode with pipelines is linked at the end.</p>"},{"location":"tutorials/local-end-to-end/#prereqs","title":"Prereqs","text":"<ul> <li>Docker + Docker Compose</li> <li>curl</li> <li>POSIX shell</li> <li>Go toolchain (to build <code>recsys-eval</code>)</li> </ul>"},{"location":"tutorials/local-end-to-end/#expected-outcome","title":"Expected outcome","text":"<ul> <li><code>POST /v1/recommend</code> returns a non-empty list for tenant <code>demo</code> and surface <code>home</code></li> <li>A local exposure log file exists (eval schema)</li> <li><code>recsys-eval run</code> produces a Markdown report</li> </ul>"},{"location":"tutorials/local-end-to-end/#1-start-postgres-recsys-service","title":"1) Start Postgres + recsys-service","text":"<p>From repo root:</p> <pre><code>test -f api/.env || cp api/.env.example api/.env\nmake dev\n</code></pre> <p>Apply database migrations (idempotent):</p> <pre><code>(cd api &amp;&amp; make migrate-up)\n</code></pre> <p>Verify:</p> <pre><code>curl -fsS http://localhost:8000/healthz &gt;/dev/null\n</code></pre>"},{"location":"tutorials/local-end-to-end/#2-configure-local-dev-for-a-runnable-tutorial","title":"2) Configure local dev for a runnable tutorial","text":"<p>This tutorial uses dev headers for auth and disables admin RBAC roles so you can call admin endpoints without JWT claims.</p> <p>Edit <code>api/.env</code> and set:</p> <pre><code># DB-only mode (no artifact manifest)\nRECSYS_ARTIFACT_MODE_ENABLED=false\n\n# Make requests deterministic\nRECSYS_ALGO_MODE=popularity\n\n# Enable rules so you can prove control-plane wiring (pin/exclude) works\nRECSYS_ALGO_RULES_ENABLED=true\n\n# Enable eval-compatible exposure logs\nEXPOSURE_LOG_ENABLED=true\nEXPOSURE_LOG_FORMAT=eval_v1\nEXPOSURE_LOG_PATH=/app/tmp/exposures.eval.jsonl\n\n# Local dev: disable admin RBAC roles (dev headers don\u2019t carry roles)\nAUTH_VIEWER_ROLE=\nAUTH_OPERATOR_ROLE=\nAUTH_ADMIN_ROLE=\n</code></pre> <p>Restart the service:</p> <pre><code>docker compose up -d --force-recreate api\n</code></pre>"},{"location":"tutorials/local-end-to-end/#3-bootstrap-a-demo-tenant-postgres","title":"3) Bootstrap a demo tenant (Postgres)","text":"<p>Insert a tenant row:</p> <pre><code>docker exec -i recsys-db psql -U recsys-db -d recsys-db &lt;&lt;'SQL'\ninsert into tenants (external_id, name)\nvalues ('demo', 'Demo Tenant')\non conflict (external_id) do nothing;\nSQL\n</code></pre>"},{"location":"tutorials/local-end-to-end/#4-create-minimal-tenant-config-and-rules-admin-api","title":"4) Create minimal tenant config and rules (admin API)","text":"<p>Create a small config document:</p> <pre><code>cat &gt; /tmp/demo_config.json &lt;&lt;'JSON'\n{\n  \"weights\": { \"pop\": 1.0, \"cooc\": 0.0, \"emb\": 0.0 },\n  \"flags\": { \"enable_rules\": true },\n  \"limits\": { \"max_k\": 50, \"max_exclude_ids\": 200 }\n}\nJSON\n</code></pre> <p>Upsert config:</p> <pre><code>curl -fsS -X PUT http://localhost:8000/v1/admin/tenants/demo/config \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d @/tmp/demo_config.json\n</code></pre> <p>Create a small rules document (pin <code>item_3</code> to prove control works):</p> <pre><code>cat &gt; /tmp/demo_rules.json &lt;&lt;'JSON'\n[\n  {\n    \"action\": \"pin\",\n    \"target_type\": \"item\",\n    \"item_ids\": [\"item_3\"],\n    \"surface\": \"home\",\n    \"priority\": 10\n  }\n]\nJSON\n</code></pre> <p>Upsert rules:</p> <pre><code>curl -fsS -X PUT http://localhost:8000/v1/admin/tenants/demo/rules \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d @/tmp/demo_rules.json\n</code></pre>"},{"location":"tutorials/local-end-to-end/#5-seed-minimal-db-only-signals-tags-popularity","title":"5) Seed minimal DB-only signals (tags + popularity)","text":"<p>Seed <code>item_tags</code> and <code>item_popularity_daily</code> for surface <code>home</code>:</p> <pre><code>docker exec -i recsys-db psql -U recsys-db -d recsys-db &lt;&lt;'SQL'\nwith t as (\n  select id as tenant_id\n    from tenants\n   where external_id = 'demo'\n)\ninsert into item_tags (tenant_id, namespace, item_id, tags, price, created_at)\nselect tenant_id, 'home', 'item_1', array['brand:nike','category:shoes'], 99.90, now() from t\nunion all\nselect tenant_id, 'home', 'item_2', array['brand:nike','category:shoes'], 79.00, now() from t\nunion all\nselect tenant_id, 'home', 'item_3', array['brand:acme','category:socks'], 12.00, now() from t\non conflict (tenant_id, namespace, item_id)\ndo update set tags = excluded.tags,\n              price = excluded.price,\n              created_at = excluded.created_at;\n\nwith t as (\n  select id as tenant_id\n    from tenants\n   where external_id = 'demo'\n)\ninsert into item_popularity_daily (tenant_id, namespace, item_id, day, score)\nselect tenant_id, 'home', 'item_1', current_date, 10 from t\nunion all\nselect tenant_id, 'home', 'item_2', current_date, 7 from t\nunion all\nselect tenant_id, 'home', 'item_3', current_date, 3 from t\non conflict (tenant_id, namespace, item_id, day)\ndo update set score = excluded.score;\nSQL\n</code></pre>"},{"location":"tutorials/local-end-to-end/#6-call-v1recommend-and-verify-non-empty-output","title":"6) Call <code>/v1/recommend</code> and verify non-empty output","text":"<p>Send a request with deterministic <code>request_id</code>:</p> <pre><code>curl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: req-1' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"u_1\",\"session_id\":\"s_1\"}}'\n</code></pre> <p>You should see <code>items</code> with <code>item_id</code> values like <code>item_1</code>, <code>item_2</code>, <code>item_3</code>.</p> <p>Because you pinned <code>item_3</code>, it should appear first in the list.</p> <p>Example response shape:</p> <pre><code>{\n  \"items\": [{ \"item_id\": \"item_3\", \"rank\": 1, \"score\": 0.12 }],\n  \"meta\": {\n    \"tenant_id\": \"demo\",\n    \"surface\": \"home\",\n    \"config_version\": \"W/\\\"...\\\"\",\n    \"rules_version\": \"W/\\\"...\\\"\",\n    \"request_id\": \"req-1\"\n  },\n  \"warnings\": []\n}\n</code></pre> <p>If you get an empty list, check:</p> <ul> <li>you inserted rows into <code>item_popularity_daily</code> for <code>namespace='home'</code></li> <li>you are calling the API with <code>surface=home</code></li> </ul>"},{"location":"tutorials/local-end-to-end/#7-extract-the-exposure-log-and-create-a-tiny-outcome-log","title":"7) Extract the exposure log and create a tiny outcome log","text":"<p>Copy the exposure file out of the container:</p> <pre><code>docker cp recsys-svc:/app/tmp/exposures.eval.jsonl /tmp/exposures.jsonl\n</code></pre> <p>Extract the hashed <code>user_id</code> from the exposure file (this is what <code>recsys-service</code> logs for eval format):</p> <pre><code>EXPOSURE_USER_ID=\"$(python3 -c 'import json; print(json.loads(open(\\\"/tmp/exposures.jsonl\\\").readline())[\\\"user_id\\\"])')\"\n</code></pre> <p>Create a minimal outcome log that joins by <code>request_id</code> (and matches the exposure <code>user_id</code>):</p> <pre><code>OUTCOME_TS=\"$(date -u +%Y-%m-%dT%H:%M:%SZ)\"\ncat &gt; /tmp/outcomes.jsonl &lt;&lt;JSONL\n{\"request_id\":\"req-1\",\"user_id\":\"${EXPOSURE_USER_ID}\",\"item_id\":\"item_3\",\"event_type\":\"click\",\"ts\":\"${OUTCOME_TS}\"}\nJSONL\n</code></pre>"},{"location":"tutorials/local-end-to-end/#8-run-recsys-eval-on-the-logs","title":"8) Run <code>recsys-eval</code> on the logs","text":"<p>Create a dataset config:</p> <pre><code>cat &gt; /tmp/dataset.yaml &lt;&lt;'YAML'\nexposures:\n  type: jsonl\n  path: /tmp/exposures.jsonl\noutcomes:\n  type: jsonl\n  path: /tmp/outcomes.jsonl\nYAML\n</code></pre> <p>Create a minimal offline config (slice keys match the service <code>eval_v1</code> context keys):</p> <pre><code>cat &gt; /tmp/eval.yaml &lt;&lt;'YAML'\nmode: offline\noffline:\n  metrics:\n    - name: hitrate\n      k: 5\n    - name: precision\n      k: 5\n  slice_keys: [\"tenant_id\", \"surface\"]\n  gates: []\nscale:\n  mode: memory\nYAML\n</code></pre> <p>Build + run:</p> <pre><code>(cd recsys-eval &amp;&amp; make build)\n\nrecsys-eval/bin/recsys-eval validate --schema exposure.v1 --input /tmp/exposures.jsonl\nrecsys-eval/bin/recsys-eval validate --schema outcome.v1 --input /tmp/outcomes.jsonl\n\nrecsys-eval/bin/recsys-eval run \\\n  --mode offline \\\n  --dataset /tmp/dataset.yaml \\\n  --config /tmp/eval.yaml \\\n  --output /tmp/recsys_eval_report.md \\\n  --output-format markdown\n</code></pre> <p>Inspect the report:</p> <pre><code>sed -n '1,80p' /tmp/recsys_eval_report.md\n</code></pre> <p>You should see an \u201cOffline Metrics\u201d table with values like:</p> <pre><code>| hitrate@5 | 1.000000 |\n| precision@5 | 0.333333 |\n</code></pre>"},{"location":"tutorials/local-end-to-end/#9-optional-run-pipelines-once-produces-a-manifest","title":"9) (Optional) Run pipelines once (produces a manifest)","text":"<p>This step proves <code>recsys-pipelines</code> can produce artifacts and a manifest from events.</p> <p>Ensure MinIO is up:</p> <pre><code>curl -fsS http://localhost:9000/minio/health/ready &gt;/dev/null\n</code></pre> <p>Build + run one day from the tiny pipelines dataset:</p> <pre><code>(cd recsys-pipelines &amp;&amp; make build)\n\n(cd recsys-pipelines &amp;&amp; ./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-01)\n</code></pre> <p>Verify the local manifest exists:</p> <pre><code>cat recsys-pipelines/.out/registry/current/demo/home/manifest.json\n</code></pre> <p>Verify artifacts exist in MinIO (paths are under the <code>recsys/</code> prefix by default):</p> <pre><code>docker compose run --rm --entrypoint sh minio-init -c \\\n  'mc alias set local http://minio:9000 minioadmin minioadmin &gt;/dev/null &amp;&amp; \\\n   mc ls local/recsys-artifacts/recsys/demo/home/ | head'\n</code></pre>"},{"location":"tutorials/local-end-to-end/#appendix-success-criteria-and-troubleshooting","title":"Appendix: success criteria and troubleshooting","text":""},{"location":"tutorials/local-end-to-end/#success-criteria-quick-checks","title":"Success criteria (quick checks)","text":"<ul> <li>Service is healthy: <code>curl -fsS http://localhost:8000/readyz &gt;/dev/null</code></li> <li>Tenant exists:</li> </ul> <pre><code>docker exec -i recsys-db psql -U recsys-db -d recsys-db -c \\\"select external_id from tenants;\\\"\n</code></pre> <ul> <li>Config and rules exist:</li> </ul> <pre><code>curl -fsS http://localhost:8000/v1/admin/tenants/demo/config \\\\\n  -H 'X-Dev-User-Id: dev-user-1' -H 'X-Dev-Org-Id: demo' -H 'X-Org-Id: demo'\ncurl -fsS http://localhost:8000/v1/admin/tenants/demo/rules \\\\\n  -H 'X-Dev-User-Id: dev-user-1' -H 'X-Dev-Org-Id: demo' -H 'X-Org-Id: demo'\n</code></pre> <ul> <li>Exposure log exists: <code>test -s /tmp/exposures.jsonl</code></li> <li>Eval report exists: <code>test -s /tmp/recsys_eval_report.md</code></li> </ul>"},{"location":"tutorials/local-end-to-end/#common-failures","title":"Common failures","text":"<ul> <li><code>401/403</code> from admin or recommend endpoints</li> <li>Check you set <code>AUTH_*_ROLE=</code> empty in <code>api/.env</code> and recreated the <code>api</code> container.</li> <li>Ensure you send both <code>X-Dev-Org-Id</code> and <code>X-Org-Id</code> headers.</li> <li>Empty recommendations</li> <li>Check <code>item_popularity_daily</code> has rows for <code>namespace='home'</code> and for <code>day=current_date</code>.</li> <li>Pipelines cannot connect to MinIO</li> <li>Ensure <code>curl -fsS http://localhost:9000/minio/health/ready</code> succeeds.</li> </ul>"},{"location":"tutorials/local-end-to-end/#next-pipelines-artifactmanifest-mode-production-like","title":"Next: pipelines + artifact/manifest mode (production-like)","text":"<ul> <li>Production-like suite tutorial: <code>tutorials/production-like-run.md</code></li> <li>Pipelines local quickstart: <code>recsys-pipelines/docs/tutorials/local-quickstart.md</code></li> <li>How to operate pipelines: <code>how-to/operate-pipelines.md</code></li> <li>Background: <code>explanation/data-modes.md</code></li> </ul>"},{"location":"tutorials/minimal-pilot-db-only/","title":"Tutorial: minimal pilot mode (DB-only, popularity baseline)","text":""},{"location":"tutorials/minimal-pilot-db-only/#who-this-is-for","title":"Who this is for","text":"<p>Product owners and engineering leads who want a low-friction pilot of the RecSys suite without object storage or offline pipelines.</p>"},{"location":"tutorials/minimal-pilot-db-only/#what-you-will-get","title":"What you will get","text":"<ul> <li>A popularity-only baseline you can ship safely</li> <li>The minimum instrumentation needed to measure impact</li> <li>A clear list of what this mode proves (and what it does not)</li> </ul>"},{"location":"tutorials/minimal-pilot-db-only/#what-this-pilot-answers-business-engineering","title":"What this pilot answers (business + engineering)","text":"<p>With DB-only + popularity, you can answer:</p> <ul> <li>Can we integrate a recommendation placement end-to-end (API \u2192 UI render)?</li> <li>Can we attribute outcomes to exposures (do joins work)?</li> <li>Are latency, error rate, and \u201cempty recs\u201d within acceptable bounds?</li> <li>Do we have the data and IDs needed to evaluate and iterate?</li> </ul> <p>This pilot does not answer \u201chow good is personalization\u201d. It answers \u201cis the loop operationally real\u201d.</p>"},{"location":"tutorials/minimal-pilot-db-only/#prereqs","title":"Prereqs","text":"<ul> <li>One surface to start (for example: <code>home</code>)</li> <li>A way to generate or propagate a stable <code>request_id</code> per rendered list</li> <li>A pseudonymous <code>user_id</code> or <code>session_id</code> you can use consistently</li> </ul>"},{"location":"tutorials/minimal-pilot-db-only/#minimal-data-you-need-db-only-signals","title":"Minimal data you need (DB-only signals)","text":"<p>Populate these Postgres tables for your tenant:</p> <ul> <li><code>item_tags</code> (catalog + tags used for constraints and filters)</li> <li><code>item_popularity_daily</code> (daily popularity score per item and surface/namespace)</li> </ul> <p>The fastest approach is to backfill a small set of top items (for one surface) and refresh daily.</p>"},{"location":"tutorials/minimal-pilot-db-only/#steps-recommended","title":"Steps (recommended)","text":"<ol> <li>Run the runnable local tutorial once (proves the loop end-to-end):</li> <li> <p><code>tutorials/local-end-to-end.md</code></p> </li> <li> <p>Replace the seed SQL with your own data loading:</p> </li> <li>Load <code>item_tags</code> from your catalog.</li> <li> <p>Load <code>item_popularity_daily</code> from page views / purchases / clicks (your choice).</p> </li> <li> <p>Integrate one placement in your product:</p> </li> <li>Use <code>POST /v1/recommend</code> with a stable <code>request_id</code>.</li> <li> <p>Log exposures and outcomes with that same <code>request_id</code>.</p> </li> <li> <p>Run evaluation on real logs early:</p> </li> <li>Validate schemas and compute join rates.</li> </ol>"},{"location":"tutorials/minimal-pilot-db-only/#read-next","title":"Read next","text":"<ul> <li>Pilot plan: <code>start-here/pilot-plan.md</code></li> <li>Integrate service: <code>how-to/integrate-recsys-service.md</code></li> <li>Data contracts hub: <code>reference/data-contracts/index.md</code></li> </ul>"},{"location":"tutorials/production-like-run/","title":"Tutorial: production-like run (pipelines \u2192 object store \u2192 ship/rollback)","text":"<p>Goal: run <code>recsys-pipelines</code> to publish artifacts to local MinIO, configure <code>recsys-service</code> to read an artifact manifest, then practice ship + rollback by updating the manifest pointer.</p> <p>This tutorial uses the small built-in pipelines dataset and focuses on the deployment mechanics (not model quality).</p>"},{"location":"tutorials/production-like-run/#prereqs","title":"Prereqs","text":"<ul> <li>Docker + Docker Compose</li> <li>curl</li> <li>Go toolchain (to build <code>recsys-pipelines</code>)</li> <li><code>jq</code> (optional; only used to print item counts)</li> </ul>"},{"location":"tutorials/production-like-run/#expected-outcome","title":"Expected outcome","text":"<ul> <li><code>recsys-service</code> loads the manifest from object storage (log line: <code>artifact manifest loaded</code>)</li> <li><code>POST /v1/recommend</code> returns non-empty results after a \u201cgood\u201d ship</li> <li><code>POST /v1/recommend</code> returns an empty list after a \u201cbad\u201d ship</li> <li>rolling back the manifest restores non-empty results</li> </ul>"},{"location":"tutorials/production-like-run/#1-start-postgres-minio-and-recsys-service","title":"1) Start Postgres, MinIO, and recsys-service","text":"<p>From repo root:</p> <pre><code>make dev\n</code></pre> <p>Verify:</p> <pre><code>curl -fsS http://localhost:8000/healthz &gt;/dev/null\ncurl -fsS http://localhost:9000/minio/health/ready &gt;/dev/null\n</code></pre>"},{"location":"tutorials/production-like-run/#2-enable-artifactmanifest-mode-in-recsys-service","title":"2) Enable artifact/manifest mode in <code>recsys-service</code>","text":"<p>Edit <code>api/.env</code> (create it from <code>api/.env.example</code> if missing) and set:</p> <pre><code>RECSYS_ARTIFACT_MODE_ENABLED=true\nRECSYS_ARTIFACT_MANIFEST_TEMPLATE=s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json\n\n# Tutorial convenience: reload quickly when we swap the manifest\nRECSYS_ARTIFACT_MANIFEST_TTL=1s\nRECSYS_ARTIFACT_CACHE_TTL=1s\n\n# Deterministic behavior for the demo\nRECSYS_ALGO_MODE=popularity\n</code></pre> <p>Apply env changes (Compose loads <code>env_file</code> values at container creation time):</p> <pre><code>docker compose up -d --force-recreate api\n</code></pre>"},{"location":"tutorials/production-like-run/#3-run-pipelines-to-publish-a-good-artifact-set","title":"3) Run pipelines to publish a \u201cgood\u201d artifact set","text":"<p>Build the CLI:</p> <pre><code>(cd recsys-pipelines &amp;&amp; make build)\n</code></pre> <p>Run one day (this produces non-empty popularity/co-vis artifacts from the tiny dataset):</p> <pre><code>(cd recsys-pipelines &amp;&amp; ./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-01)\n</code></pre> <p>This writes a local manifest at:</p> <ul> <li><code>recsys-pipelines/.out/registry/current/demo/home/manifest.json</code></li> </ul> <p>And uploads referenced blobs to the <code>recsys-artifacts</code> bucket in MinIO.</p>"},{"location":"tutorials/production-like-run/#4-publish-the-manifest-pointer-to-minio-so-the-service-can-load-it","title":"4) Publish the manifest pointer to MinIO (so the service can load it)","text":"<p>Today, <code>recsys-pipelines</code> writes the manifest locally. In a production setup, you would publish the manifest pointer as part of your pipeline/CI run.</p> <p>For local dev, copy the manifest file into MinIO using the <code>minio-init</code> image (it includes <code>mc</code>):</p> <pre><code>docker compose run --rm --entrypoint sh \\\n  -v \"$PWD/recsys-pipelines/.out/registry/current/demo/home/manifest.json:/tmp/manifest.json:ro\" \\\n  minio-init -c \\\n  'mc alias set local http://minio:9000 minioadmin minioadmin &gt;/dev/null &amp;&amp; \\\n   mc cp /tmp/manifest.json local/recsys-artifacts/registry/current/demo/home/manifest.json'\n</code></pre>"},{"location":"tutorials/production-like-run/#5-call-v1recommend-and-verify-non-empty-output","title":"5) Call <code>/v1/recommend</code> and verify non-empty output","text":"<pre><code>curl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: prodlike-1' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"u_1\",\"session_id\":\"s_1\"}}'\n</code></pre> <p>Optional quick check:</p> <pre><code>curl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: prodlike-1b' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"u_1\",\"session_id\":\"s_1\"}}' | jq '.items | length'\n</code></pre> <p>You should see a non-empty <code>items</code> array with <code>item_id</code> values.</p>"},{"location":"tutorials/production-like-run/#6-ship-a-bad-manifest-empty-window-and-observe-the-impact","title":"6) Ship a \u201cbad\u201d manifest (empty window) and observe the impact","text":"<p>Back up the current (good) manifest locally:</p> <pre><code>cp recsys-pipelines/.out/registry/current/demo/home/manifest.json /tmp/manifest-good.json\n</code></pre> <p>Generate a manifest for a day with no events in the tiny dataset (this produces empty artifacts):</p> <pre><code>(cd recsys-pipelines &amp;&amp; ./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-02 \\\n  --end 2026-01-02)\n</code></pre> <p>Publish the new (bad) manifest:</p> <pre><code>docker compose run --rm --entrypoint sh \\\n  -v \"$PWD/recsys-pipelines/.out/registry/current/demo/home/manifest.json:/tmp/manifest.json:ro\" \\\n  minio-init -c \\\n  'mc alias set local http://minio:9000 minioadmin minioadmin &gt;/dev/null &amp;&amp; \\\n   mc cp /tmp/manifest.json local/recsys-artifacts/registry/current/demo/home/manifest.json'\n</code></pre> <p>Wait for the manifest TTL to expire (we set it to 1s):</p> <pre><code>sleep 2\n</code></pre> <p>Call recommend again; you should now get an empty list:</p> <pre><code>curl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: prodlike-2' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"u_1\",\"session_id\":\"s_1\"}}' | jq '.items | length'\n</code></pre>"},{"location":"tutorials/production-like-run/#7-roll-back-the-manifest-and-verify-recovery","title":"7) Roll back the manifest and verify recovery","text":"<p>Publish the backed-up manifest back to the \u201ccurrent\u201d pointer:</p> <pre><code>docker compose run --rm --entrypoint sh \\\n  -v \"/tmp/manifest-good.json:/tmp/manifest.json:ro\" \\\n  minio-init -c \\\n  'mc alias set local http://minio:9000 minioadmin minioadmin &gt;/dev/null &amp;&amp; \\\n   mc cp /tmp/manifest.json local/recsys-artifacts/registry/current/demo/home/manifest.json'\n</code></pre> <p>Wait for TTL and retry:</p> <pre><code>sleep 2\ncurl -fsS http://localhost:8000/v1/recommend \\\n  -H 'Content-Type: application/json' \\\n  -H 'X-Request-Id: prodlike-3' \\\n  -H 'X-Dev-User-Id: dev-user-1' \\\n  -H 'X-Dev-Org-Id: demo' \\\n  -H 'X-Org-Id: demo' \\\n  -d '{\"surface\":\"home\",\"k\":5,\"user\":{\"user_id\":\"u_1\",\"session_id\":\"s_1\"}}' | jq '.items | length'\n</code></pre> <p>You should be back to a non-zero item count.</p>"},{"location":"tutorials/production-like-run/#8-verify-the-service-is-actually-reading-manifests","title":"8) Verify the service is actually reading manifests","text":"<p>The service logs a line when it loads a manifest:</p> <pre><code>docker logs --tail 200 recsys-svc | grep -i \"artifact manifest loaded\"\n</code></pre> <p>If you do not see it, confirm the environment inside the container:</p> <pre><code>docker exec recsys-svc sh -c 'printenv | grep -E \"RECSYS_ARTIFACT_MODE_ENABLED|RECSYS_ARTIFACT_MANIFEST_TEMPLATE\"'\n</code></pre>"},{"location":"tutorials/production-like-run/#read-next","title":"Read next","text":"<ul> <li>Manifest lifecycle (why ship/rollback works): <code>explanation/artifacts-and-manifest-lifecycle.md</code></li> <li>Operate pipelines: <code>how-to/operate-pipelines.md</code></li> <li>Data modes background: <code>explanation/data-modes.md</code></li> <li>Pipelines rollback guide: <code>recsys-pipelines/docs/how-to/rollback-manifest.md</code></li> </ul>"},{"location":"tutorials/datasets/tiny/","title":"Tiny dataset","text":"<p>This dataset is intentionally small and human-readable. It is for documentation, smoke tests, and local demo runs.</p>"},{"location":"whats-new/","title":"What\u2019s new","text":""},{"location":"whats-new/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Customers upgrading the RecSys suite</li> <li>Evaluators who want a fast view of progress and breaking changes</li> </ul>"},{"location":"whats-new/#what-you-will-get","title":"What you will get","text":"<ul> <li>A curated list of changes that matter to production users</li> <li>Pointers to upgrade guidance and \u201cgotchas\u201d</li> </ul>"},{"location":"whats-new/#unreleased","title":"Unreleased","text":"<p>No release notes yet. When cutting a release, add a section here:</p> <ul> <li>Highlights (1\u20135 bullets)</li> <li>Breaking changes (if any)</li> <li>Upgrade notes (migrations, config changes, contract changes)</li> </ul>"},{"location":"whats-new/#read-next","title":"Read next","text":"<ul> <li>Docs versioning: <code>project/docs-versioning.md</code></li> <li>Start here: <code>start-here/index.md</code></li> </ul>"}]}