{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"RecSys suite documentation","text":"<p>Welcome. This documentation is intended to start running the suite, integrate it into an application, and operate it safely.</p>"},{"location":"#what-is-the-suite","title":"What is the suite?","text":"<p>The suite is four modules that form an end-to-end recommendation system loop:</p> <ul> <li>recsys-service: low-latency recommendation API (auth, tenancy, limits, caching, observability, exposure logging).</li> <li>recsys-algo: deterministic ranking logic (candidate merge, scoring, constraints, rules, diversity).</li> <li>recsys-pipelines: offline/stream processing that turns events into versioned artifacts the service consumes.</li> <li>recsys-eval: offline regression + online experiment analysis that decides what to ship.</li> </ul>"},{"location":"#where-to-start","title":"Where to start","text":"<ol> <li>Tutorial: <code>tutorials/local-end-to-end.md</code></li> <li>Integrate: <code>how-to/integrate-recsys-service.md</code></li> <li>Operate: <code>how-to/operate-pipelines.md</code></li> <li>Evaluate: <code>how-to/run-eval-and-ship.md</code></li> <li>Deploy: <code>how-to/deploy-helm.md</code></li> </ol>"},{"location":"#reference","title":"Reference","text":"<ul> <li>REST API: <code>reference/api/openapi.yaml</code></li> <li>Admin API: <code>reference/api/admin.md</code></li> <li>Contracts: <code>reference/data-contracts/</code></li> <li>Config: <code>reference/config/</code></li> <li>CLI: <code>reference/cli/</code></li> <li>Database: <code>reference/database/</code></li> </ul> <p>Note:</p> <ul> <li>Admin endpoints are documented in <code>reference/api/admin.md</code></li> </ul>"},{"location":"#concepts","title":"Concepts","text":"<ul> <li><code>explanation/suite-architecture.md</code></li> <li><code>explanation/candidate-vs-ranking.md</code></li> <li><code>explanation/exposure-logging-and-attribution.md</code></li> <li><code>explanation/surface-namespaces.md</code></li> <li><code>explanation/data-modes.md</code></li> </ul>"},{"location":"#development","title":"Development","text":"<ul> <li>Use the repo-level Go workspace: <code>go work sync</code> from <code>recsys/</code>.</li> <li>Each module is versioned/released independently; tags are module-prefixed</li> </ul> <p>(e.g., <code>recsys-eval/v0.2.0</code>). Run tests per module (e.g., <code>cd recsys-eval &amp;&amp; go test ./...</code>).</p>"},{"location":"#operations","title":"Operations","text":"<ul> <li><code>operations/runbooks/service-not-ready.md</code></li> <li><code>operations/runbooks/empty-recs.md</code></li> <li><code>operations/runbooks/rollback-config-rules.md</code></li> <li><code>operations/performance-and-capacity.md</code></li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ul> <li><code>project/docs-style.md</code></li> </ul>"},{"location":"explanation/candidate-vs-ranking/","title":"Candidate generation vs ranking","text":"<p>Candidates: high-recall sources (popularity, cooc, embeddings) Ranking: scoring + constraints + diversification to produce the final top-K</p> <p>Candidate overrides:</p> <ul> <li><code>candidates.include_ids</code> acts as an allow-list (only these items may appear).</li> <li><code>candidates.exclude_ids</code> always removes items from the final list.</li> </ul> <p>Rules:</p> <ul> <li>Pin rules can inject items even if they are not in the base candidate pool.</li> </ul>"},{"location":"explanation/data-modes/","title":"Data modes: DB-only vs object store","text":"<p>The service supports DB-only mode and artifact/manifest mode. DB-only is the default; artifact mode is opt-in via config.</p>"},{"location":"explanation/data-modes/#db-only-mode-current-recommended-for-mvp","title":"DB-only mode (current, recommended for MVP)","text":"<p>Signals are stored directly in Postgres tables and read by the service:</p> <ul> <li><code>item_tags</code></li> <li><code>item_popularity_daily</code></li> <li><code>item_covisit_daily</code> (if enabled)</li> </ul> <p>Popularity uses a decayed sum over <code>item_popularity_daily</code> with the configured half-life, so newer days dominate when you seed both recent and older rows.</p> <p>This is ideal for local development and popularity-only pilots.</p>"},{"location":"explanation/data-modes/#artifactmanifest-mode-pipelines-object-store","title":"Artifact/manifest mode (pipelines + object store)","text":"<p>Pipelines can publish artifacts (popularity, co-vis, embeddings) to object storage and update a manifest pointer. This enables atomic updates and easy rollback, but the service must be configured to read artifacts.</p> <p>Enable artifact mode:</p> <ul> <li><code>RECSYS_ARTIFACT_MODE_ENABLED=true</code></li> <li><code>RECSYS_ARTIFACT_MANIFEST_TEMPLATE</code> (e.g. <code>s3://recsys/registry/current/{tenant}/{surface}/manifest.json</code></li> </ul> <p>or <code>file:///data/registry/current/{tenant}/{surface}/manifest.json</code>)</p> <p>Notes:</p> <ul> <li><code>{tenant}</code> uses the incoming tenant id (header/JWT) when available.</li> <li><code>{surface}</code> maps to the request surface (namespace).</li> <li>Tags and constraints still read from Postgres (<code>item_tags</code>), even in artifact mode.</li> </ul>"},{"location":"explanation/data-modes/#recommendation","title":"Recommendation","text":"<ul> <li>Use DB-only for MVP and local testing (default today).</li> <li>Use object store + manifest for production-scale artifacts once the</li> </ul> <p>pipelines are producing artifacts and the service is configured to read them.</p>"},{"location":"explanation/data-modes/#which-mode-is-active","title":"Which mode is active?","text":"<p>The service runs in DB-only mode by default. When <code>RECSYS_ARTIFACT_MODE_ENABLED=true</code>, the service reads popularity/co-visitation from the artifact manifest and uses Postgres for tag metadata.</p>"},{"location":"explanation/exposure-logging-and-attribution/","title":"Exposure logging and attribution","text":"<p>Log what you showed (exposure) and what the user did (outcome). Join by request_id when possible.</p> <p>Service support:</p> <ul> <li>Enable JSONL logging with <code>EXPOSURE_LOG_ENABLED=true</code> and <code>EXPOSURE_LOG_PATH</code>.</li> <li>Set <code>EXPOSURE_LOG_FORMAT=eval_v1</code> to emit recsys-eval compatible exposure</li> </ul> <p>records (<code>exposure.v1</code> schema). Default is <code>service_v1</code>.</p> <ul> <li>Retention is controlled via <code>EXPOSURE_LOG_RETENTION_DAYS</code> (file-based logs).</li> </ul> <p>Attribution reminder:</p> <ul> <li>Outcomes must carry the same request_id returned by <code>/v1/recommend</code> to</li> </ul> <p>join in recsys-eval.</p>"},{"location":"explanation/suite-architecture/","title":"Suite architecture","text":"<p>Serving: client -&gt; recsys-service -&gt; recsys-algo -&gt; response + exposure log Pipelines: exposures/outcomes -&gt; artifacts + manifest Eval: exposures/outcomes + candidate versions -&gt; decision (ship/rollback)</p>"},{"location":"explanation/surface-namespaces/","title":"Surface namespaces","text":"<p>The service treats surface as a first-class scoping key. In practice this means the online API uses <code>surface</code> as the namespace when reading signals (e.g., popularity, tags, co-vis). This keeps signals isolated per surface by default and prevents \"home\" data from leaking into \"pdp\" results.</p>"},{"location":"explanation/surface-namespaces/#recommended-strategy","title":"Recommended strategy","text":"<ul> <li>Use a small, stable list of surface names (e.g., <code>home</code>, <code>pdp</code>, <code>cart</code>).</li> <li>In pipelines, emit artifacts/signals with <code>surface</code> matching the API surface.</li> <li>In DB-only mode, write signals under <code>namespace = &lt;surface&gt;</code>.</li> </ul>"},{"location":"explanation/surface-namespaces/#default-namespace-fallback","title":"Default namespace fallback","text":"<p>The service currently falls back to <code>default</code> for popularity/tags when a surface namespace is missing. This is helpful for local development but can be surprising in production.</p> <p>Best practice:</p> <ul> <li>Seed per-surface data for production.</li> <li>Use <code>default</code> only for shared or global signals.</li> </ul> <p>Note on similar-items:</p> <ul> <li><code>/v1/similar</code> reads co-visit signals scoped by surface/namespace.</li> <li>If you only seed <code>home</code>, requests for <code>surface=pdp</code> will return empty results.</li> </ul>"},{"location":"explanation/surface-namespaces/#example","title":"Example","text":"<ul> <li>API request: <code>surface=home</code></li> <li>Signals stored under: <code>namespace=home</code></li> <li>Optional fallback: <code>namespace=default</code> if <code>home</code> has no rows</li> </ul>"},{"location":"how-to/deploy-helm/","title":"Deploy with Helm (production-ish)","text":"<p>This chart installs the recsys-service and optionally a pipelines CronJob. Postgres and MinIO are disabled by default so you can bring your own.</p>"},{"location":"how-to/deploy-helm/#1-install-byo-postgres-s3","title":"1) Install (BYO Postgres + S3)","text":"<pre><code>RECSYS_ARTIFACT_MANIFEST_TEMPLATE='s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json'\n\nhelm install recsys ./charts/recsys \\\n  --set api.env.DATABASE_URL='postgres://user:pass@db:5432/recsys?sslmode=disable' \\\n  --set api.env.RECSYS_ARTIFACT_MANIFEST_TEMPLATE=\"${RECSYS_ARTIFACT_MANIFEST_TEMPLATE}\" \\\n  --set api.env.RECSYS_ARTIFACT_S3_ENDPOINT='s3.example.com' \\\n  --set api.env.RECSYS_ARTIFACT_S3_ACCESS_KEY='***' \\\n  --set api.env.RECSYS_ARTIFACT_S3_SECRET_KEY='***'\n</code></pre>"},{"location":"how-to/deploy-helm/#2-local-demo-enable-bundled-postgres-minio","title":"2) Local demo (enable bundled Postgres + MinIO)","text":"<pre><code># kind\n./scripts/helm_local.sh --kind\n\n# minikube\n./scripts/helm_local.sh --minikube\n</code></pre>"},{"location":"how-to/deploy-helm/#3-enable-pipelines-cronjob","title":"3) Enable pipelines CronJob","text":"<pre><code>helm upgrade --install recsys ./charts/recsys \\\n  --set pipelines.enabled=true \\\n  --set pipelines.schedule='0 2 * * *'\n</code></pre> <p>The CronJob reads <code>pipelines.configJson</code> from a ConfigMap. Override it in <code>values.yaml</code> for your tenant, surfaces, and storage endpoints.</p>"},{"location":"how-to/deploy-helm/#4-verify","title":"4) Verify","text":"<pre><code>kubectl get deploy,svc,cronjob\nkubectl logs deploy/recsys-api\n</code></pre>"},{"location":"how-to/deploy-helm/#notes","title":"Notes","text":"<ul> <li>The chart uses the <code>DATABASE_URL</code> env var as defined in <code>recsys/api/.env.example</code>.</li> <li>If you disable bundled Postgres/MinIO, you must provide external endpoints.</li> <li>The pipelines job requires object store + registry configured in its config.</li> </ul>"},{"location":"how-to/integrate-recsys-service/","title":"How-to: integrate recsys-service into an application","text":"<p>1) Define your surfaces (home, pdp, checkout) and keep names stable 2) Send stable pseudonymous user/session identifiers 3) Call POST /v1/recommend and render the list 4) Log outcomes (click/purchase) linked by request_id 5) Use /v1/recommend/validate during development 6) Handle failures: empty list fallback, respect 429 Retry-After</p> <p>Notes:</p> <ul> <li><code>surface</code> also acts as the namespace for signals and rules.</li> <li>For local MVPs, a <code>default</code> namespace fallback is available (see <code>explanation/surface-namespaces.md</code>).</li> <li>Admin bootstrap (tenant + config + rules) is required before first use:</li> </ul> <p>see <code>reference/api/admin.md</code>.</p> <p>Tenant headers (local dev):</p> <ul> <li>When <code>DEV_AUTH_ENABLED=true</code>, send both:</li> <li><code>X-Dev-Org-Id</code> (dev auth tenant context)</li> <li><code>X-Org-Id</code> (tenant scope enforced by middleware)</li> <li>In JWT mode, a bearer token with a tenant claim is sufficient (see <code>AUTH_TENANT_CLAIMS</code>).</li> <li>To use a single header locally, set <code>DEV_AUTH_TENANT_HEADER=X-Org-Id</code>.</li> </ul>"},{"location":"how-to/operate-pipelines/","title":"How-to: operate recsys-pipelines","text":"<p>Daily:</p> <ul> <li>ingest exposures + outcomes</li> <li>validate/canonicalize</li> <li>build artifacts (start with popularity)</li> <li>publish atomically (update manifest pointer)</li> <li>monitor freshness, volume anomalies, output sizes</li> </ul> <p>Backfills:</p> <ul> <li>compute for explicit time windows</li> <li>publish new manifest version</li> <li>keep prior manifest for rollback</li> </ul> <p>Rollback:</p> <ul> <li>pointer swap to last good manifest</li> <li>invalidate service caches</li> </ul> <p>Local MinIO example (docker-compose default):</p> <ul> <li>Bucket: <code>${MINIO_BUCKET:-recsys-artifacts}</code></li> <li>Manifest path convention: <code>registry/current/{tenant}/{surface}/manifest.json</code></li> <li>Example manifest URI:</li> </ul> <p><code>s3://recsys-artifacts/registry/current/demo/home/manifest.json</code></p> <p>Service env (artifact mode):</p> <pre><code>RECSYS_ARTIFACT_MODE_ENABLED=true\nRECSYS_ARTIFACT_MANIFEST_TEMPLATE=s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json\nRECSYS_ARTIFACT_S3_ENDPOINT=minio:9000\nRECSYS_ARTIFACT_S3_ACCESS_KEY=minioadmin\nRECSYS_ARTIFACT_S3_SECRET_KEY=minioadmin\nRECSYS_ARTIFACT_S3_REGION=us-east-1\nRECSYS_ARTIFACT_S3_USE_SSL=false\n</code></pre> <p>Tip:</p> <ul> <li>If <code>registry_dir</code> points to <code>s3://.../registry</code>, pipelines will write</li> </ul> <p>manifests directly to MinIO and you do not need a manual upload step.   A local path (e.g. <code>registry</code>) requires uploading the manifest yourself.</p> <p>DB-only mode:</p> <ul> <li>write signals into Postgres tables instead of publishing artifacts</li> <li>useful for local MVPs and popularity-only pilots</li> <li>seed examples: <code>reference/database/db-only-seeding.md</code></li> </ul>"},{"location":"how-to/run-eval-and-ship/","title":"How-to: run evaluation and make ship decisions","text":"<p>Always run an offline regression gate:</p> <ul> <li>compare baseline vs candidate versions</li> <li>fail if primary metric regresses beyond threshold</li> </ul> <p>Prefer online A/B tests:</p> <ul> <li>log exposures with experiment id/variant</li> <li>log outcomes tied to the same request_id</li> <li>check KPI + guardrails</li> </ul> <p>Ship if KPI improves and guardrails hold. Rollback by switching current pointers and invalidating caches.</p>"},{"location":"licensing/","title":"Licensing","text":"<p>This repository is a multi-license codebase. Different directories are licensed under different terms.</p>"},{"location":"licensing/#quick-map","title":"Quick map","text":"<p>Path/component: <code>recsys-eval/**</code> License: Apache License 2.0 Purpose: Offline evaluation &amp; reporting tooling.</p> <p>Path/component: <code>api/**</code>, <code>recsys-algo/**</code>, <code>recsys-pipelines/**</code>, and everything else unless stated otherwise License: GNU AGPL v3 Purpose: Serving API, algorithms, pipelines, ops templates</p> <p>The authoritative license texts are in:</p> <ul> <li><code>LICENSE</code> (AGPLv3)</li> <li><code>recsys-eval/LICENSE</code> (Apache-2.0)</li> </ul>"},{"location":"licensing/#how-to-determine-the-license-for-a-file","title":"How to determine the license for a file","text":"<p>We recommend (and are moving toward) using SPDX license identifiers in file headers and storing license texts in a <code>LICENSES/</code> directory (REUSE specification style).</p> <p>If there is ever a mismatch between this page and file headers, the per-file SPDX identifier (or the closest directory-level declaration) is the source of truth.</p>"},{"location":"licensing/#using-recsys-eval-apache-20","title":"Using <code>recsys-eval</code> (Apache-2.0)","text":"<p>You can use, modify, and redistribute <code>recsys-eval</code> under Apache-2.0 terms, including in proprietary systems, provided you comply with the Apache-2.0 conditions (e.g., preserving notices).</p>"},{"location":"licensing/#using-the-serving-stack-agplv3","title":"Using the serving stack (AGPLv3)","text":"<p>The serving stack is licensed under the GNU Affero General Public License v3 (AGPLv3).</p> <p>If your organization cannot or does not want to comply with AGPL obligations, you can obtain a commercial license (see <code>COMMERCIAL.md</code>).</p>"},{"location":"licensing/#commercial-licensing","title":"Commercial licensing","text":"<p>We offer a commercial license as an alternative set of terms for parts of this repository covered by AGPLv3.</p> <p>See:</p> <ul> <li><code>COMMERCIAL.md</code> (overview, what you get, and how to buy)</li> <li><code>pricing.md</code> (tiers)</li> </ul>"},{"location":"licensing/#third-party-dependencies","title":"Third-party dependencies","text":"<p>This project depends on third-party open source libraries with their own licenses. Compliance for those dependencies is separate from this project\u2019s license. If you publish releases, include SBOMs and/or dependency license reports as part of your compliance workflow.</p>"},{"location":"licensing/#questions","title":"Questions","text":"<p>If you have licensing questions, open an issue titled \"Licensing question\" (public) or contact us privately if your question contains confidential details.</p>"},{"location":"licensing/commercial/","title":"Commercial Use &amp; Licensing","text":"<p>This page explains how to purchase and use a commercial license for parts of this repository that are otherwise licensed under AGPLv3.</p> <p>This page is informational and describes our commercial offering at a high level.</p>"},{"location":"licensing/commercial/#why-a-commercial-license","title":"Why a commercial license?","text":"<p>The AGPLv3 is designed for software used over a network. If you modify AGPL-covered code and provide network access to users, AGPLv3 requires offering those users access to the Corresponding Source of your modified version (see Section 13).</p> <p>A commercial license allows you to use the covered components under alternative terms, typically enabling:</p> <ul> <li>Internal or external deployment without AGPL source-offer obligations (subject to the commercial agreement)</li> <li>Keeping modifications private</li> <li>Using the software in proprietary stacks</li> </ul>"},{"location":"licensing/commercial/#what-is-covered","title":"What is covered?","text":"<p>Commercial licensing applies to the components that are AGPLv3 in this repository, including typically:</p> <ul> <li><code>recsys-svc</code> (serving API)</li> <li><code>recsys-algo</code> (algorithms used by the service)</li> <li><code>recsys-pipelines</code> (batch pipelines and artifact generation)</li> </ul> <p><code>recsys-eval</code> remains Apache-2.0.</p>"},{"location":"licensing/commercial/#what-you-get-when-you-buy","title":"What you get when you buy","text":"<p>A typical commercial purchase includes:</p> <ul> <li>A signed commercial license grant (agreement + order form)</li> <li>A license token/file for bookkeeping (optional, not DRM)</li> <li>Access to commercial release artifacts (e.g., signed container images) if you offer those</li> <li>Security and patch releases according to the purchased tier</li> <li>Optional support terms (if purchased)</li> </ul> <p>See <code>pricing.md</code> for tier definitions.</p>"},{"location":"licensing/commercial/#how-to-buy","title":"How to buy","text":"<p>Recommended low-friction flow:</p> <ol> <li>Choose a tier in <code>pricing.md</code></li> <li>Purchase via a self-serve checkout (e.g., Stripe payment link) or request an invoice</li> <li>Receive:</li> <li>commercial license paperwork,</li> <li>delivery instructions for artifacts (if applicable),</li> <li>optional support contact</li> </ol> <p>Placeholder: Replace the following with your actual process:</p> <ul> <li>Sales contact: <code>sales@recsys.app</code></li> <li>Billing contact: <code>billing@recsys.app</code></li> </ul>"},{"location":"licensing/commercial/#evaluation-licenses-optional","title":"Evaluation licenses (optional)","text":"<p>If you offer evaluation terms, define them clearly:</p> <ul> <li>Duration (e.g., 30 days)</li> <li>Limits (e.g., 1 deployment, non-production)</li> <li>What\u2019s included (e.g., private artifact access)</li> </ul> <p>Document details in <code>docs/licensing/eval_license.md</code> if you provide this.</p>"},{"location":"licensing/commercial/#where-are-the-legal-terms","title":"Where are the legal terms?","text":"<p>Commercial terms live in:</p> <ul> <li><code>docs/licensing/commercial_license.md</code></li> <li><code>docs/licensing/order_form.md</code></li> </ul>"},{"location":"licensing/commercial_license/","title":"RecSys Commercial License Agreement","text":"<p>Version: <code>1.0</code> Last updated: <code>2026-02-01</code></p> <p>This Commercial License Agreement (\"Agreement\") is between:</p> <ul> <li>Vendor: <code>VENDOR_LEGAL_NAME</code>, <code>ADDRESS</code> (\"Vendor\"), and  </li> <li>Customer: <code>CUSTOMER_LEGAL_NAME</code>, <code>ADDRESS</code> (\"Customer\")</li> </ul> <p>This Agreement provides the general terms for Customer\u2019s commercial use of the Software. Specific scope, fees, and entitlements are set out in one or more Order Forms that reference this Agreement.</p> <p>TEMPLATE NOTICE: This is a starting template for commercial contracting. It should be reviewed for your jurisdiction and business needs.</p>"},{"location":"licensing/commercial_license/#1-definitions","title":"1. Definitions","text":"<ul> <li>\"Software\": The RecSys software identified in an Order Form, including related documentation, and any updates provided by Vendor under this Agreement.</li> <li>\"Commercial Artifacts\": Vendor-provided binaries, container images, license files/keys, and related deliverables made available under commercial terms.</li> <li>\"Open Source Components\": Components distributed under open-source licenses (e.g., Apache-2.0, AGPLv3) as identified in <code>licensing/index.md</code> or applicable notices.</li> <li>\"Production Deployment\": A production environment serving real end-user traffic.</li> <li>\"Tenant\": A logically separate recommendation domain (catalog + signals partition) as described in <code>pricing.md</code> or the Order Form.</li> <li>\"Authorized Scope\": The entitlements purchased by Customer and specified in the Order Form (e.g.,   number of tenants, number of production deployments).</li> <li>\"Order Form\": A document signed or accepted by Customer and Vendor that references this Agreement and specifies products, scope, term, and fees.</li> </ul>"},{"location":"licensing/commercial_license/#2-agreement-structure-and-order-of-precedence","title":"2. Agreement Structure and Order of Precedence","text":"<p>2.1. Order Forms are incorporated into and governed by this Agreement. 2.2. In case of conflict, the following order controls: Order Form \u2192 this Agreement \u2192 referenced policies/attachments.</p>"},{"location":"licensing/commercial_license/#3-commercial-license-grant","title":"3. Commercial License Grant","text":"<p>3.1. Subject to payment of fees and compliance with this Agreement, Vendor grants Customer a non-exclusive, worldwide, non-transferable license to:</p> <ul> <li>install, run, and use the Commercial Artifacts within the Authorized Scope for Customer\u2019s internal business operations;</li> <li>run the Software as a network service (including internal SaaS) within the Authorized Scope;</li> <li>make a reasonable number of copies for backup and internal administrative purposes.</li> </ul> <p>3.2. Modification Rights. Customer may modify the Software for internal use within the Authorized Scope. Customer is not required to disclose modifications under this commercial license.</p> <p>3.3. Affiliates and Contractors. Customer may permit affiliates and contractors to use the Software solely on Customer\u2019s behalf within the Authorized Scope, provided they are bound by obligations consistent with this Agreement. Customer remains responsible for their compliance.</p> <p>3.4. No implied rights. All rights not expressly granted are reserved by Vendor.</p>"},{"location":"licensing/commercial_license/#4-restrictions","title":"4. Restrictions","text":"<p>Customer must not:</p> <ul> <li>exceed the Authorized Scope (e.g., number of Production Deployments or Tenants) without purchasing an upgrade;</li> <li>sublicense, resell, rent, lease, or commercially distribute the Software or Commercial Artifacts, except as expressly allowed in an Order Form;</li> <li>use the Software for OEM/resale or third-party hosting unless explicitly purchased (Enterprise terms).</li> </ul>"},{"location":"licensing/commercial_license/#5-open-source-components","title":"5. Open Source Components","text":"<p>5.1. Open Source Components are governed by their respective open-source licenses. 5.2. This Agreement grants additional permissions for commercial use of the covered components as specified in Order Forms and/or <code>licensing/index.md</code>. 5.3. Nothing in this Agreement limits Customer\u2019s rights under applicable open-source licenses for Open Source Components.</p>"},{"location":"licensing/commercial_license/#6-delivery-updates","title":"6. Delivery; Updates","text":"<p>6.1. Vendor will provide Commercial Artifacts via <code>DELIVERY_METHOD</code> (e.g., private container registry). 6.2. Updates, if included, are provided during the Term as specified in the Order Form.</p>"},{"location":"licensing/commercial_license/#7-fees-and-payment","title":"7. Fees and Payment","text":"<p>7.1. Fees, invoicing, and payment terms are specified in the Order Form. 7.2. Taxes: Customer is responsible for applicable taxes/VAT, excluding Vendor\u2019s income taxes.</p>"},{"location":"licensing/commercial_license/#8-support-if-purchased","title":"8. Support (If Purchased)","text":"<p>8.1. Support is provided only if included in an Order Form. 8.2. Support scope, channels, and response targets are specified in the Order Form or an attached Support Policy.</p>"},{"location":"licensing/commercial_license/#9-confidentiality","title":"9. Confidentiality","text":"<p>Each party may receive the other\u2019s Confidential Information. The receiving party will protect it using reasonable care and use it only to perform under this Agreement.</p> <p>Confidentiality does not apply to information that is public, independently developed, or rightfully received from a third party.</p>"},{"location":"licensing/commercial_license/#10-intellectual-property-feedback","title":"10. Intellectual Property; Feedback","text":"<p>10.1. Vendor retains all IP rights in the Software and Commercial Artifacts, except the rights expressly granted to Customer. 10.2. Customer may provide feedback; Vendor may use feedback without obligation, provided it does not disclose Customer Confidential Information.</p>"},{"location":"licensing/commercial_license/#11-warranty-disclaimer","title":"11. Warranty Disclaimer","text":"<p>EXCEPT AS EXPRESSLY STATED IN AN ORDER FORM, THE SOFTWARE AND COMMERCIAL ARTIFACTS ARE PROVIDED \"AS IS\". VENDOR DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT, TO THE MAXIMUM EXTENT PERMITTED BY LAW.</p>"},{"location":"licensing/commercial_license/#12-limitation-of-liability","title":"12. Limitation of Liability","text":"<p>TO THE MAXIMUM EXTENT PERMITTED BY LAW:</p> <ul> <li>NEITHER PARTY IS LIABLE FOR INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL, OR PUNITIVE DAMAGES, OR LOSS OF PROFITS, REVENUE, DATA, OR BUSINESS INTERRUPTION.</li> <li>VENDOR\u2019S TOTAL LIABILITY UNDER THIS AGREEMENT WILL NOT EXCEED THE FEES PAID OR PAYABLE BY CUSTOMER UNDER THE APPLICABLE ORDER FORM IN THE 12 MONTHS PRECEDING THE EVENT GIVING RISE TO LIABILITY.</li> </ul>"},{"location":"licensing/commercial_license/#13-term-and-termination","title":"13. Term and Termination","text":"<p>13.1. This Agreement begins on the Effective Date and remains in effect until terminated. 13.2. Each Order Form has its own term. 13.3. Either party may terminate for material breach if not cured within 30 days of written notice. 13.4. Upon termination/expiration of an Order Form, Customer must stop using the Software beyond the scope of remaining active Order Forms.</p>"},{"location":"licensing/commercial_license/#14-compliance","title":"14. Compliance","text":"<p>Customer will comply with applicable laws, including export/sanctions laws, where applicable.</p>"},{"location":"licensing/commercial_license/#15-governing-law-venue","title":"15. Governing Law; Venue","text":"<p>This Agreement is governed by the laws of <code>GOVERNING_LAW_JURISDICTION</code>, excluding conflict-of-law rules. Exclusive venue: <code>VENUE</code>.</p>"},{"location":"licensing/commercial_license/#16-miscellaneous","title":"16. Miscellaneous","text":"<p>Assignment, force majeure, notices, severability, waiver, entire agreement.</p>"},{"location":"licensing/commercial_license/#signatures","title":"Signatures","text":"<p>Vendor: ___  Date: _ Name/Title: ______</p> <p>Customer: ____  Date: _ Name/Title: ___</p>"},{"location":"licensing/eval_license/","title":"RecSys Evaluation License Terms","text":"<p>Last updated: 2026-02-01 Vendor: RecSys (\"Vendor\") Licensee: The individual or entity downloading, installing, accessing, or using the Evaluation Materials (\"Licensee\")</p> <p>NOTE: This document is a lightweight evaluation agreement intended to enable internal evaluation. For production use under commercial terms, see <code>COMMERCIAL.md</code> and the Commercial License Agreement/Order Form templates under <code>commercial/</code>.</p>"},{"location":"licensing/eval_license/#1-acceptance","title":"1. Acceptance","text":"<p>By downloading, installing, accessing, pulling, or using any Evaluation Materials (defined below), Licensee agrees to these Evaluation License Terms.</p>"},{"location":"licensing/eval_license/#2-definitions","title":"2. Definitions","text":"<ul> <li>\"Software\": The RecSys software components and documentation.</li> <li>\"Evaluation Materials\": Any of the following, provided by Vendor for evaluation: (a) commercial builds (e.g.,   container images, binaries), (b) license files/keys, (c) documentation or evaluation pack, (d) updates to any of the   foregoing.</li> <li>\"Evaluation Term\": The time-limited period stated in Section 5.</li> <li>\"Production\": Use serving real end-user traffic in a live environment where recommendations materially affect   business operations, customers, or revenue (as determined reasonably by Vendor).</li> <li>\"Non-Production\": Dev/test/staging/sandbox evaluation environments.</li> </ul>"},{"location":"licensing/eval_license/#3-evaluation-license-grant","title":"3. Evaluation License Grant","text":"<p>Subject to these terms, Vendor grants Licensee a non-exclusive, non-transferable, non-sublicensable (except to permitted contractors under Section 4.4), revocable, limited license to install and operate the Evaluation Materials solely in Non-Production for Licensee\u2019s internal evaluation of suitability for Licensee\u2019s business needs during the Evaluation Term.</p> <p>No rights are granted beyond those expressly stated.</p>"},{"location":"licensing/eval_license/#4-restrictions","title":"4. Restrictions","text":""},{"location":"licensing/eval_license/#41-non-production-only","title":"4.1 Non-Production only","text":"<p>Licensee must not use the Evaluation Materials in Production.</p>"},{"location":"licensing/eval_license/#42-no-resale-oem-third-party-hosting","title":"4.2 No resale / OEM / third-party hosting","text":"<p>Licensee must not (a) resell, rent, lease, or otherwise commercialize the Evaluation Materials, (b) offer the Evaluation Materials as a service to third parties, or (c) embed the Evaluation Materials in a product or service offered to third parties.</p>"},{"location":"licensing/eval_license/#43-no-public-distribution","title":"4.3 No public distribution","text":"<p>Licensee must not distribute Evaluation Materials outside Licensee\u2019s organization.</p>"},{"location":"licensing/eval_license/#44-contractors","title":"4.4 Contractors","text":"<p>Licensee may allow its contractors to access Evaluation Materials only if:</p> <ul> <li>they are under confidentiality obligations at least as protective as Licensee\u2019s, and</li> <li>access is limited to the internal evaluation purpose.</li> </ul> <p>Licensee remains responsible for contractor compliance.</p>"},{"location":"licensing/eval_license/#45-benchmark-publication-optional","title":"4.5 Benchmark publication (optional)","text":"<p>Unless Vendor gives written permission, Licensee must not publish benchmark results of the Evaluation Materials. (If you want \"maximum openness\", delete this section.)</p>"},{"location":"licensing/eval_license/#5-term-and-expiration","title":"5. Term and Expiration","text":"<p>The Evaluation Term begins on the date Licensee first accesses the Evaluation Materials and lasts 30 days, unless extended in writing by Vendor.</p> <p>Upon expiration or termination, Licensee must stop use and destroy all Evaluation Materials in its possession, including license files/keys and any copied commercial artifacts, except that Licensee may retain evaluation results and notes that do not contain Vendor Confidential Information.</p>"},{"location":"licensing/eval_license/#6-confidentiality","title":"6. Confidentiality","text":"<p>Evaluation Materials, license files/keys, and any non-public documentation are Vendor\u2019s confidential information (\"Confidential Information\").</p> <p>Licensee agrees to protect Confidential Information using reasonable measures and not disclose it except as allowed under this agreement. This obligation survives for 3 years after expiration/termination.</p>"},{"location":"licensing/eval_license/#7-feedback","title":"7. Feedback","text":"<p>If Licensee provides feedback, suggestions, or evaluation results, Vendor may use them to improve the Software without obligation to Licensee. Feedback does not include Licensee\u2019s Confidential Information.</p>"},{"location":"licensing/eval_license/#8-support","title":"8. Support","text":"<p>Evaluation support, if any, is provided on a best-effort basis and may be limited. Vendor may choose not to provide support during evaluation.</p>"},{"location":"licensing/eval_license/#9-open-source-components","title":"9. Open Source Components","text":"<p>If Licensee uses any open-source components of RecSys separately, such components are governed by their respective open-source licenses. These Evaluation Terms govern only Evaluation Materials provided under this document.</p>"},{"location":"licensing/eval_license/#10-warranty-disclaimer","title":"10. Warranty Disclaimer","text":"<p>THE EVALUATION MATERIALS ARE PROVIDED \"AS IS\" AND \"AS AVAILABLE\". VENDOR DISCLAIMS ALL WARRANTIES, EXPRESS OR IMPLIED, INCLUDING MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT, TO THE MAXIMUM EXTENT PERMITTED BY LAW.</p>"},{"location":"licensing/eval_license/#11-limitation-of-liability","title":"11. Limitation of Liability","text":"<p>TO THE MAXIMUM EXTENT PERMITTED BY LAW:</p> <ul> <li>VENDOR WILL NOT BE LIABLE FOR ANY INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL, OR PUNITIVE DAMAGES, OR LOSS OF   PROFITS, REVENUE, DATA, OR BUSINESS INTERRUPTION.</li> <li>VENDOR\u2019S TOTAL LIABILITY UNDER THESE TERMS WILL NOT EXCEED EUR 500 (OR THE AMOUNT PAID FOR THE EVALUATION, IF   ANY), WHICHEVER IS GREATER.</li> </ul>"},{"location":"licensing/eval_license/#12-termination","title":"12. Termination","text":"<p>Vendor may terminate this Evaluation License immediately if Licensee breaches these terms. Upon termination, Licensee must comply with Section 5 (stop use and destroy Evaluation Materials).</p>"},{"location":"licensing/eval_license/#13-governing-law","title":"13. Governing Law","text":"<p>These terms are governed by the laws of <code>GOVERNING_LAW_JURISDICTION</code>, excluding conflict-of-law rules. The parties agree to the exclusive venue of <code>VENUE</code>.</p>"},{"location":"licensing/eval_license/#14-contact","title":"14. Contact","text":"<p>Vendor contact for evaluation questions: <code>CONTACT_EMAIL</code></p>"},{"location":"licensing/order_form/","title":"Order Form (Template) \u2014 Recsys Commercial License","text":"<p>Order Form ID: <code>OF-YYYY-NNN</code> Effective Date: <code>YYYY-MM-DD</code> Vendor: <code>VENDOR_LEGAL_NAME</code> (\"Vendor\") Customer: <code>CUSTOMER_LEGAL_NAME</code> (\"Customer\")</p> <p>This Order Form is governed by and incorporates the Commercial License Agreement (Recsys) v<code>version</code> (\"Agreement\"). Capitalized terms not defined here have the meaning given in the Agreement.</p>"},{"location":"licensing/order_form/#1-products-and-fees","title":"1. Products and Fees","text":""},{"location":"licensing/order_form/#11-product","title":"1.1 Product","text":"<ul> <li>Product: Recsys Commercial License</li> <li>Plan: \u2610 Starter \u2610 Growth \u2610 Enterprise (custom)</li> </ul>"},{"location":"licensing/order_form/#12-term","title":"1.2 Term","text":"<ul> <li>Start date: <code>YYYY-MM-DD</code></li> <li>End date: <code>YYYY-MM-DD</code></li> <li>Renewal: \u2610 Annual renewal \u2610 Non-renewing (evaluation/custom)</li> </ul>"},{"location":"licensing/order_form/#13-fees-excl-vat","title":"1.3 Fees (excl. VAT)","text":"<ul> <li>License fee: \u20ac <code>AMOUNT</code></li> <li>Support fee (if any): \u20ac <code>AMOUNT</code></li> <li>Total: \u20ac <code>AMOUNT</code></li> <li>Payment terms: <code>e.g., Net 14 / Net 30</code></li> <li>Billing method: \u2610 Invoice \u2610 Payment link/credit card \u2610 Other: <code>...</code></li> </ul>"},{"location":"licensing/order_form/#14-taxes","title":"1.4 Taxes","text":"<p>Customer is responsible for applicable VAT/sales taxes unless a valid exemption applies. Customer VAT ID: <code>VAT_ID</code></p>"},{"location":"licensing/order_form/#2-authorized-scope-entitlements","title":"2. Authorized Scope (Entitlements)","text":""},{"location":"licensing/order_form/#21-tenants","title":"2.1 Tenants","text":"<ul> <li>Authorized Tenants: <code>N</code></li> </ul>"},{"location":"licensing/order_form/#22-production-deployments","title":"2.2 Production Deployments","text":"<ul> <li>Authorized Production Deployments: <code>N</code></li> </ul>"},{"location":"licensing/order_form/#23-non-production-environments","title":"2.3 Non-Production Environments","text":"<p>Included at no extra charge:</p> <ul> <li>Up to 2 non-prod environments per Production Deployment (dev/staging/sandbox)</li> </ul>"},{"location":"licensing/order_form/#24-regions-affiliates-if-applicable","title":"2.4 Regions / Affiliates (if applicable)","text":"<ul> <li>Regions allowed: <code>e.g., EU / global</code></li> <li>Affiliates allowed: \u2610 Yes \u2610 No (details if yes): <code>...</code></li> </ul>"},{"location":"licensing/order_form/#25-oem-resale-third-party-hosting","title":"2.5 OEM / Resale / Third-Party Hosting","text":"<ul> <li>OEM/resale: \u2610 Not allowed \u2610 Allowed (details): <code>...</code></li> <li>Third-party hosting: \u2610 Not allowed \u2610 Allowed (details): <code>...</code></li> </ul>"},{"location":"licensing/order_form/#3-support-if-purchased","title":"3. Support (If Purchased)","text":"<p>Support tier: \u2610 None \u2610 Best effort async \u2610 8x5 SLA \u2610 24x7 SLA Support channel(s): <code>email/ticket portal</code> Response targets (if applicable): <code>e.g., P1 4h, P2 1bd, ...</code> Exclusions/limits: <code>optional</code></p>"},{"location":"licensing/order_form/#4-delivery-and-access","title":"4. Delivery and Access","text":"<ul> <li>Delivery method: \u2610 Private container registry \u2610 Download link \u2610 Other</li> <li>Registry/URL: <code>REGISTRY_URL or DOWNLOAD_URL</code></li> <li>Credential delivery: <code>how credentials are provided</code></li> <li>License file delivery: <code>signed license.json/JWT, delivered via email/portal</code></li> </ul>"},{"location":"licensing/order_form/#5-special-terms-optional","title":"5. Special Terms (Optional)","text":"<p><code>Any negotiated terms, e.g., security addendum, DPA reference, custom liability cap, etc.</code></p>"},{"location":"licensing/order_form/#6-signatures","title":"6. Signatures","text":"<p>Vendor: ___  Date: _ Name/Title: ______</p> <p>Customer: ____  Date: _ Name/Title: ___</p>"},{"location":"licensing/pricing/","title":"Pricing (Commercial License)","text":"<p>This repository includes open-source components (e.g., Apache-2.0 and AGPLv3). A commercial license is available for organizations that want commercial terms and/or prefer not to adopt AGPL obligations for production use.</p> <p>All prices below are EUR, excl. VAT.</p>"},{"location":"licensing/pricing/#quick-definitions","title":"Quick definitions","text":"<ul> <li>Tenant: A logically separate recommendation domain with its own catalog and behavior signals (e.g., brand, product   line, customer partition).</li> <li>Production deployment: One production environment serving real end-user traffic (e.g., a Kubernetes cluster/namespace   or a distinct production installation).</li> <li>Non-production environments: Up to 2 non-prod environments (dev/staging) per production deployment are included   at no extra charge.</li> </ul> <p>If your use case involves OEM/resale, multi-region HA across many clusters, or unusually large scale, use Enterprise.</p>"},{"location":"licensing/pricing/#plans","title":"Plans","text":""},{"location":"licensing/pricing/#commercial-evaluation","title":"Commercial Evaluation","text":"<p>Price: \u20ac490 (one-time, 30 days)</p> <p>For teams who want to evaluate under commercial terms and/or use signed commercial artifacts.</p> <p>Includes:</p> <ul> <li>Commercial evaluation license grant (time-boxed)</li> <li>Access to signed commercial artifacts (private registry)</li> <li>Scope: 1 tenant, 1 deployment (non-prod allowed)</li> </ul> <p>Notes:</p> <ul> <li>Evaluation is for internal testing only (no resale/OEM).</li> <li>See <code>docs/licensing/eval_license.md</code> for the exact evaluation terms.</li> </ul>"},{"location":"licensing/pricing/#starter","title":"Starter","text":"<p>Price: \u20ac9,900 / year</p> <p>Scope:</p> <ul> <li>1 tenant</li> <li>1 production deployment</li> <li>Includes up to 2 non-prod environments</li> </ul> <p>Includes:</p> <ul> <li>Commercial license grant for the commercial-licensed components (as described in <code>COMMERCIAL.md</code>)</li> <li>Access to signed commercial artifacts (private registry)</li> <li>Updates during the license term</li> <li>Async support channel (best effort)</li> </ul>"},{"location":"licensing/pricing/#growth","title":"Growth","text":"<p>Price: \u20ac24,900 / year</p> <p>Scope:</p> <ul> <li>Up to 3 tenants and/or up to 3 production deployments</li> <li>Includes up to 2 non-prod environments per production deployment</li> </ul> <p>Includes:</p> <ul> <li>Everything in Starter</li> <li>Faster async response target (typically within 2 business days)</li> </ul>"},{"location":"licensing/pricing/#enterprise","title":"Enterprise","text":"<p>Price: From \u20ac60,000 / year</p> <p>For:</p> <ul> <li>Many tenants/deployments, multi-region HA, OEM/resale, custom legal/security requirements, or regulated environments.</li> </ul> <p>Includes:</p> <ul> <li>Custom scope and terms</li> <li>Optional premium support / security commitments</li> <li>Optional fixed-scope professional services (explicitly scoped)</li> </ul>"},{"location":"licensing/pricing/#optional-add-ons-available-for-growthenterprise","title":"Optional add-ons (available for Growth/Enterprise)","text":"<ul> <li>Premium support / SLA (8\u00d75 or 24\u00d77)</li> <li>Security review package (SBOM/provenance guidance, hardening checklist)</li> <li>Fixed-scope onboarding (time-boxed)</li> </ul>"},{"location":"licensing/pricing/#what-you-get-when-you-buy","title":"What you get when you buy","text":"<ul> <li>A signed license file (offline verifiable), or equivalent commercial entitlement artifact</li> <li>Credentials to pull signed commercial images from the private registry</li> <li>Instructions to run the \"Commercial lane\" of the evaluation pack (if applicable)</li> </ul>"},{"location":"licensing/pricing/#payment-renewal","title":"Payment &amp; renewal","text":"<ul> <li>Annual plans are billed annually in advance unless otherwise agreed.</li> <li>Renewals are annual. Upgrades are typically prorated.</li> <li>Taxes: VAT may apply depending on your location and VAT ID status.</li> </ul>"},{"location":"licensing/pricing/#how-to-buy","title":"How to buy","text":"<p>Use the payment links (recommended for fastest fulfillment) or contact us for Enterprise terms.</p> <ul> <li>Commercial Evaluation (30 days)</li> <li>Starter (annual)</li> <li>Growth (annual)</li> <li>Enterprise (contact)</li> </ul> <p>Contact: <code>contact@recsys.app</code></p>"},{"location":"licensing/pricing/#contact","title":"Contact","text":"<p>If you need Enterprise terms, OEM/resale rights, or help selecting the right plan, contact: <code>contact@recsys.app</code></p>"},{"location":"operations/performance-and-capacity/","title":"Performance and capacity guide","text":"<p>This guide describes how to run reproducible load tests against recsys-service and capture sizing data for production planning.</p>"},{"location":"operations/performance-and-capacity/#1-preflight-checklist","title":"1) Preflight checklist","text":"<ul> <li>Postgres is seeded with a tenant, config, and signal data.</li> <li>recsys-service is healthy (<code>/healthz</code> returns 200).</li> <li>Auth headers are configured (dev headers or a bearer token).</li> </ul>"},{"location":"operations/performance-and-capacity/#2-run-the-load-test","title":"2) Run the load test","text":"<p>Use the built-in harness:</p> <pre><code>./scripts/loadtest.sh\n</code></pre> <p>Key parameters (env vars):</p> <ul> <li><code>BASE_URL</code> (default: http://localhost:8000)</li> <li><code>ENDPOINT</code> (default: /v1/recommend; set /v1/similar for similar-items)</li> <li><code>TENANT_ID</code>, <code>SURFACE</code>, <code>K</code></li> <li><code>REQUESTS</code>, <code>CONCURRENCY</code></li> <li><code>DEV_HEADERS=true</code> (local) or set <code>BEARER_TOKEN</code> / <code>API_KEY</code></li> </ul> <p>Example:</p> <pre><code>BASE_URL=http://localhost:8000 \\\nENDPOINT=/v1/recommend \\\nTENANT_ID=demo \\\nSURFACE=home \\\nREQUESTS=1000 \\\nCONCURRENCY=25 \\\n./scripts/loadtest.sh\n</code></pre> <p>Capture:</p> <ul> <li><code>rps</code> (requests/sec)</li> <li>p50/p95/p99 latency</li> <li>error rate (non-2xx + timeouts)</li> </ul>"},{"location":"operations/performance-and-capacity/#3-record-sizing-data","title":"3) Record sizing data","text":"<p>Use this table as a living record. Fill with measured results from your environment (hardware, cache settings, dataset size).</p> Tier Target QPS p95 Latency CPU Memory Notes dev local, seeded data small single tenant med multi-tenant large dedicated cache"},{"location":"operations/performance-and-capacity/#4-tuning-levers","title":"4) Tuning levers","text":"<ul> <li>Cache TTLs: <code>RECSYS_CONFIG_CACHE_TTL</code>, <code>RECSYS_RULES_CACHE_TTL</code></li> <li>Backpressure: <code>RECSYS_BACKPRESSURE_MAX_INFLIGHT</code>, <code>RECSYS_BACKPRESSURE_MAX_QUEUE</code></li> <li>Algorithm mode: <code>RECSYS_ALGO_MODE</code> (<code>blend</code>, <code>popularity</code>, <code>cooc</code>, etc.)</li> <li>Artifact mode: <code>RECSYS_ARTIFACT_MODE_ENABLED</code> (affects S3/manifest latency)</li> </ul>"},{"location":"operations/performance-and-capacity/#5-repeat-after-changes","title":"5) Repeat after changes","text":"<p>Re-run the load test after:</p> <ul> <li>schema changes (new signals)</li> <li>algorithm changes</li> <li>cache or artifact mode changes</li> <li>infrastructure changes</li> </ul>"},{"location":"operations/runbooks/empty-recs/","title":"Runbook: empty recs","text":"<p>Checklist:</p> <ul> <li>validate request with /v1/recommend/validate</li> <li>confirm current config/rules versions</li> <li>confirm artifacts exist and manifest points to them</li> <li>ensure constraints are not filtering everything</li> <li>rollback pointers and invalidate caches if needed</li> </ul>"},{"location":"operations/runbooks/rollback-config-rules/","title":"Runbook: rollback","text":"<ul> <li>identify last known good versions (config/rules/manifest)</li> <li>swap current pointers back</li> <li>invalidate caches</li> <li>verify response versions and metrics</li> </ul>"},{"location":"operations/runbooks/service-not-ready/","title":"Runbook: service not ready","text":"<p>Checklist:</p> <ul> <li>DB connectivity and migrations</li> <li>required tenant config/rules/manifest exist</li> <li>object store/registry connectivity</li> <li>caches not stuck warming</li> </ul>"},{"location":"project/","title":"Project","text":"<ul> <li><code>Code of Conduct</code></li> <li><code>Contributing</code></li> <li><code>Governance</code></li> <li><code>License Directory Notes</code></li> <li><code>Security Policy</code></li> <li><code>Support</code></li> </ul>"},{"location":"project/code_of_conduct/","title":"Code of Conduct","text":"<p>This project adopts the Contributor Covenant Code of Conduct.</p>"},{"location":"project/code_of_conduct/#our-pledge","title":"Our pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone.</p>"},{"location":"project/code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces and also applies when an individual is officially representing the community in public spaces.</p>"},{"location":"project/code_of_conduct/#enforcement","title":"Enforcement","text":"<p>To report incidents, contact: <code>conduct@recsys.app</code>.</p>"},{"location":"project/code_of_conduct/#full-text","title":"Full text","text":"<p>The full text of Contributor Covenant v2.1 is available at: Contributor Covenant v2.1.</p> <p>Attribution: Contributor Covenant v2.1.</p>"},{"location":"project/contributing/","title":"Contributing","text":"<p>Thanks for your interest in contributing!</p>"},{"location":"project/contributing/#contribution-scope","title":"Contribution scope","text":"<p>We welcome:</p> <ul> <li>Bug reports and reproducible issue reports</li> <li>Documentation improvements</li> <li>Tests and CI improvements</li> <li>Code contributions (see licensing note below)</li> </ul>"},{"location":"project/contributing/#licensing-of-contributions","title":"Licensing of contributions","text":"<p>By submitting a contribution, you agree that your contribution is licensed under the same license as the component you are contributing to (Apache-2.0 for <code>recsys-eval</code>, AGPLv3 for the serving stack), unless otherwise agreed in writing.</p>"},{"location":"project/contributing/#commercial-dual-licensing-note-important","title":"Commercial dual-licensing note (important)","text":"<p>If we accept code contributions into the AGPL-covered components and later want to include them in commercial distributions, we may require an additional contributor agreement for those specific contributions.</p> <p>To keep things simple, we may ask contributors to:</p> <ul> <li>contribute substantial feature code to <code>recsys-eval</code> (Apache-2.0), or</li> <li>contribute via issues/design proposals for AGPL components, or</li> <li>sign an additional agreement when necessary.</li> </ul>"},{"location":"project/contributing/#development-workflow","title":"Development workflow","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Run tests and linters</li> <li>Open a pull request</li> </ol>"},{"location":"project/contributing/#commit-sign-off-dco","title":"Commit sign-off (DCO)","text":"<p>We use the Developer Certificate of Origin (DCO) sign-off on commits.</p> <p>Use: <code>git commit -s -m \"...\"</code></p> <p>Your commits should include a <code>Signed-off-by:</code> line.</p>"},{"location":"project/contributing/#style","title":"Style","text":"<ul> <li>Prefer small, focused PRs</li> <li>Add tests for bug fixes and new behavior</li> <li>Update docs when behavior changes</li> </ul>"},{"location":"project/docs-style/","title":"Documentation style guide","text":"<p>This repository follows the Diataxis structure:</p> <ul> <li>Tutorials: learning by doing</li> <li>How-to: goal-oriented steps</li> <li>Explanation: understanding and design rationale</li> <li>Reference: precise specification (APIs, schemas, config)</li> </ul>"},{"location":"project/docs-style/#writing-rules","title":"Writing rules","text":"<ul> <li>Prefer short sections and explicit headings.</li> <li>Use consistent terminology (see <code>glossary.md</code>).</li> <li>Always include:</li> <li>prerequisites</li> <li>expected outcomes</li> <li>examples and sample outputs (when applicable)</li> <li>Prefer relative links inside <code>/docs</code>.</li> <li>Avoid linking to repository paths that do not exist in the rendered MkDocs site.</li> </ul>"},{"location":"project/docs-style/#markdown-conventions","title":"Markdown conventions","text":"<ul> <li>Use fenced code blocks with language hints.</li> <li>Use admonitions for warnings and important notes.</li> <li>Keep line length readable (wrap long paragraphs).</li> </ul>"},{"location":"project/glossary/","title":"Glossary","text":"<p>A small shared vocabulary used throughout the suite docs.</p> <ul> <li>Artifact: a versioned offline output (e.g., popularity list) consumed by the service.</li> <li>Manifest: a pointer/document that tells the service which artifact versions are current.</li> <li>Namespace: an application-defined bucket of recommendation logic/data (e.g., per catalog).</li> <li>Surface: where recommendations are shown (home, PDP, cart, \u2026).</li> <li>Tenant: an organization boundary for configuration and data isolation.</li> </ul>"},{"location":"project/governance/","title":"Governance","text":""},{"location":"project/governance/#maintainers","title":"Maintainers","text":"<p>This project is currently maintained by the core maintainer(s). Maintainers are responsible for:</p> <ul> <li>Reviewing and merging pull requests</li> <li>Cutting releases</li> <li>Managing security reports</li> <li>Curating roadmap direction</li> </ul>"},{"location":"project/governance/#decision-making","title":"Decision-making","text":"<p>Default decision model:</p> <ul> <li>Lazy consensus for small changes</li> <li>Maintainer decision for roadmap and release decisions</li> <li>Discuss major changes in an issue before implementation</li> </ul>"},{"location":"project/governance/#becoming-a-maintainer","title":"Becoming a maintainer","text":"<p>We may invite contributors to become maintainers based on:</p> <ul> <li>sustained high-quality contributions</li> <li>good judgment and communication</li> <li>alignment with project goals</li> </ul>"},{"location":"project/licenses_readme/","title":"License Directory Notes","text":"<p>This repository uses multiple licenses.</p> <p>Recommended best practice (REUSE/SPDX style):</p> <ul> <li>License texts are stored in <code>LICENSES/</code> directory.</li> </ul> <ul> <li>Use <code>SPDX-License-Identifier:</code> headers in files</li> </ul> <p>Current split: See <code>docs/licensing/index.md</code> for the human-readable guide.</p>"},{"location":"project/security/","title":"Security Policy","text":""},{"location":"project/security/#reporting-a-vulnerability","title":"Reporting a vulnerability","text":"<p>Please do not open public GitHub issues for security vulnerabilities.</p> <p>Preferred reporting options:</p> <ol> <li>GitHub Security Advisories / Private vulnerability reporting (if enabled for this repo)</li> <li>Email: <code>security@recsys.app</code></li> </ol> <p>Include:</p> <ul> <li>A clear description of the issue and potential impact</li> <li>Steps to reproduce (PoC if possible)</li> <li>Affected versions/commit hashes</li> <li>Any suggested fixes or mitigations</li> </ul>"},{"location":"project/security/#coordinated-disclosure","title":"Coordinated disclosure","text":"<p>We follow coordinated disclosure:</p> <ul> <li>We will acknowledge receipt within 72 hours (best effort)</li> <li>We will work with you on a disclosure timeline where feasible</li> <li>We will credit reporters in release notes unless you prefer anonymity</li> </ul>"},{"location":"project/security/#supported-versions","title":"Supported versions","text":"<ul> <li>We aim to support the latest stable minor release line.</li> <li>Security fixes may be backported at our discretion, depending on severity and effort.</li> </ul>"},{"location":"project/security/#security-hardening-guidance-high-level","title":"Security hardening guidance (high level)","text":"<ul> <li>Run the service with least privilege</li> <li>Keep secrets out of images; use environment variables or a secrets manager</li> <li>Restrict network access; prefer private networking for internal deployments</li> <li>Monitor logs and metrics for anomalous traffic</li> </ul>"},{"location":"project/support/","title":"Support","text":"<p>This project supports self-serve adoption. We keep support lightweight and mostly asynchronous.</p>"},{"location":"project/support/#community-support-free","title":"Community support (free)","text":"<ul> <li>GitHub Issues for bugs and feature requests</li> <li>Discussions for questions</li> </ul> <p>We do not guarantee response times for free support.</p>"},{"location":"project/support/#commercial-support-paid","title":"Commercial support (paid)","text":"<p>Commercial customers get the support level defined in their agreement.</p> <p>Typical support channels include:</p> <ul> <li>Private support email which will be provided upon commercial agreement</li> <li>Private issue tracker or GitHub private issues</li> </ul> <p>No-meetings policy (default):</p> <ul> <li>Support is async-first</li> <li>Calls are only by exception and must be pre-agreed and time-boxed</li> </ul>"},{"location":"project/support/#what-we-can-help-with","title":"What we can help with","text":"<ul> <li>Installation and upgrade guidance</li> <li>Reproducible bug investigation (with logs/configs)</li> <li>Security patch guidance</li> </ul>"},{"location":"project/support/#what-we-do-not-provide-by-default","title":"What we do not provide by default","text":"<ul> <li>24/7 on-call</li> <li>Operating your infrastructure</li> <li>Unlimited custom development without a fixed scope</li> </ul>"},{"location":"project/support/#before-opening-an-issue","title":"Before opening an issue","text":"<p>Please include:</p> <ul> <li>Version/commit hash</li> <li>Deployment mode (docker compose / k8s / helm)</li> <li>Logs and minimal reproduction steps</li> </ul>"},{"location":"recsys-algo/","title":"recsys-algo","text":"<p>Deterministic recommendation engine with explainable scoring, optional personalization, and merchandising rules.</p> <p>This module is the ranking core of the suite. It consumes candidate sets (popularity, co-visitation, similarity, etc.), applies constraints/rules, and produces a ranked list with optional explain/trace details.</p>"},{"location":"recsys-algo/#start-here","title":"Start here","text":"<ul> <li>Concepts: <code>concepts.md</code></li> <li>Integration (store ports): <code>store-ports.md</code></li> <li>Examples: <code>examples.md</code></li> <li>Releases: <code>releases.md</code></li> </ul>"},{"location":"recsys-algo/#where-this-fits","title":"Where this fits","text":"<ul> <li>recsys-service calls into <code>recsys-algo</code> to generate ranked outputs.</li> <li>recsys-pipelines produces artifacts/signals that the service exposes as stores.</li> <li>recsys-eval validates changes in ranking behavior and business KPIs.</li> </ul>"},{"location":"recsys-algo/concepts/","title":"Concepts","text":"<p><code>recsys-algo</code> is built for determinism, explainability, and safe operational behavior.</p>"},{"location":"recsys-algo/concepts/#signals-and-blending","title":"Signals and blending","text":"<p>The engine can blend multiple signals:</p> <ul> <li>Popularity (top-K)</li> <li>Co-visitation (users/items seen together)</li> <li>Similarity (embeddings / collaborative / content / session)</li> </ul> <p>A typical configuration exposes blending weights (often referred to as <code>BlendAlpha</code>, <code>BlendBeta</code>, <code>BlendGamma</code>) to control each signal's contribution.</p>"},{"location":"recsys-algo/concepts/#rules-and-constraints","title":"Rules and constraints","text":"<p>After scoring, the engine can apply:</p> <ul> <li>Merchandising rules: pin / boost / block</li> <li>Diversity and capping: MMR-style diversification, brand/category caps</li> <li>Hard limits: K bounds, exclusions, safety checks</li> </ul>"},{"location":"recsys-algo/concepts/#explainability","title":"Explainability","text":"<p>For debugging, audits, and safer rollouts, responses can include:</p> <ul> <li>Reasons (high-level explain blocks)</li> <li>Trace data (low-level diagnostics suitable for audit logs)</li> </ul> <p>Use explain/trace only when you need it \u2014 it can increase payload size and computation.</p>"},{"location":"recsys-algo/examples/","title":"Examples","text":"<p>The module ships runnable examples under <code>recsys-algo/examples/</code>.</p>"},{"location":"recsys-algo/examples/#install","title":"Install","text":"<pre><code>go get github.com/aatuh/recsys-suite/api/recsys-algo\n</code></pre>"},{"location":"recsys-algo/examples/#minimal-example-popularity-only","title":"Minimal example (popularity-only)","text":"<p>See <code>recsys-algo/examples/basic</code> for a runnable popularity-only pipeline.</p>"},{"location":"recsys-algo/examples/#full-examples","title":"Full examples","text":"<ul> <li><code>recsys-algo/examples/personalized</code> \u2014 user profile + personalization</li> <li><code>recsys-algo/examples/rules</code> \u2014 pin/boost/block rule application</li> </ul>"},{"location":"recsys-algo/releases/","title":"Releases","text":"<p>Tag releases with the module prefix, for example:</p> <ul> <li><code>recsys-algo/v0.2.0</code></li> </ul> <p>Each module in the suite can be versioned and released independently.</p>"},{"location":"recsys-algo/store-ports/","title":"Store ports","text":"<p><code>recsys-algo</code> follows a ports-and-adapters style:</p> <ul> <li><code>model</code> defines interfaces (ports) for data access.</li> <li><code>algorithm</code> consumes those ports to produce ranked outputs.</li> </ul> <p>This separation makes the engine testable and lets you plug in different storage/backends (Postgres, Redis, object store, in-memory, etc.).</p>"},{"location":"recsys-algo/store-ports/#minimal-required-ports","title":"Minimal required ports","text":"<p>At minimum, implement:</p> <ul> <li><code>model.PopularityStore</code> \u2014 provides popularity candidates</li> <li><code>model.TagStore</code> \u2014 provides item tags used for filtering/diversity/caps</li> </ul>"},{"location":"recsys-algo/store-ports/#optional-ports-enable-more-signals","title":"Optional ports (enable more signals)","text":"<p>Depending on which signals/features you want, implement one or more of:</p> <ul> <li><code>model.ProfileStore</code> \u2014 user profile for personalization</li> <li><code>model.CooccurrenceStore</code> / <code>model.HistoryStore</code> \u2014 co-visitation</li> <li><code>model.EmbeddingStore</code> \u2014 embedding similarity</li> <li><code>model.CollaborativeStore</code> \u2014 ALS/CF similarity</li> <li><code>model.ContentStore</code> \u2014 content similarity (tag overlap)</li> <li><code>model.SessionStore</code> \u2014 session sequences</li> <li><code>model.EventStore</code> \u2014 event-based exclusions</li> </ul> <p>If a capability is missing, the engine should treat the signal as unavailable and continue.</p>"},{"location":"recsys-algo/store-ports/#runtime-feature-disabling","title":"Runtime feature disabling","text":"<p>To disable a feature at runtime (even if the port exists), return <code>model.ErrFeatureUnavailable</code> from a method.</p>"},{"location":"recsys-eval/overview/","title":"recsys-eval","text":"<p>recsys-eval turns recommendation logs into reports that tell you whether a recommender change is better, worse, or unclear - globally and per segment - with guardrails.</p> <p>If you only read one thing: read <code>Concepts</code>.</p>"},{"location":"recsys-eval/overview/#who-this-is-for","title":"Who this is for","text":"<ul> <li>Engineers shipping recommender changes</li> <li>Analysts and DS folks validating impact</li> <li>Platform teams wiring evaluation into CI</li> <li>Anyone who wants a clear \"ship / hold / rollback\" decision trail</li> </ul>"},{"location":"recsys-eval/overview/#what-you-get","title":"What you get","text":"<ul> <li>Offline evaluation (fast regression gate)</li> <li>Experiment analysis (A/B from production logs)</li> <li>Off-policy evaluation (OPE) when experiments are hard</li> <li>Interleaving analysis for sensitive ranker comparisons</li> <li>JSON/Markdown/HTML reports + optional decision artifact</li> </ul>"},{"location":"recsys-eval/overview/#quick-start-jsonl","title":"Quick start (JSONL)","text":"<p>1) Validate your inputs (recommended):</p> <pre><code>recsys-eval validate \\\n  --schema exposure.v1 \\\n  --input testdata/datasets/tiny/exposures.jsonl\n</code></pre> <p>1) Run an evaluation (choose one mode):</p> <pre><code># Offline evaluation\nrecsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.default.yaml \\\n  --output /tmp/offline_report.json\n\n# Markdown report\nrecsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.default.yaml \\\n  --output /tmp/offline_report.md \\\n  --output-format markdown\n\n# Experiment analysis\nrecsys-eval run \\\n  --mode experiment \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/experiment.default.yaml \\\n  --output /tmp/experiment_report.json\n\n# Offline evaluation (signals sample dataset)\nrecsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.signals.yaml \\\n  --config configs/eval/offline.signals.yaml \\\n  --output /tmp/offline_signals_report.json\n\n# Off-policy evaluation (OPE)\nrecsys-eval run \\\n  --mode ope \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/ope.default.yaml \\\n  --output /tmp/ope_report.json\n\n# Interleaving analysis\nrecsys-eval run \\\n  --mode interleaving \\\n  --dataset configs/examples/dataset.interleaving.jsonl.yaml \\\n  --config configs/eval/interleaving.default.yaml \\\n  --output /tmp/interleaving_report.json\n</code></pre>"},{"location":"recsys-eval/overview/#outputs","title":"Outputs","text":"<p>The primary output is a JSON report that conforms to api/schemas/report.v1.json. You can also emit Markdown or HTML summaries for sharing. It always includes:</p> <ul> <li>run_id</li> <li>mode</li> <li>created_at</li> <li>version</li> <li>summary</li> </ul> <p>Mode-specific sections are included when relevant: offline, experiment, ope, interleaving, aa_check.</p> <p>Optionally, some modes can emit a decision artifact that conforms to api/schemas/decision.v1.json.</p>"},{"location":"recsys-eval/overview/#read-next","title":"Read next","text":"<ul> <li><code>Concepts</code>: what the system does and how to think about it</li> <li><code>Data contracts</code>: what your inputs must look like</li> <li><code>Interpreting results</code>: how to read reports and make decisions</li> </ul> <p>Company-grade additions:</p> <ul> <li><code>Integration</code>: how to emit logs from a serving system</li> <li><code>CI gates</code>: exit codes, gating, and recommended pipelines</li> <li><code>Scaling</code>: large datasets and stream mode</li> <li><code>Runbooks</code> and <code>Troubleshooting</code>: debug and operate it</li> <li><code>OPE</code> and <code>Interleaving</code>: deeper dives</li> <li><code>Architecture</code>: extension points and how to add features</li> </ul>"},{"location":"recsys-eval/overview/#releases","title":"Releases","text":"<p>Tag releases with the module prefix, e.g. <code>recsys-eval/v0.2.0</code>.</p>"},{"location":"recsys-eval/docs/","title":"Index","text":"<p>If you are new:</p> <ul> <li><code>RecSys Eval Overview</code></li> <li><code>Concepts</code></li> </ul> <p>If you need to integrate:</p> <ul> <li><code>Data Contracts</code></li> <li><code>Integration</code></li> </ul> <p>If you need to interpret results:</p> <ul> <li><code>Metrics</code></li> <li><code>Interpreting Results</code></li> </ul> <p>If you run this in CI or ops:</p> <ul> <li><code>CI Gates</code></li> <li><code>Scaling</code></li> <li><code>Runbooks</code></li> <li><code>Troubleshooting</code></li> </ul> <p>Deep dives:</p> <ul> <li><code>OPE</code></li> <li><code>Interleaving</code></li> <li><code>Architecture</code></li> </ul>"},{"location":"recsys-eval/docs/architecture/","title":"Architecture: how the code is organized and how to extend it","text":""},{"location":"recsys-eval/docs/architecture/#who-this-is-for","title":"Who this is for","text":"<p>Maintainers and contributors.</p>"},{"location":"recsys-eval/docs/architecture/#what-you-will-get","title":"What you will get","text":"<ul> <li>The boundaries (domain vs ports vs adapters)</li> <li>Where to add a new metric, datasource, or report writer</li> <li>How to avoid creating a god-package</li> </ul>"},{"location":"recsys-eval/docs/architecture/#high-level-structure","title":"High-level structure","text":"<ul> <li>cmd/:</li> </ul> <p>CLI entrypoints</p> <ul> <li>internal/domain/:</li> </ul> <p>pure logic: metrics, statistics, joining rules, report models</p> <ul> <li>internal/ports/:</li> </ul> <p>interfaces for IO: datasources, report writers, loggers</p> <ul> <li>internal/adapters/:</li> </ul> <p>concrete IO: JSONL readers, Postgres readers, writers</p> <ul> <li>internal/app/:</li> </ul> <p>usecases that orchestrate domain logic + ports</p> <p>If you keep domain pure, tests become easy and reliability improves.</p>"},{"location":"recsys-eval/docs/architecture/#add-a-new-metric","title":"Add a new metric","text":"<p>1) Implement the metric in internal/domain/metrics/... 2) Add it to the registry (internal/domain/metrics/registry.go) 3) Add tests with toy inputs and known outputs 4) Document it in <code>metrics.md</code></p>"},{"location":"recsys-eval/docs/architecture/#add-a-new-datasource","title":"Add a new datasource","text":"<p>1) Implement ports interfaces (ExposureReader, OutcomeReader, etc.) 2) Add adapter under internal/adapters/datasource/<code>yourtype</code>/ 3) Wire it into the datasource factory or provider registry (depending on repo)</p>"},{"location":"recsys-eval/docs/architecture/#add-a-new-report-format","title":"Add a new report format","text":"<p>1) Implement a writer adapter under internal/adapters/reporting/ 2) Ensure the JSON report stays canonical (other formats derive from it)</p>"},{"location":"recsys-eval/docs/architecture/#the-rule-of-thumb","title":"The rule of thumb","text":"<ul> <li>Domain code should not import adapters.</li> <li>Ports should not import adapters.</li> <li>Adapters can import ports and domain.</li> </ul> <p>This keeps the system testable and change-friendly.</p>"},{"location":"recsys-eval/docs/ci_gates/","title":"CI gates: using recsys-eval in automation","text":""},{"location":"recsys-eval/docs/ci_gates/#who-this-is-for","title":"Who this is for","text":"<p>Engineers wiring recsys-eval into CI/CD or scheduled pipelines.</p>"},{"location":"recsys-eval/docs/ci_gates/#what-you-will-get","title":"What you will get","text":"<ul> <li>A practical gating pattern</li> <li>How to use exit codes</li> <li>How to store artifacts and compare runs</li> </ul>"},{"location":"recsys-eval/docs/ci_gates/#the-pattern-validate-run-store-report-gate","title":"The pattern: validate -&gt; run -&gt; store report -&gt; gate","text":"<p>1) Validate data (optional but recommended) 2) Run evaluation 3) Upload report artifact 4) Fail the pipeline if gates fail</p> <p>Example (tiny dataset gate used in CI):</p> <pre><code>recsys-eval run \\\n  --mode offline \\\n  --dataset configs/examples/dataset.jsonl.yaml \\\n  --config configs/eval/offline.ci.yaml \\\n  --output /tmp/offline_report.json \\\n  --baseline testdata/golden/offline.json\n</code></pre>"},{"location":"recsys-eval/docs/ci_gates/#exit-codes","title":"Exit codes","text":"<p>recsys-eval is designed to be automation-friendly:</p> <ul> <li>configuration or schema errors should fail fast</li> <li>gate failures should fail deterministically</li> </ul> <p>Recommended practice:</p> <ul> <li>treat \"invalid input\" differently from \"metric regression\"</li> </ul> <p>If your build supports a decision artifact:</p> <ul> <li>fail if decision != ship</li> <li>attach decision.json and report.json to the build</li> </ul>"},{"location":"recsys-eval/docs/ci_gates/#artifact-storage","title":"Artifact storage","text":"<p>Store:</p> <ul> <li>report.json</li> <li>effective config (or config hash)</li> <li>dataset fingerprint / window</li> <li>the exact binary version (build info)</li> </ul> <p>This is what makes runs auditable.</p>"},{"location":"recsys-eval/docs/ci_gates/#golden-tests-vs-production-gates","title":"Golden tests vs production gates","text":"<p>Golden tests:</p> <ul> <li>use tiny datasets</li> <li>protect behavior and output stability</li> </ul> <p>Production gates:</p> <ul> <li>use real logs</li> <li>protect business impact and safety</li> </ul> <p>Do not confuse the two. Use both.</p>"},{"location":"recsys-eval/docs/concepts/","title":"Concepts: how to understand recsys-eval","text":""},{"location":"recsys-eval/docs/concepts/#who-this-is-for","title":"Who this is for","text":"<p>Anyone. This is the \"map\" of the system.</p>"},{"location":"recsys-eval/docs/concepts/#what-you-will-get","title":"What you will get","text":"<ul> <li>The core mental model in 5 minutes</li> <li>The four workflows and when to use each</li> <li>A small glossary so words like \"exposure\" stop being mysterious</li> </ul>"},{"location":"recsys-eval/docs/concepts/#the-mental-model-in-one-picture","title":"The mental model in one picture","text":"<p>You log:</p> <ul> <li>what you showed (exposures)</li> <li>what users did (outcomes)</li> <li>who was in A vs B (assignments, for experiments)</li> </ul> <p>recsys-eval reads those logs and produces a report and optional decision.</p> <pre><code>exposures (ranked list shown)\n        + outcomes (clicks, purchases, etc.)\n        + assignments (control vs candidate)\n-------------------------------------------&gt; recsys-eval\n-------------------------------------------&gt; report.json (+ optional decision.json)\n</code></pre>"},{"location":"recsys-eval/docs/concepts/#glossary","title":"Glossary","text":"<ul> <li>request_id:</li> </ul> <p>A single recommendation moment. One screen, one call, one \"ranked list shown\".   In recsys-eval, request_id is the main join key.</p> <ul> <li>exposure:</li> </ul> <p>What you showed to the user for a request_id: the ranked list of items plus   context (tenant, surface, etc.).</p> <ul> <li>outcome:</li> </ul> <p>What the user did after the exposure: click, conversion, revenue, etc.</p> <ul> <li>assignment:</li> </ul> <p>Which experiment variant a request/user belongs to (control or candidate).</p> <ul> <li>segment:</li> </ul> <p>A slice such as tenant + surface + device. Segments are where hidden problems   show up. Global averages lie.</p> <ul> <li>guardrail:</li> </ul> <p>A metric that must not regress even if a primary metric improves. Typical   guardrails: latency, errors, empty recommendation rate.</p> <ul> <li>propensity (OPE only):</li> </ul> <p>A probability that a policy would show an item in a position. If you do not   have correct propensities, OPE can confidently produce nonsense.</p>"},{"location":"recsys-eval/docs/concepts/#the-four-workflows-pick-the-right-tool","title":"The four workflows (pick the right tool)","text":""},{"location":"recsys-eval/docs/concepts/#1-offline-evaluation","title":"1) Offline evaluation","text":"<p>Question:</p> <ul> <li>\"If we rank differently, does it better match what users later did?\"</li> </ul> <p>Inputs:</p> <ul> <li>exposures + outcomes</li> </ul> <p>Outputs:</p> <ul> <li>ranking metrics (NDCG@K, Recall@K, MAP@K, etc.)</li> <li>segment breakdowns</li> <li>optional confidence intervals</li> </ul> <p>When to use:</p> <ul> <li>before shipping changes</li> <li>regression gate in CI</li> </ul> <p>Common pitfalls:</p> <ul> <li>your join from exposures to outcomes is broken</li> <li>your \"ground truth\" is too sparse or biased</li> </ul>"},{"location":"recsys-eval/docs/concepts/#2-experiment-analysis-ab","title":"2) Experiment analysis (A/B)","text":"<p>Question:</p> <ul> <li>\"In production, did variant B outperform A, and did we stay within guardrails?\"</li> </ul> <p>Inputs:</p> <ul> <li>exposures + outcomes + assignments</li> </ul> <p>Outputs:</p> <ul> <li>KPI deltas (CTR, conversion, etc.)</li> <li>confidence intervals or p-values (depending on config)</li> <li>guardrail checks</li> <li>optional decision artifact (ship/hold/rollback)</li> </ul> <p>When to use:</p> <ul> <li>shipping decisions</li> </ul> <p>Common pitfalls:</p> <ul> <li>SRM (sample ratio mismatch): buckets are not balanced</li> <li>too many segments: false positives</li> </ul>"},{"location":"recsys-eval/docs/concepts/#3-off-policy-evaluation-ope","title":"3) Off-policy evaluation (OPE)","text":"<p>Question:</p> <ul> <li>\"Can we estimate impact from logs without running an experiment?\"</li> </ul> <p>Inputs:</p> <ul> <li>exposures + outcomes + propensities</li> </ul> <p>Outputs:</p> <ul> <li>IPS/SNIPS/DR estimates and diagnostics</li> <li>warnings about variance and missing propensities</li> </ul> <p>When to use:</p> <ul> <li>directional iteration when A/B is expensive</li> </ul> <p>Common pitfalls:</p> <ul> <li>missing overlap: the new policy behaves outside the support of the logged one</li> <li>near-zero propensities: variance explodes</li> </ul>"},{"location":"recsys-eval/docs/concepts/#4-interleaving","title":"4) Interleaving","text":"<p>Question:</p> <ul> <li>\"Between ranker A and B, which one wins more often on the same traffic?\"</li> </ul> <p>Inputs:</p> <ul> <li>ranker A results + ranker B results + outcomes (often clicks)</li> </ul> <p>Outputs:</p> <ul> <li>win rates, tie rate, p-value</li> </ul> <p>When to use:</p> <ul> <li>comparing two rankers or weight sets quickly</li> <li>when A/B would be too slow or noisy</li> </ul> <p>Common pitfalls:</p> <ul> <li>you treat interleaving as a full business KPI replacement (it is not)</li> </ul>"},{"location":"recsys-eval/docs/concepts/#where-this-fits-in-the-bigger-system","title":"Where this fits in the bigger system","text":"<p>Typical stack:</p> <ul> <li>recsys-service: serves recs and logs exposures and outcomes</li> <li>recsys-pipelines: builds artifacts (popularity, co-occurrence, embeddings)</li> <li>recsys-algo: ranks and applies rules</li> <li>recsys-eval: measures and decides</li> </ul> <p>recsys-eval is the \"truth serum\": it turns change claims into evidence.</p>"},{"location":"recsys-eval/docs/data_contracts/","title":"Data contracts: what inputs look like","text":""},{"location":"recsys-eval/docs/data_contracts/#who-this-is-for","title":"Who this is for","text":"<p>Integrators and anyone who needs to produce valid input logs.</p>"},{"location":"recsys-eval/docs/data_contracts/#what-you-will-get","title":"What you will get","text":"<ul> <li>The minimum required fields for each input type</li> <li>How the joins work</li> <li>Small example records</li> </ul> <p>recsys-eval uses JSON Schemas for validation:</p> <ul> <li>schemas/exposure.v1.json</li> <li>schemas/outcome.v1.json</li> <li>schemas/assignment.v1.json</li> <li>api/schemas/report.v1.json</li> <li>api/schemas/decision.v1.json</li> </ul> <p>Use the validate command before doing anything else:</p> <pre><code>recsys-eval validate --schema exposure.v1 --input exposures.jsonl\nrecsys-eval validate --schema outcome.v1 --input outcomes.jsonl\nrecsys-eval validate --schema assignment.v1 --input assignments.jsonl\n</code></pre>"},{"location":"recsys-eval/docs/data_contracts/#record-formats","title":"Record formats","text":""},{"location":"recsys-eval/docs/data_contracts/#exposure-what-was-shown","title":"Exposure (what was shown)","text":"<p>Purpose:</p> <ul> <li>describes what items were recommended and in what order</li> <li>provides context for segment slicing</li> <li>acts as the \"left side\" of joins</li> </ul> <p>Join key:</p> <ul> <li>request_id (required)</li> </ul> <p>Minimal example (illustrative, not exhaustive):</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"tenant\": \"demo\",\n  \"surface\": \"home\",\n  \"user_id\": \"u_42\",\n  \"timestamp\": \"2026-01-27T12:00:00Z\",\n  \"items\": [\n    {\"item_id\": \"A\", \"rank\": 1},\n    {\"item_id\": \"B\", \"rank\": 2}\n  ]\n}\n</code></pre> <p>Notes:</p> <ul> <li>For OPE, exposures may also include propensities. See docs/OPE.md.</li> </ul>"},{"location":"recsys-eval/docs/data_contracts/#outcome-what-the-user-did","title":"Outcome (what the user did)","text":"<p>Purpose:</p> <ul> <li>records the behavior you care about: click, conversion, etc.</li> </ul> <p>Join key:</p> <ul> <li>request_id (required)</li> </ul> <p>Minimal example:</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"event\": \"click\",\n  \"item_id\": \"B\",\n  \"timestamp\": \"2026-01-27T12:00:05Z\"\n}\n</code></pre>"},{"location":"recsys-eval/docs/data_contracts/#assignment-experiment-bucket","title":"Assignment (experiment bucket)","text":"<p>Purpose:</p> <ul> <li>tells which variant a request/user belongs to (control vs candidate)</li> </ul> <p>Join key:</p> <ul> <li>request_id (required in this dataset contract)</li> </ul> <p>Minimal example:</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"experiment_id\": \"exp_home_rank_v3\",\n  \"variant\": \"control\"\n}\n</code></pre>"},{"location":"recsys-eval/docs/data_contracts/#interleaving-datasets","title":"Interleaving datasets","text":"<p>Interleaving mode uses a different dataset config:</p> <ul> <li>ranker_a results</li> <li>ranker_b results</li> <li>outcomes (often clicks)</li> </ul> <p>See configs/examples/dataset.interleaving.jsonl.yaml for the wiring.</p>"},{"location":"recsys-eval/docs/data_contracts/#join-expectations-and-quality-signals","title":"Join expectations and quality signals","text":"<p>Good joins are boring. Bad joins destroy trust.</p> <p>In reports, look for:</p> <ul> <li>match rate: how many exposures have outcomes</li> <li>duplicate request_id rates</li> <li>timestamp anomalies</li> <li>missing tenant/surface fields (kills segmentation)</li> </ul> <p>If joins look wrong, stop and fix instrumentation. Do not \"tune metrics\".</p>"},{"location":"recsys-eval/docs/integration/","title":"Integration: how to produce the inputs","text":""},{"location":"recsys-eval/docs/integration/#who-this-is-for","title":"Who this is for","text":"<p>Backend / platform engineers wiring recsys-eval into a real recommender stack.</p>"},{"location":"recsys-eval/docs/integration/#what-you-will-get","title":"What you will get","text":"<ul> <li>What you need to log in your serving system</li> <li>How to keep IDs stable and privacy-safe</li> <li>A minimal logging plan for each mode</li> </ul>"},{"location":"recsys-eval/docs/integration/#the-one-rule-always-log-exposures","title":"The one rule: always log exposures","text":"<p>If you want to measure recommendations, you must log \"what you showed\". Clicks without exposures are not evaluatable.</p>"},{"location":"recsys-eval/docs/integration/#exposure-logging-recommended-fields","title":"Exposure logging (recommended fields)","text":"<p>At recommendation time (serving):</p> <ul> <li>request_id: unique per recommendation request</li> <li>tenant, surface: required for segmentation</li> <li>user_id or session_id: pseudonymized</li> <li>timestamp (ISO-8601)</li> <li>the ranked list of items (item_id + rank)</li> <li>optional: latency_ms, model_version, config_version, algo_version</li> <li>optional for deeper analysis: per-item scores and reasons (if you have them)</li> </ul> <p>Minimal JSONL exposure record:</p> <pre><code>{\n  \"request_id\": \"req_123\",\n  \"tenant\": \"demo\",\n  \"surface\": \"home\",\n  \"user_id\": \"u_hash_...\",\n  \"timestamp\": \"2026-01-27T12:00:00Z\",\n  \"items\": [{\"item_id\": \"A\", \"rank\": 1}]\n}\n</code></pre>"},{"location":"recsys-eval/docs/integration/#outcome-logging","title":"Outcome logging","text":"<p>After exposure, when the user acts:</p> <ul> <li>request_id (same one)</li> <li>event type: click, purchase, etc.</li> <li>item_id (the item clicked/converted)</li> <li>timestamp</li> </ul> <p>If you have revenue or value, log it. If you do not, do not invent it.</p>"},{"location":"recsys-eval/docs/integration/#assignment-logging-experiments","title":"Assignment logging (experiments)","text":"<p>When you run an experiment:</p> <ul> <li>assignment should be deterministic and consistent</li> <li>log control vs candidate in a way you can audit</li> </ul> <p>Minimum:</p> <ul> <li>request_id</li> <li>experiment_id</li> <li>variant</li> </ul>"},{"location":"recsys-eval/docs/integration/#ope-logging-advanced","title":"OPE logging (advanced)","text":"<p>If you want OPE:</p> <ul> <li>you must log propensities</li> <li>you must define what policy produced the logged exposures</li> </ul> <p>This is easy to get wrong. Read docs/OPE.md before attempting.</p>"},{"location":"recsys-eval/docs/integration/#privacy-and-ids","title":"Privacy and IDs","text":"<p>Guidelines:</p> <ul> <li>never log raw PII (email, phone)</li> <li>hash or pseudonymize user identifiers</li> <li>be consistent: the same user should map to the same pseudonymous ID</li> </ul>"},{"location":"recsys-eval/docs/integration/#minimal-viable-integration-by-mode","title":"\"Minimal viable integration\" by mode","text":"<p>Offline:</p> <ul> <li>exposures + outcomes</li> <li>no assignments needed</li> </ul> <p>Experiment:</p> <ul> <li>exposures + outcomes + assignments</li> </ul> <p>Interleaving:</p> <ul> <li>ranker_a results + ranker_b results + outcomes</li> </ul> <p>OPE:</p> <ul> <li>exposures + outcomes + propensities (hard requirement)</li> </ul>"},{"location":"recsys-eval/docs/integration/#operational-tip","title":"Operational tip","text":"<p>Start with the tiny dataset shipped in testdata. If you cannot make your production logs look like that, you will struggle later.</p>"},{"location":"recsys-eval/docs/interleaving/","title":"Interleaving: fast ranker comparison on the same traffic","text":""},{"location":"recsys-eval/docs/interleaving/#who-this-is-for","title":"Who this is for","text":"<p>Engineers comparing two rankers or weight sets.</p>"},{"location":"recsys-eval/docs/interleaving/#what-you-will-get","title":"What you will get","text":"<ul> <li>What interleaving measures</li> <li>When it is the right tool</li> <li>Common mistakes</li> </ul>"},{"location":"recsys-eval/docs/interleaving/#what-it-is","title":"What it is","text":"<p>Interleaving mixes two ranked lists (A and B) into one displayed list. Then it attributes user actions (often clicks) back to A or B.</p> <p>This can be more sensitive than a full A/B when you only care about ranking.</p>"},{"location":"recsys-eval/docs/interleaving/#what-it-is-not","title":"What it is not","text":"<p>Interleaving is not a full product KPI decision engine. It does not account for all downstream effects. Use it to choose between rankers, then validate with A/B.</p>"},{"location":"recsys-eval/docs/interleaving/#inputs","title":"Inputs","text":"<ul> <li>ranker_a results (per request_id)</li> <li>ranker_b results (per request_id)</li> <li>outcomes (clicks)</li> </ul> <p>Dataset wiring example: configs/examples/dataset.interleaving.jsonl.yaml</p>"},{"location":"recsys-eval/docs/interleaving/#output","title":"Output","text":"<ul> <li>A wins / B wins counts</li> <li>win rate and tie rate</li> <li>a significance estimate</li> </ul>"},{"location":"recsys-eval/docs/interleaving/#common-mistakes","title":"Common mistakes","text":"<ul> <li>comparing rankers trained on different candidate sets without noting it</li> <li>treating interleaving wins as business KPI wins</li> </ul>"},{"location":"recsys-eval/docs/interpreting_results/","title":"Interpreting results: how to go from report to decision","text":""},{"location":"recsys-eval/docs/interpreting_results/#who-this-is-for","title":"Who this is for","text":"<p>Anyone making ship/hold decisions (engineers, PMs, analysts).</p>"},{"location":"recsys-eval/docs/interpreting_results/#what-you-will-get","title":"What you will get","text":"<ul> <li>How to read a report</li> <li>How to decide \"ship / hold / rollback\" without fooling yourself</li> <li>What to do when results are unclear</li> </ul>"},{"location":"recsys-eval/docs/interpreting_results/#step-0-trust-the-data-before-trusting-the-metrics","title":"Step 0: Trust the data before trusting the metrics","text":"<p>Check:</p> <ul> <li>data_quality: missing fields, duplicates, anomalies</li> <li>join integrity: match rates, unexpected drops</li> <li>warnings: especially for OPE</li> </ul> <p>If these look bad, stop. Fix logging.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-1-start-with-the-summary","title":"Step 1: Start with the summary","text":"<p>The report includes a summary for quick scanning:</p> <ul> <li>mode</li> <li>main deltas (baseline vs candidate or control vs candidate)</li> <li>whether gates passed</li> </ul> <p>If the summary says \"inconclusive\", treat it as a real outcome.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-2-check-guardrails","title":"Step 2: Check guardrails","text":"<p>Even if the primary metric improves, do not ship if:</p> <ul> <li>empty rate regressed</li> <li>latency regressed outside budget</li> <li>error rate regressed</li> <li>a critical segment cliff appears</li> </ul> <p>Guardrails exist because \"winning slowly\" is losing.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-3-look-at-segments-as-a-radar-not-a-scoreboard","title":"Step 3: Look at segments as a radar, not a scoreboard","text":"<p>Segments answer:</p> <ul> <li>Who did this help?</li> <li>Who did this hurt?</li> <li>Is the impact consistent?</li> </ul> <p>Segments can also create false positives when you slice too much. Use segments as diagnostics unless you have power to claim segment wins.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-4-interpreting-uncertainty","title":"Step 4: Interpreting uncertainty","text":"<p>If you use confidence intervals or p-values:</p> <ul> <li>wide intervals mean you do not know yet</li> <li>small p-values can still happen by chance if you test too many things</li> </ul> <p>\"Inconclusive\" is not failure. It is a request for more data or a better experiment design.</p>"},{"location":"recsys-eval/docs/interpreting_results/#step-5-a-simple-decision-policy-you-can-adopt","title":"Step 5: A simple decision policy you can adopt","text":"<p>Suggested policy:</p> <ul> <li>SHIP:</li> </ul> <p>primary metric improves and guardrails hold and no major segment regressions</p> <ul> <li>HOLD:</li> </ul> <p>results are inconclusive or diagnostics warn about data quality</p> <ul> <li>ROLLBACK:</li> </ul> <p>primary regresses or guardrails regress or a major segment cliff appears</p> <p>This maps well to a decision artifact (api/schemas/decision.v1.json).</p>"},{"location":"recsys-eval/docs/interpreting_results/#what-to-do-when-it-is-unclear","title":"What to do when it is unclear","text":"<p>Choose one:</p> <ul> <li>run longer / collect more samples</li> <li>reduce variance (CUPED / better covariates)</li> <li>narrow the change (smaller delta)</li> <li>use interleaving for ranker comparison</li> <li>do offline gating first, then A/B</li> </ul>"},{"location":"recsys-eval/docs/interpreting_results/#common-pitfalls","title":"Common pitfalls","text":"<ul> <li>Confusing \"statistically significant\" with \"practically important\".</li> <li>Shipping a win that is isolated to a single surface and breaks another.</li> <li>Ignoring SRM warnings in experiments.</li> </ul> <p>Treat the report as a navigation tool, not a trophy.</p>"},{"location":"recsys-eval/docs/metrics/","title":"Metrics: what we measure and why","text":""},{"location":"recsys-eval/docs/metrics/#who-this-is-for","title":"Who this is for","text":"<p>Analysts, DS, and engineers who need to interpret the output correctly.</p>"},{"location":"recsys-eval/docs/metrics/#what-you-will-get","title":"What you will get","text":"<ul> <li>A practical description of the main metric families</li> <li>When each metric is useful</li> <li>What each metric can hide</li> </ul> <p>You do not need to love metrics. You just need to not be fooled by them.</p>"},{"location":"recsys-eval/docs/metrics/#offline-ranking-metrics-relevance-proxies","title":"Offline ranking metrics (relevance proxies)","text":"<p>Offline metrics compare the ranked list (exposure) against some notion of \"ground truth\" (outcomes). Common examples:</p> <ul> <li>HitRate@K:</li> </ul> <p>Did at least one relevant item appear in the top K?</p> <ul> <li>Precision@K:</li> </ul> <p>Of the top K items, how many were relevant?</p> <ul> <li>Recall@K:</li> </ul> <p>Of all relevant items, how many did we include in top K?</p> <ul> <li>MAP@K:</li> </ul> <p>Rewards putting relevant items early, averaged across requests.</p> <ul> <li>NDCG@K:</li> </ul> <p>A discounted gain metric: earlier is better; supports graded relevance.</p> <p>These are great for fast regression gating. They are not the same as business KPIs. They can disagree with online results.</p>"},{"location":"recsys-eval/docs/metrics/#experiment-metrics-business-facing","title":"Experiment metrics (business-facing)","text":"<p>Online metrics are computed from experiments (control vs candidate). Examples:</p> <ul> <li>CTR: clicks / exposures</li> <li>conversion rate: purchases / exposures</li> <li>revenue per exposure: sum(value) / exposures</li> <li>downstream engagement proxies (if you log them)</li> </ul> <p>These are closer to what the business cares about. They are noisier.</p>"},{"location":"recsys-eval/docs/metrics/#guardrails","title":"Guardrails","text":"<p>Guardrails exist to prevent you from shipping a \"win\" that breaks the system.</p> <p>Common guardrails:</p> <ul> <li>empty recommendation rate: response has zero items</li> <li>latency: p95/p99 changes</li> <li>error rate: HTTP failures or upstream store failures</li> <li>join integrity: if joins break, your metrics are fiction</li> </ul> <p>A typical decision policy:</p> <ul> <li>ship only if primary improves AND guardrails hold AND no segment cliffs</li> </ul>"},{"location":"recsys-eval/docs/metrics/#distribution-and-quality-metrics","title":"Distribution and quality metrics","text":"<p>These answer: \"Did we change what we show, even if CTR is stable?\"</p> <p>Examples:</p> <ul> <li>item coverage: how much of the catalog appears</li> <li>long-tail share: are we showing only popular items</li> <li>category shift: are we drifting away from desired category mix</li> <li>diversity: are top K items too similar</li> </ul> <p>These are especially useful when you care about discovery and fairness.</p>"},{"location":"recsys-eval/docs/metrics/#distribution-metrics-implemented-here","title":"Distribution metrics implemented here","text":"<p>These are proxy metrics derived from exposures and outcomes (no catalog metadata required):</p> <ul> <li>Coverage@K: unique items shown in top K across all requests divided by</li> </ul> <p>unique items seen anywhere in recommendations or outcomes. It answers   \"how much of the observed catalog is exposed in the top slots?\"</p> <ul> <li>Novelty@K: average <code>-log2(popularity)</code> for items shown in top K, where</li> </ul> <p>popularity is the global exposure frequency. Higher means \"less popular on   average\". This is a proxy for long\u2011tail exposure.</p> <ul> <li>Diversity@K: normalized entropy of the item distribution in top K</li> </ul> <p>recommendations across requests. Values near 1.0 mean a wide spread;   values near 0 mean concentration on a few items.</p> <p>If you have real catalog metadata (categories, embeddings), you should compute richer diversity/novelty metrics upstream and feed them as outcomes.</p>"},{"location":"recsys-eval/docs/metrics/#common-mistakes","title":"Common mistakes","text":"<ul> <li>\"CTR improved so we are done\":</li> </ul> <p>CTR can increase by getting click-bait-y or repeating popular items.</p> <ul> <li>\"Offline NDCG improved so it must ship\":</li> </ul> <p>Offline evaluation can be biased or too simplified.</p> <ul> <li>\"We looked at 50 segments and found 3 big wins\":</li> </ul> <p>This can be pure chance. Treat segments as diagnostics unless powered.</p>"},{"location":"recsys-eval/docs/metrics/#practical-recommendations","title":"Practical recommendations","text":"<p>Start with:</p> <ul> <li>1-2 primary metrics</li> <li>2-4 guardrails</li> <li>segment slicing limited to the top business cuts (tenant/surface/device)</li> </ul> <p>Add more only after you can run the basics reliably.</p>"},{"location":"recsys-eval/docs/ope/","title":"Off-policy evaluation (OPE): powerful and easy to misuse","text":""},{"location":"recsys-eval/docs/ope/#who-this-is-for","title":"Who this is for","text":"<p>Advanced users. Read this before using --mode ope in anything serious.</p>"},{"location":"recsys-eval/docs/ope/#what-you-will-get","title":"What you will get","text":"<ul> <li>What OPE tries to estimate</li> <li>What propensities are and why they matter</li> <li>When OPE results are trustworthy and when they are not</li> </ul>"},{"location":"recsys-eval/docs/ope/#the-promise","title":"The promise","text":"<p>OPE tries to answer:</p> <ul> <li>\"What would have happened if we used a different ranking policy?\"</li> </ul> <p>using logs collected from an old policy.</p> <p>This can save you from running an online experiment.</p>"},{"location":"recsys-eval/docs/ope/#the-catch","title":"The catch","text":"<p>OPE depends on assumptions that are easy to violate:</p> <ul> <li>correct propensity logging</li> <li>overlap between old and new policies (support)</li> <li>stable user behavior model</li> </ul> <p>If you violate these, OPE can confidently lie.</p>"},{"location":"recsys-eval/docs/ope/#propensities-in-plain-language","title":"Propensities in plain language","text":"<p>A propensity is the probability that a policy shows an item in a position.</p> <p>If an item never appears under the logging policy, you cannot reliably estimate how it would perform under a new policy. This is the \"no overlap\" problem.</p>"},{"location":"recsys-eval/docs/ope/#diagnostics-you-should-take-seriously","title":"Diagnostics you should take seriously","text":"<ul> <li>near-zero propensities:</li> </ul> <p>your estimator variance explodes</p> <ul> <li>missing target propensities:</li> </ul> <p>you are not evaluating the policy you think you are</p> <ul> <li>heavy clipping:</li> </ul> <p>your result is dominated by a few samples</p>"},{"location":"recsys-eval/docs/ope/#a-practical-when-to-use-checklist","title":"A practical \"when to use\" checklist","text":"<p>Use OPE when:</p> <ul> <li>you log propensities correctly</li> <li>your new policy is a mild change from the old</li> <li>you mainly want directional signal</li> </ul> <p>Do not use OPE when:</p> <ul> <li>the new policy changes candidate generation dramatically</li> <li>you have missing propensity fields</li> <li>you care about strict ship/no-ship</li> </ul>"},{"location":"recsys-eval/docs/ope/#recommended-practice","title":"Recommended practice","text":"<ul> <li>Use offline evaluation first.</li> <li>Use OPE as an early filter.</li> <li>Use A/B or interleaving for the final decision.</li> </ul>"},{"location":"recsys-eval/docs/roadmap/","title":"Roadmap (high level)","text":"<p>This doc is intentionally short. It exists to set expectations.</p>"},{"location":"recsys-eval/docs/roadmap/#now-stability-and-trust","title":"Now (stability and trust)","text":"<ul> <li>streaming-first for big logs</li> <li>structured logging and run correlation</li> <li>reproducibility: config and dataset fingerprints</li> </ul>"},{"location":"recsys-eval/docs/roadmap/#next-power-and-sensitivity","title":"Next (power and sensitivity)","text":"<ul> <li>stronger experiment analysis features (variance reduction)</li> <li>better segment regression surfacing</li> <li>richer guardrails</li> </ul>"},{"location":"recsys-eval/docs/roadmap/#later-advanced-evaluation","title":"Later (advanced evaluation)","text":"<ul> <li>more OPE diagnostics and ranking-specific estimators</li> <li>interleaving variants and deeper analysis</li> </ul>"},{"location":"recsys-eval/docs/roadmap/#non-goals","title":"Non-goals","text":"<ul> <li>training models</li> <li>serving recommendations</li> <li>replacing a full experimentation platform</li> </ul>"},{"location":"recsys-eval/docs/runbooks/","title":"Runbooks: operating recsys-eval","text":""},{"location":"recsys-eval/docs/runbooks/#who-this-is-for","title":"Who this is for","text":"<p>Maintainers and on-call engineers.</p>"},{"location":"recsys-eval/docs/runbooks/#what-you-will-get","title":"What you will get","text":"<ul> <li>The top failure modes and how to debug them quickly</li> <li>A repeatable \"triage\" flow</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#triage-flow","title":"Triage flow","text":"<ol> <li> <p>Identify the run:</p> </li> <li> <p>run_id</p> </li> <li>mode</li> <li>dataset window</li> <li> <p>binary version</p> </li> <li> <p>Check data quality:</p> </li> <li> <p>schema validation</p> </li> <li>duplicates</li> <li> <p>missing required fields</p> </li> <li> <p>Check joins:</p> </li> <li> <p>match rates</p> </li> <li> <p>timestamp anomalies</p> </li> <li> <p>Check gates and warnings:</p> </li> <li> <p>which metric triggered the gate</p> </li> <li> <p>which segment drove the regression</p> </li> <li> <p>Decide action:</p> </li> <li> <p>fix data</p> </li> <li>rerun</li> <li>rollback config/model</li> <li>escalate</li> </ol>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-schema-validation-fails","title":"Failure mode: schema validation fails","text":"<p>Symptoms:</p> <ul> <li>validate command reports missing fields or wrong types</li> </ul> <p>Fix:</p> <ul> <li>update logging to match schemas</li> <li>if schema changed, bump schema version and update producers</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-join-match-rate-collapses","title":"Failure mode: join match rate collapses","text":"<p>Symptoms:</p> <ul> <li>offline metrics drop to near zero</li> <li>report shows low join match</li> </ul> <p>Likely causes:</p> <ul> <li>request_id changed format</li> <li>producers stopped logging outcomes with request_id</li> <li>duplicate or missing request_id in exposures</li> </ul> <p>Fix:</p> <ul> <li>compare recent exposure and outcome samples</li> <li>confirm request_id consistency end-to-end</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-srm-warning-experiments","title":"Failure mode: SRM warning (experiments)","text":"<p>Symptoms:</p> <ul> <li>control vs candidate sample sizes are off</li> </ul> <p>Likely causes:</p> <ul> <li>bucket assignment bug</li> <li>logging bug</li> <li>rollout was not actually 50/50</li> </ul> <p>Fix:</p> <ul> <li>stop interpreting metrics</li> <li>fix assignment and rerun</li> </ul>"},{"location":"recsys-eval/docs/runbooks/#failure-mode-ope-high-variance","title":"Failure mode: OPE high variance","text":"<p>Symptoms:</p> <ul> <li>warnings about near-zero propensities</li> <li>wildly unstable estimates</li> </ul> <p>Fix:</p> <ul> <li>do not ship based on OPE</li> <li>improve propensity logging and overlap</li> <li>prefer A/B or interleaving</li> </ul>"},{"location":"recsys-eval/docs/scaling/","title":"Scaling: large datasets and performance","text":""},{"location":"recsys-eval/docs/scaling/#who-this-is-for","title":"Who this is for","text":"<p>Anyone running recsys-eval on real production-sized logs.</p>"},{"location":"recsys-eval/docs/scaling/#what-you-will-get","title":"What you will get","text":"<ul> <li>When JSONL is enough and when to move to a warehouse</li> <li>How stream mode works and what it requires</li> <li>Practical tips to avoid OOM and slow runs</li> </ul>"},{"location":"recsys-eval/docs/scaling/#reality-check","title":"Reality check","text":"<p>If your logs are gigabytes:</p> <ul> <li>reading everything into memory is not acceptable</li> <li>joining exposures and outcomes is the main cost center</li> </ul> <p>Your goals:</p> <ul> <li>bounded memory</li> <li>stable runtime</li> <li>reproducible results</li> </ul>"},{"location":"recsys-eval/docs/scaling/#data-source-choices","title":"Data source choices","text":"<p>Small datasets:</p> <ul> <li>JSONL is fine</li> </ul> <p>Large datasets:</p> <ul> <li>prefer a warehouse-backed adapter (Postgres, etc.)</li> <li>let SQL do joins when possible</li> </ul>"},{"location":"recsys-eval/docs/scaling/#stream-mode-jsonl","title":"Stream mode (JSONL)","text":"<p>Offline mode can support stream mode for large presorted JSONL inputs:</p> <ul> <li>merge join by request_id</li> <li>requires exposures and outcomes sorted by request_id</li> </ul> <p>If inputs are not sorted, stream mode will not behave correctly. Note: dataset-level distribution metrics (coverage/novelty/diversity) are not available in stream mode.</p>"},{"location":"recsys-eval/docs/scaling/#practical-knobs-recommended","title":"Practical knobs (recommended)","text":"<ul> <li>Run per tenant and per surface, then aggregate.</li> <li>Reduce slice keys until you understand performance.</li> <li>Start without bootstrap; add it once the basics work.</li> </ul>"},{"location":"recsys-eval/docs/scaling/#performance-debugging-checklist","title":"Performance debugging checklist","text":"<ul> <li>Is join match rate unexpectedly low?</li> <li>Are there duplicate request_id values?</li> <li>Are you reading through network storage instead of local disk?</li> <li>Are you outputting huge reports because you enabled too much detail?</li> </ul> <p>When in doubt, reduce scope, confirm correctness, then scale up.</p>"},{"location":"recsys-eval/docs/security_privacy/","title":"Security and privacy notes","text":""},{"location":"recsys-eval/docs/security_privacy/#who-this-is-for","title":"Who this is for","text":"<p>Anyone handling real user data.</p>"},{"location":"recsys-eval/docs/security_privacy/#what-you-will-get","title":"What you will get","text":"<ul> <li>A safe baseline for logging and storage</li> <li>Common pitfalls</li> </ul>"},{"location":"recsys-eval/docs/security_privacy/#baseline","title":"Baseline","text":"<ul> <li>Do not log raw PII (email, phone, exact address).</li> <li>Prefer pseudonymous user IDs.</li> <li>Keep per-tenant boundaries strict.</li> <li>Limit report retention based on policy.</li> </ul>"},{"location":"recsys-eval/docs/security_privacy/#data-minimization","title":"Data minimization","text":"<p>Only log what you can justify measuring. If you do not need a field, do not collect it.</p>"},{"location":"recsys-eval/docs/security_privacy/#ope-and-privacy","title":"OPE and privacy","text":"<p>Propensity logging can include per-item scores. Treat them as sensitive. They can leak model behavior and business logic if exposed carelessly.</p>"},{"location":"recsys-eval/docs/style/","title":"Documentation style guide","text":"<p>This documentation is written to be:</p> <ul> <li>human-friendly</li> <li>practical and runnable</li> <li>honest about uncertainty</li> <li>consistent across files</li> </ul>"},{"location":"recsys-eval/docs/style/#voice","title":"Voice","text":"<ul> <li>Use \"you\" and \"we\".</li> <li>Prefer concrete examples over theory.</li> <li>Define terms the first time they appear.</li> <li>Avoid jargon unless it buys precision.</li> </ul>"},{"location":"recsys-eval/docs/style/#structure","title":"Structure","text":"<p>Every doc starts with:</p> <ul> <li>Who this is for</li> <li>What you will get</li> </ul> <p>Every doc contains:</p> <ul> <li>Examples (commands or JSON)</li> <li>Common pitfalls</li> </ul>"},{"location":"recsys-eval/docs/style/#line-width-and-typography","title":"Line width and typography","text":"<ul> <li>Keep lines reasonably short (about 80-100 chars).</li> <li>Use plain ASCII characters in code and examples.</li> </ul>"},{"location":"recsys-eval/docs/style/#terminology","title":"Terminology","text":"<p>Use these consistently:</p> <ul> <li>\"exposure\": what was shown (ranked list)</li> <li>\"outcome\": what the user did after exposure</li> <li>\"assignment\": experiment bucket (control vs candidate)</li> <li>\"segment\": a slice like tenant+surface+device</li> <li>\"guardrail\": a metric that must not regress</li> </ul> <p>Generated: 2026-01-27</p>"},{"location":"recsys-eval/docs/troubleshooting/","title":"Troubleshooting: symptom -&gt; cause -&gt; fix","text":""},{"location":"recsys-eval/docs/troubleshooting/#who-this-is-for","title":"Who this is for","text":"<p>Anyone stuck. Use this as a quick lookup.</p>"},{"location":"recsys-eval/docs/troubleshooting/#report-is-empty-or-missing-sections","title":"Report is empty or missing sections","text":"<p>Cause:</p> <ul> <li>wrong mode</li> <li>output path permission issue</li> </ul> <p>Fix:</p> <ul> <li>verify --mode and config</li> <li>write to a writable path</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#unknown-schema-in-validate","title":"\"unknown schema\" in validate","text":"<p>Cause:</p> <ul> <li>wrong schema name</li> </ul> <p>Fix:</p> <ul> <li>use exposure.v1, outcome.v1, assignment.v1</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#metrics-are-all-zero","title":"Metrics are all zero","text":"<p>Cause:</p> <ul> <li>outcomes not joined to exposures</li> <li>event types not matching expectations</li> </ul> <p>Fix:</p> <ul> <li>check request_id alignment</li> <li>inspect a few joined records</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#everything-looks-like-a-win","title":"Everything looks like a win","text":"<p>Cause:</p> <ul> <li>you compared the same dataset against itself</li> <li>you sliced too much and found random wins</li> </ul> <p>Fix:</p> <ul> <li>run AA-check or use a known baseline</li> <li>reduce slices and focus on primary metrics</li> </ul>"},{"location":"recsys-eval/docs/troubleshooting/#interleaving-says-a-wins-but-ab-says-b-wins","title":"Interleaving says A wins but A/B says B wins","text":"<p>Cause:</p> <ul> <li>interleaving measures relative ranker preference on the same traffic</li> <li>A/B includes broader effects and guardrails</li> </ul> <p>Fix:</p> <ul> <li>use interleaving to choose between rankers</li> <li>use A/B to decide shipping</li> </ul>"},{"location":"recsys-pipelines/overview/","title":"recsys-pipelines","text":"<p>Filesystem-first pipelines that build versioned recommendation artifacts from raw exposure events.</p> <p>This repository is the offline factory of a recommender stack:</p> <ul> <li>It ingests raw exposure events (JSONL, Postgres, or S3 batch).</li> <li>It canonicalizes them into a deterministic, replayable dataset.</li> <li>It computes artifacts (v1: popularity, co-occurrence, implicit, content_sim, session_seq).</li> <li>It validates outputs and enforces hard resource limits.</li> <li>It publishes artifacts to a versioned object store and updates a</li> </ul> <p>single \"current\" manifest pointer.</p> <p>If you are new: start at <code>docs/start-here.md</code>.</p>"},{"location":"recsys-pipelines/overview/#quickstart","title":"Quickstart","text":"<p>Requirements:</p> <ul> <li>Go toolchain (see <code>go.mod</code>)</li> </ul> <p>Run the pipeline locally against the tiny sample dataset:</p> <pre><code>make test\nmake build\n\n./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-01\n</code></pre> <p>Outputs (default <code>.out/</code>):</p> <ul> <li>Canonical events: <code>.out/canonical/&lt;tenant&gt;/&lt;surface&gt;/exposures/YYYY-MM-DD.jsonl</code></li> <li>Staged artifacts: <code>.out/artifacts/&lt;tenant&gt;/&lt;surface&gt;/&lt;segment&gt;/&lt;type&gt;/&lt;window&gt;/...</code></li> <li>Published blobs: <code>.out/objectstore/&lt;tenant&gt;/&lt;surface&gt;/&lt;type&gt;/&lt;version&gt;.json</code></li> <li>Current manifest: <code>.out/registry/current/&lt;tenant&gt;/&lt;surface&gt;/manifest.json</code></li> </ul> <p>Run the smoke test (includes an idempotency check):</p> <pre><code>make smoke\n</code></pre>"},{"location":"recsys-pipelines/overview/#documentation","title":"Documentation","text":"<p>Docs are organized using the Diataxis approach (tutorials, how-to guides, explanations, and reference). See <code>docs/index.md</code> for the entry point.</p> <ul> <li>Start here: <code>docs/start-here.md</code></li> <li>Tutorials: <code>docs/tutorials/</code></li> <li>How-to: <code>docs/how-to/</code></li> <li>Explanations: <code>docs/explanation/</code></li> <li>Reference: <code>docs/reference/</code></li> <li>Operations: <code>docs/operations/</code></li> </ul>"},{"location":"recsys-pipelines/overview/#binaries","title":"Binaries","text":"<ul> <li><code>recsys-pipelines</code>: one-shot runner (local/dev, or simple cron)</li> <li><code>job_ingest</code>: ingest + canonicalize (job-per-container style)</li> <li><code>job_popularity</code>: compute + stage popularity artifact</li> <li><code>job_cooc</code>: compute + stage co-occurrence artifact</li> <li><code>job_implicit</code>: compute + stage implicit (collaborative) artifact</li> <li><code>job_content_sim</code>: compute + stage content similarity artifact</li> <li><code>job_session_seq</code>: compute + stage session sequence artifact</li> <li><code>job_validate</code>: validate canonical event quality for a window range</li> <li><code>job_publish</code>: publish staged artifacts + swap the current manifest</li> <li><code>job_db_signals</code>: write popularity + co-vis signals into Postgres</li> <li><code>job_catalog</code>: ingest item tags into Postgres</li> </ul> <p>See: <code>docs/tutorials/job-mode.md</code>.</p>"},{"location":"recsys-pipelines/overview/#contributing","title":"Contributing","text":"<p>See <code>docs/contributing/dev-workflow.md</code>.</p>"},{"location":"recsys-pipelines/overview/#releases","title":"Releases","text":"<p>Tag releases with the module prefix, e.g. <code>recsys-pipelines/v0.2.0</code>.</p>"},{"location":"recsys-pipelines/docs/","title":"Index","text":"<p>Welcome! This documentation explains what this system is, who it is for, and how to run and operate it.</p> <p>This repo builds versioned recommendation artifacts (currently popularity and co-occurrence) from raw exposure events.</p>"},{"location":"recsys-pipelines/docs/#start-here","title":"Start here","text":"<ul> <li>If you are new: Start Here: <code>start-here.md</code></li> <li>If you want to run it now: <code>tutorials/local-quickstart.md</code></li> </ul>"},{"location":"recsys-pipelines/docs/#choose-your-path","title":"Choose your path","text":"<ul> <li>Product / PM: <code>learning-paths/product.md</code></li> <li>Engineers: <code>learning-paths/engineer.md</code></li> <li>Data Engineering / Analytics: <code>learning-paths/data-engineer.md</code></li> <li>SRE / Platform: <code>learning-paths/sre-oncall.md</code></li> </ul>"},{"location":"recsys-pipelines/docs/#docs-map-diataxis","title":"Docs map (Diataxis)","text":"<ul> <li>Tutorials: learning by doing</li> <li>How-to guides: task-focused recipes</li> <li>Explanation: concepts and reasoning</li> <li>Reference: exact contracts and CLI/config details</li> </ul> <p>See <code>explanation/documentation-approach.md</code>.</p>"},{"location":"recsys-pipelines/docs/glossary/","title":"Glossary","text":"<p>Artifact : A precomputed data product used by the online recommender, such as popularity   lists or item neighbors.</p> <p>Canonical events : Events stored in a normalized format that the rest of the pipeline relies on.</p> <p>Tenant : A logical customer or environment namespace.</p> <p>Surface : A recommendation placement (e.g. \"home\", \"checkout\").</p> <p>Segment : Optional sub-grouping within a surface (e.g. \"new_users\").</p> <p>Window : A time range that a job processes. In v1, windows are daily UTC buckets.</p> <p>Version : A deterministic identifier (SHA-256 hex) of an artifact payload excluding   volatile build metadata.</p> <p>Manifest : A small JSON document that points to the current artifact URIs for a   (tenant, surface).</p> <p>Registry : Storage for artifact records and current manifests.</p> <p>Object store : Storage for artifact blobs. In local mode, this is the filesystem.</p> <p>Idempotent : Safe to run multiple times without changing the result.</p>"},{"location":"recsys-pipelines/docs/start-here/","title":"Start here","text":""},{"location":"recsys-pipelines/docs/start-here/#what-this-system-does-non-technical","title":"What this system does (non-technical)","text":"<p>Think of <code>recsys-pipelines</code> as a factory:</p> <ul> <li>It reads a stream of user activity events (\"people saw item X\")</li> <li>It cleans and stores them in a consistent format (canonical events)</li> <li>It computes simple recommendation building blocks (artifacts)</li> <li>It publishes those artifacts in a versioned and rollbackable way</li> </ul> <p>The output artifacts are meant to be consumed by an online recommender service.</p>"},{"location":"recsys-pipelines/docs/start-here/#what-this-system-does-technical","title":"What this system does (technical)","text":"<p><code>recsys-pipelines</code> builds deterministic, version-addressed artifacts from raw exposure events.</p> <p>Current v1 artifact types:</p> <ul> <li>popularity: top-N items by exposure count</li> <li>cooc: item-item co-occurrence neighbors within a session</li> <li>implicit: user\u2192item scores from implicit feedback</li> <li>content_sim: item tags for content-based similarity</li> <li>session_seq: user\u2192next-item sequence signals</li> </ul> <p>Key production properties:</p> <ul> <li>Idempotent canonicalization: reruns for the same day window do not</li> </ul> <p>duplicate events.</p> <ul> <li>Atomic writes: artifacts and pointers are written using temp+rename.</li> <li>Validation gates: publishing is blocked if validation fails.</li> <li>Guardrails: configurable limits prevent resource blowups.</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#who-uses-it","title":"Who uses it","text":"<p>This repo is designed to be useful for:</p> <ul> <li>Product / PM: understand artifacts, freshness, rollback</li> <li>Engineers: run locally, add artifact types, integrate storage</li> <li>Data Engineering: define event contracts, backfills, data quality</li> <li>SRE / Platform: operate daily runs, alert on freshness, handle incidents</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#how-it-fits-in-a-recommendation-stack","title":"How it fits in a recommendation stack","text":"<p>Typical stack (simplified):</p> <ul> <li><code>recsys-pipelines</code> (this repo): offline artifact builder</li> <li><code>recsys-algo</code>: ranking / scoring logic that consumes artifacts</li> <li><code>recsys-service</code>: online API that serves recommendations using the algo</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#mental-model-one-screen","title":"Mental model (one-screen)","text":"<p>Raw events (jsonl)    |    v Ingest + canonicalize (idempotent)    |    v Validate canonical data (gates)    |    v Compute artifacts (popularity, cooc, implicit, content_sim, session_seq)    |    v Stage artifacts (optional)    |    v Publish (atomic):</p> <ul> <li>write versioned blob</li> <li>write registry record</li> <li>update current manifest pointer</li> </ul>"},{"location":"recsys-pipelines/docs/start-here/#what-you-should-do-next","title":"What you should do next","text":"<ul> <li>Run locally: <code>tutorials/local-quickstart.md</code></li> <li>Understand artifacts: <code>explanation/artifacts-and-versioning.md</code></li> <li>Learn operations: <code>operations/slos-and-freshness.md</code></li> </ul> <p>If you are here because something broke, jump to:</p> <ul> <li><code>operations/runbooks/</code></li> </ul>"},{"location":"recsys-pipelines/docs/adr/","title":"Architecture Decision Records (ADR)","text":"<p>ADRs capture the \"why\" behind important decisions.</p> <p>Template: <code>adr/template.md</code></p> <p>When to add an ADR:</p> <ul> <li>new artifact type</li> <li>new storage backend (S3/GCS)</li> <li>change in windowing or versioning</li> <li>new validation policy</li> </ul>"},{"location":"recsys-pipelines/docs/adr/template/","title":"ADR-XXXX: <code>title</code>","text":"<p>Date: YYYY-MM-DD</p>"},{"location":"recsys-pipelines/docs/adr/template/#status","title":"Status","text":"<p>Proposed | Accepted | Deprecated | Superseded</p>"},{"location":"recsys-pipelines/docs/adr/template/#context","title":"Context","text":"<p>What problem are we solving?</p>"},{"location":"recsys-pipelines/docs/adr/template/#decision","title":"Decision","text":"<p>What did we decide?</p>"},{"location":"recsys-pipelines/docs/adr/template/#consequences","title":"Consequences","text":"<ul> <li>Positive</li> <li>Negative</li> <li>Neutral</li> </ul>"},{"location":"recsys-pipelines/docs/adr/template/#alternatives-considered","title":"Alternatives considered","text":"<p>List alternatives and why they were rejected.</p>"},{"location":"recsys-pipelines/docs/contributing/dev-workflow/","title":"Developer workflow","text":""},{"location":"recsys-pipelines/docs/contributing/dev-workflow/#local-commands","title":"Local commands","text":"<pre><code>make fmt\nmake test\nmake build\nmake smoke\n</code></pre>"},{"location":"recsys-pipelines/docs/contributing/dev-workflow/#code-structure-rules","title":"Code structure rules","text":"<ul> <li>Keep domain logic deterministic (no IO)</li> <li>Keep adapters behind ports</li> <li>Add unit tests for domain and usecases</li> </ul>"},{"location":"recsys-pipelines/docs/contributing/dev-workflow/#adding-docs","title":"Adding docs","text":"<p>Docs live under <code>docs/</code> and follow Diataxis.</p> <ul> <li>tutorials: <code>docs/tutorials/</code></li> <li>how-to: <code>docs/how-to/</code></li> <li>explanation: <code>docs/explanation/</code></li> <li>reference: <code>docs/reference/</code></li> </ul>"},{"location":"recsys-pipelines/docs/contributing/releasing/","title":"Releasing","text":"<p>This repo includes a <code>CHANGELOG.md</code> and uses tags for releases.</p> <p>Recommended practice:</p> <ul> <li>Keep a human-written changelog entry per release</li> <li>Use SemVer for tags</li> </ul> <p>Local build:</p> <pre><code>make build\n</code></pre>"},{"location":"recsys-pipelines/docs/contributing/style/","title":"Style guide","text":"<ul> <li>Keep comments ASCII.</li> <li>Prefer small focused packages.</li> <li>Avoid cleverness; optimize for readability.</li> <li>Keep public APIs minimal.</li> </ul> <p>Documentation:</p> <ul> <li>Prefer short sections.</li> <li>Use concrete examples.</li> <li>Explain the \"why\" in explanation docs.</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/architecture/","title":"Architecture","text":""},{"location":"recsys-pipelines/docs/explanation/architecture/#code-organization","title":"Code organization","text":"<ul> <li><code>internal/domain</code>: pure, deterministic domain logic</li> <li><code>internal/app/usecase</code>: orchestration of domain logic through ports</li> <li><code>internal/ports</code>: interfaces the app depends on</li> <li><code>internal/adapters</code>: IO implementations (filesystem, logging, etc.)</li> <li><code>cmd/*</code>: binaries (all-in-one CLI and job-per-step)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/architecture/#system-interactions-c4-inspired-ascii","title":"System interactions (C4-inspired, ASCII)","text":"<p>Level 1: context</p> <p>+---------------------+           +------------------+ |  Offline scheduler  |  runs     | recsys-pipelines | | (cron/airflow/k8s)  +----------&gt;+ (this repo)      | +---------------------+           +---------+--------+                                             |                                             | publishes                                             v                                     +-------+--------+                                     | Artifact store  |                                     | + Registry      |                                     +-------+--------+                                             |                                             | consumed by                                             v                                     +-------+--------+                                     | Online service  |                                     | (recsys-service)|                                     +-----------------+</p> <p>Level 2: containers within this repo</p> <ul> <li>CLI and jobs in <code>cmd/*</code></li> <li>Filesystem adapters</li> <li>Usecases (ingest/validate/compute/publish)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/architecture/#why-portsadapters","title":"Why ports/adapters","text":"<ul> <li>Keeps domain logic deterministic and testable</li> <li>Makes storage pluggable (filesystem now, S3/GCS later)</li> <li>Makes validation pluggable (builtin now, GE/dbt later)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/","title":"Artifacts and versioning","text":""},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#what-is-an-artifact","title":"What is an artifact?","text":"<p>A file (JSON) that the online recommender uses to make decisions quickly. Artifacts are precomputed offline so serving stays fast.</p>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#versioning","title":"Versioning","text":"<p>Artifacts are version-addressed:</p> <ul> <li>Compute the payload</li> <li>Remove volatile build metadata</li> <li>Hash the remaining JSON (SHA-256 hex)</li> <li>Embed the version into the final artifact</li> </ul> <p>If the canonical input does not change, the version should not change.</p>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#publishing-protocol-two-phase","title":"Publishing protocol (two-phase)","text":"<p>Publishing is ordered to keep serving safe:</p> <p>1) Write the versioned blob 1) Validate the artifact (including version recompute) 1) Write the version record 1) Swap the manifest pointer last</p> <p>This means a failed publish does not break \"current\".</p>"},{"location":"recsys-pipelines/docs/explanation/artifacts-and-versioning/#rollback","title":"Rollback","text":"<p>Rollback is changing the manifest pointer to an older URI. The older versioned blob remains available.</p> <p>See <code>how-to/rollback-manifest.md</code>.</p>"},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/","title":"Data lifecycle","text":""},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/#stages","title":"Stages","text":"<ol> <li> <p>Raw events</p> </li> <li> <p>Input is JSON Lines files (jsonl)</p> </li> <li> <p>Schema: <code>schemas/events/exposure.v1.json</code></p> </li> <li> <p>Canonical events</p> </li> <li> <p>Stored per day (UTC) per tenant/surface</p> </li> <li> <p>Written idempotently (replace per partition)</p> </li> <li> <p>Validation</p> </li> <li> <p>Canonical is validated before any artifacts are computed/published</p> </li> <li> <p>Artifact compute</p> </li> <li> <p>popularity: counts by item</p> </li> <li> <p>cooc: session-level co-occurrence</p> </li> <li> <p>Staging (optional)</p> </li> <li> <p>Compute jobs can stage artifacts to <code>artifacts_dir</code></p> </li> <li> <p>Publish</p> </li> <li> <p>Versioned blob written to object store</p> </li> <li>Registry record written</li> <li>Current manifest pointer updated last</li> </ol>"},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/#why-canonicalization-exists","title":"Why canonicalization exists","text":"<ul> <li>Raw data is messy (missing fields, inconsistent formatting)</li> <li>Canonical events define a stable boundary</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/data-lifecycle/#why-validation-gates-exist","title":"Why validation gates exist","text":"<p>If you publish a bad artifact, you can degrade user experience immediately. Validation prevents \"bad data\" from reaching serving.</p>"},{"location":"recsys-pipelines/docs/explanation/documentation-approach/","title":"Documentation approach (Diataxis)","text":"<p>This documentation is organized around four different user needs:</p> <ul> <li>Tutorials: learn by doing</li> <li>How-to guides: solve a specific task</li> <li>Explanation: understand concepts and tradeoffs</li> <li>Reference: exact details</li> </ul> <p>This structure is based on the Diataxis documentation framework.</p>"},{"location":"recsys-pipelines/docs/explanation/validation-and-guardrails/","title":"Validation and guardrails","text":""},{"location":"recsys-pipelines/docs/explanation/validation-and-guardrails/#validation-gate","title":"Validation gate","text":"<p>The pipeline validates canonical data before computing/publishing.</p> <p>Builtin checks include:</p> <ul> <li>event parsing and required fields</li> <li>timestamp inside the window</li> <li>maximum events processed</li> <li>maximum distinct sessions/items</li> </ul> <p>Artifacts are also validated:</p> <ul> <li>correct type/version/window</li> <li>version matches recomputed hash</li> <li>maximum sizes (items/neighbors)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/validation-and-guardrails/#guardrails","title":"Guardrails","text":"<p>Resource limits protect the pipeline from unbounded inputs:</p> <ul> <li>max events per run</li> <li>max sessions per run</li> <li>max items per session</li> <li>max distinct items per run</li> <li>max neighbors per item</li> <li>max items per artifact</li> </ul> <p>If you see \"limit exceeded\", raise limits only after understanding why.</p> <p>Operational guidance: <code>operations/runbooks/limit-exceeded.md</code>.</p>"},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/","title":"Windows and backfills","text":""},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/#window-semantics","title":"Window semantics","text":"<p>This repo uses daily windows in UTC:</p> <ul> <li>A day window is [00:00, 24:00) UTC</li> <li>Backfills iterate start..end (inclusive end date)</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/#why-daily-windows","title":"Why daily windows","text":"<ul> <li>Easy operational model</li> <li>Simple freshness SLOs</li> <li>Deterministic partitioning</li> </ul>"},{"location":"recsys-pipelines/docs/explanation/windows-and-backfills/#backfill-safety","title":"Backfill safety","text":"<p>Backfills should be safe because:</p> <ul> <li>canonical partitions are replaced idempotently</li> <li>publishing updates the pointer last</li> </ul> <p>Still, you should backfill gradually and watch limits.</p> <p>See <code>how-to/run-backfill.md</code>.</p>"},{"location":"recsys-pipelines/docs/how-to/add-artifact-type/","title":"How-to: Add a new artifact type","text":"<p>This repo uses ports/adapters and a workflow pipeline.</p>"},{"location":"recsys-pipelines/docs/how-to/add-artifact-type/#checklist","title":"Checklist","text":"<ol> <li> <p>Define the domain model</p> </li> <li> <p>Add a new <code>artifacts.Type</code> value</p> </li> <li> <p>Add a v1 model struct and constructor</p> </li> <li> <p>Implement a compute usecase</p> </li> <li> <p>IO via <code>datasource.CanonicalStore</code></p> </li> <li> <p>Deterministic version hash (exclude build info)</p> </li> <li> <p>Update validation</p> </li> <li> <p>Extend builtin validator: schema checks + version recompute</p> </li> <li> <p>Wire into workflow</p> </li> <li> <p>Add to <code>workflow.Pipeline.RunDay</code></p> </li> <li> <p>Add to job mode (compute job + publish job)</p> </li> <li> <p>Add reference docs</p> </li> <li> <p>Add schema under <code>schemas/artifacts/</code></p> </li> <li>Update <code>reference/output-layout.md</code></li> </ol>"},{"location":"recsys-pipelines/docs/how-to/add-artifact-type/#non-negotiables","title":"Non-negotiables","text":"<ul> <li>Deterministic output for same canonical inputs</li> <li>Bounded resource usage</li> <li>Publish pointer updated last</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/add-event-field/","title":"How-to: Add a new field to exposure events","text":""},{"location":"recsys-pipelines/docs/how-to/add-event-field/#rules","title":"Rules","text":"<ul> <li>Keep old readers working (backwards compatible)</li> <li>Do not reuse field meanings</li> <li>Update schema and examples</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/add-event-field/#steps","title":"Steps","text":"<p>1) Update JSON schema: <code>schemas/events/exposure.v1.json</code> 1) Update domain event struct: <code>internal/domain/events/exposure.go</code> 1) Update raw event decoder if needed 1) Update canonical writer/reader tests 1) Update docs: <code>reference/schemas-events.md</code></p>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/","title":"How-to: Debug a failed pipeline run","text":""},{"location":"recsys-pipelines/docs/how-to/debug-failures/#1-identify-the-step","title":"1) Identify the step","text":"<p>Look at logs for one of:</p> <ul> <li>ingest</li> <li>validate</li> <li>popularity</li> <li>cooc</li> <li>publish</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/#2-common-root-causes","title":"2) Common root causes","text":"<ul> <li>Input files missing or wrong path</li> <li>Bad JSON in raw event files</li> <li>Validation fails (out-of-window timestamps, too many events)</li> <li>Resource limit exceeded (sessions/items)</li> <li>Disk permission errors</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/#3-useful-commands","title":"3) Useful commands","text":"<pre><code># Re-run one day\n./bin/recsys-pipelines run --config configs/env/local.json --tenant demo \\\n  --surface home --start 2026-01-01 --end 2026-01-01\n\n# Check manifest\ncat .out/registry/current/demo/home/manifest.json\n\n# Inspect canonical files\nfind .out/canonical -type f | sort\n</code></pre>"},{"location":"recsys-pipelines/docs/how-to/debug-failures/#4-if-publish-failed","title":"4) If publish failed","text":"<p>Publishing is ordered so that the manifest pointer updates last. This means serving should still point to the previous version.</p> <p>See <code>operations/runbooks/pipeline-failed.md</code>.</p>"},{"location":"recsys-pipelines/docs/how-to/rollback-manifest/","title":"How-to: Roll back to a previous artifact version","text":"<p>This repo intentionally separates:</p> <ul> <li>versioned blobs (immutable)</li> <li>a small manifest pointer (mutable)</li> </ul> <p>Rollback is therefore a pointer change.</p>"},{"location":"recsys-pipelines/docs/how-to/rollback-manifest/#local-filesystem-example","title":"Local filesystem example","text":"<p>1) Find previous versions:</p> <pre><code>ls -1 .out/registry/records/demo/home/popularity | head\nls -1 .out/registry/records/demo/home/cooc | head\n</code></pre> <p>1) Pick a version record and get its <code>URI</code>.</p> <p>1) Edit the manifest file:</p> <p><code>.out/registry/current/demo/home/manifest.json</code></p> <p>Change <code>current.popularity</code> and/or <code>current.cooc</code> to point to the older URIs.</p>"},{"location":"recsys-pipelines/docs/how-to/rollback-manifest/#production-guidance","title":"Production guidance","text":"<p>In production, implement a dedicated rollback command in your operator tooling that:</p> <ul> <li>validates the target blob exists</li> <li>writes an audit record</li> <li>swaps the pointer atomically</li> </ul> <p>See <code>explanation/artifacts-and-versioning.md</code>.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/","title":"How-to: Run a backfill safely","text":"<p>Backfills re-run the pipeline for a date range. This repo uses daily UTC windows and includes a maximum range limit.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#safe-approach","title":"Safe approach","text":"<p>1) Start small: one day. 1) Expand gradually. 1) Monitor validation and resource limits.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#using-the-all-in-one-cli","title":"Using the all-in-one CLI","text":"<pre><code>./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-07\n</code></pre>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#using-job-mode","title":"Using job mode","text":"<p>Run jobs for the same date range and publish last.</p>"},{"location":"recsys-pipelines/docs/how-to/run-backfill/#notes","title":"Notes","text":"<ul> <li>End date is inclusive.</li> <li>Canonicalization is idempotent per day partition.</li> <li>Publishing updates the manifest pointer last.</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/run-incremental/","title":"How-to: Run incremental pipelines","text":"<p>Incremental runs use a checkpoint so you can process only new days.</p>"},{"location":"recsys-pipelines/docs/how-to/run-incremental/#prerequisites","title":"Prerequisites","text":"<ul> <li><code>checkpoint_dir</code> configured (defaults to <code>.out/checkpoints</code>)</li> <li><code>raw_source</code> configured</li> </ul>"},{"location":"recsys-pipelines/docs/how-to/run-incremental/#run","title":"Run","text":"<pre><code>recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --end 2026-02-01 \\\n  --incremental\n</code></pre> <p>First run: pass <code>--start</code> once to seed the checkpoint:</p> <pre><code>recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-07 \\\n  --incremental\n</code></pre> <p>After each successful day, the checkpoint is updated automatically.</p>"},{"location":"recsys-pipelines/docs/how-to/schedule-pipelines/","title":"How-to: Schedule pipelines with CronJob","text":"<p>This project ships CLI jobs; schedule them with Kubernetes CronJobs or system cron.</p>"},{"location":"recsys-pipelines/docs/how-to/schedule-pipelines/#example-kubernetes-cronjob","title":"Example Kubernetes CronJob","text":"<pre><code>apiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: recsys-pipelines-nightly\nspec:\n  schedule: \"0 2 * * *\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: recsys-pipelines\n              image: ghcr.io/aatuh/recsys-pipelines:latest\n              args:\n                - \"run\"\n                - \"--config\"\n                - \"/etc/recsys/config.json\"\n                - \"--tenant\"\n                - \"demo\"\n                - \"--surface\"\n                - \"home\"\n                - \"--end\"\n                - \"2026-02-01\"\n                - \"--incremental\"\n              volumeMounts:\n                - name: recsys-config\n                  mountPath: /etc/recsys\n          restartPolicy: OnFailure\n          volumes:\n            - name: recsys-config\n              configMap:\n                name: recsys-pipelines-config\n</code></pre> <p>Use <code>--incremental</code> for daily runs and <code>--start/--end</code> for backfills.</p>"},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/","title":"Learning path: Data Engineering","text":""},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/#goals","title":"Goals","text":"<ul> <li>Understand event schemas and file layouts</li> <li>Run backfills safely</li> <li>Operate data quality gates</li> <li>Define evolution rules for new fields</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>reference/schemas-events.md</code> 1) <code>explanation/data-lifecycle.md</code> 1) <code>how-to/run-backfill.md</code> 1) <code>how-to/add-event-field.md</code> 1) <code>reference/output-layout.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/data-engineer/#key-practical-advice","title":"Key practical advice","text":"<ul> <li>Treat canonical events as the contract boundary.</li> <li>Keep schema evolution backwards compatible.</li> <li>Always validate before publishing.</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/engineer/","title":"Learning path: Engineers","text":""},{"location":"recsys-pipelines/docs/learning-paths/engineer/#goals","title":"Goals","text":"<ul> <li>Run the pipeline locally</li> <li>Understand code structure (ports/adapters/usecases)</li> <li>Add a new artifact type safely</li> <li>Debug failures</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/engineer/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>tutorials/local-quickstart.md</code> 1) <code>reference/cli.md</code> 1) <code>reference/config.md</code> 1) <code>explanation/architecture.md</code> 1) <code>how-to/add-artifact-type.md</code> 1) <code>contributing/dev-workflow.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/engineer/#golden-rules","title":"Golden rules","text":"<ul> <li>Domain must stay IO-free and deterministic.</li> <li>Publishing must be atomic.</li> <li>Every step must be safe to retry.</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/product/","title":"Learning path: Product / PM","text":""},{"location":"recsys-pipelines/docs/learning-paths/product/#what-you-care-about","title":"What you care about","text":"<ul> <li>What artifacts exist and what they mean</li> <li>How freshness works (daily windows)</li> <li>How to roll back if something goes wrong</li> <li>What \"data quality\" means in practice</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/product/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>start-here.md</code> 1) <code>explanation/artifacts-and-versioning.md</code> 1) <code>operations/slos-and-freshness.md</code> 1) <code>operations/runbooks/pipeline-failed.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/product/#key-concepts","title":"Key concepts","text":"<ul> <li>Artifacts are versioned and rollbackable because production needs safe</li> </ul> <p>recovery.</p> <ul> <li>Manifest pointers are updated last so serving never points to missing blobs.</li> <li>Validation gates exist to prevent bad artifacts from reaching users.</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/product/#practical-questions-and-where-answered","title":"Practical questions (and where answered)","text":"<ul> <li>\"How often do recommendations update?\"</li> <li><code>operations/slos-and-freshness.md</code></li> <li>\"Can we revert to yesterday's artifact?\"</li> <li><code>how-to/rollback-manifest.md</code></li> <li>\"What if data is missing for a day?\"</li> <li><code>explanation/data-lifecycle.md</code></li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/","title":"Learning path: SRE / On-call","text":""},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/#goals","title":"Goals","text":"<ul> <li>Know what \"healthy\" looks like</li> <li>Detect stale artifacts</li> <li>Triage failures quickly</li> <li>Roll back safely</li> </ul>"},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/#read-in-this-order","title":"Read in this order","text":"<p>1) <code>operations/slos-and-freshness.md</code> 1) <code>operations/runbooks/pipeline-failed.md</code> 1) <code>operations/runbooks/stale-artifacts.md</code> 1) <code>operations/runbooks/limit-exceeded.md</code> 1) <code>how-to/rollback-manifest.md</code></p>"},{"location":"recsys-pipelines/docs/learning-paths/sre-oncall/#what-to-alert-on","title":"What to alert on","text":"<ul> <li>No successful publish within expected window (freshness)</li> <li>Validation failures</li> <li>Limit exceeded errors (resource protection)</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/","title":"SLOs and freshness","text":""},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#freshness-definition","title":"Freshness definition","text":"<p>A surface is \"fresh\" if the manifest for (tenant, surface) was updated within an expected time window.</p> <p>Example daily schedule:</p> <ul> <li>Run for previous UTC day at 01:00 UTC</li> <li>Expect publish to finish by 01:30 UTC</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#what-to-measure","title":"What to measure","text":"<p>At minimum:</p> <ul> <li>last successful publish timestamp per tenant/surface</li> <li>validation failures count</li> <li>limit exceeded failures count</li> <li>runtime per job</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#alert-suggestions","title":"Alert suggestions","text":"<ul> <li>Stale manifest: no update within 2x schedule interval</li> <li>Persistent validation failures</li> <li>Persistent limit exceeded</li> </ul>"},{"location":"recsys-pipelines/docs/operations/slos-and-freshness/#where-to-find-the-signal-in-local-mode","title":"Where to find the signal in local mode","text":"<ul> <li>Manifest <code>updated_at</code>:</li> </ul> <p><code>.out/registry/current/&lt;tenant&gt;/&lt;surface&gt;/manifest.json</code></p>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/","title":"Runbook: Limit exceeded","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#symptoms","title":"Symptoms","text":"<ul> <li>Error message includes \"limit exceeded\"</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#why-this-exists","title":"Why this exists","text":"<p>Limits prevent resource blowups from pathological inputs. Raising limits blindly can cause OOM or slowdowns.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#triage","title":"Triage","text":"<p>1) Identify which limit triggered (events/sessions/items/neighbors) 1) Inspect raw event volume for the window 1) Look for data bugs (duplicate events, runaway session ids)</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/limit-exceeded/#recovery","title":"Recovery","text":"<ul> <li>Fix upstream data if it's a bug</li> <li>For genuine growth, raise limits gradually and benchmark</li> </ul> <p>See <code>reference/config.md</code> and <code>explanation/validation-and-guardrails.md</code>.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/","title":"Runbook: Pipeline failed","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#symptoms","title":"Symptoms","text":"<ul> <li><code>recsys-pipelines run</code> exits non-zero</li> <li>job binary exits non-zero</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#immediate-safety-check","title":"Immediate safety check","text":"<p>Publishing updates the manifest pointer last. If publish failed mid-run, serving should still point to the previous version.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#triage-checklist","title":"Triage checklist","text":"<p>1) Identify which step failed (logs): ingest / validate / compute / publish 1) Check disk paths and permissions 1) Check raw input presence and format 1) If validation failed, inspect the reported rule 1) If limit exceeded, see <code>runbooks/limit-exceeded.md</code></p>"},{"location":"recsys-pipelines/docs/operations/runbooks/pipeline-failed/#recovery","title":"Recovery","text":"<ul> <li>Fix root cause</li> <li>Re-run the affected day only</li> <li>If publish already updated to a bad version, roll back the manifest</li> </ul> <p>See <code>how-to/rollback-manifest.md</code>.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/","title":"Runbook: Stale artifacts","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/#symptoms","title":"Symptoms","text":"<ul> <li>Manifest <code>updated_at</code> is older than expected</li> <li>Serving still uses old URIs</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/#triage","title":"Triage","text":"<p>1) Confirm scheduler ran 1) Confirm pipeline completed successfully 1) Check for validation failures or limit exceeded</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/stale-artifacts/#recovery","title":"Recovery","text":"<ul> <li>Re-run the missing day</li> <li>If inputs are missing, decide whether to publish empty artifacts or skip</li> </ul> <p>See <code>how-to/run-backfill.md</code>.</p>"},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/","title":"Runbook: Validation failed","text":""},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/#symptoms","title":"Symptoms","text":"<ul> <li>Pipeline stops before publish</li> <li>Error indicates validation failure</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/#common-causes","title":"Common causes","text":"<ul> <li>Events outside the window (timestamp issues)</li> <li>Bad JSON / schema mismatch</li> <li>Unexpected spike/drop in event volume</li> </ul>"},{"location":"recsys-pipelines/docs/operations/runbooks/validation-failed/#recovery","title":"Recovery","text":"<ul> <li>Fix data at source if possible</li> <li>Re-run the affected day</li> <li>If needed, roll back serving to previous artifacts</li> </ul> <p>See <code>explanation/data-lifecycle.md</code>.</p>"},{"location":"recsys-pipelines/docs/reference/cli/","title":"CLI reference","text":""},{"location":"recsys-pipelines/docs/reference/cli/#recsys-pipelines","title":"recsys-pipelines","text":"<p>Commands:</p> <ul> <li><code>run</code> : ingest + validate + compute + publish</li> <li><code>version</code></li> </ul>"},{"location":"recsys-pipelines/docs/reference/cli/#run","title":"run","text":"<pre><code>recsys-pipelines run \\\n  --config &lt;path&gt; \\\n  --tenant &lt;tenant&gt; \\\n  --surface &lt;surface&gt; \\\n  --segment &lt;segment optional&gt; \\\n  --start YYYY-MM-DD \\\n  --end YYYY-MM-DD\n</code></pre> <p>Notes:</p> <ul> <li>end date is inclusive</li> <li>windows are daily UTC</li> </ul> <p>Incremental (checkpointed) example:</p> <pre><code>recsys-pipelines run \\\n  --config &lt;path&gt; \\\n  --tenant &lt;tenant&gt; \\\n  --surface &lt;surface&gt; \\\n  --end YYYY-MM-DD \\\n  --incremental\n</code></pre>"},{"location":"recsys-pipelines/docs/reference/cli/#job-binaries","title":"Job binaries","text":"<p>All jobs take <code>--config --tenant --surface --start --end</code>. Some also take <code>--segment</code> or extra inputs.</p> <ul> <li><code>job_ingest</code></li> <li><code>job_validate</code></li> <li><code>job_popularity</code> (segment optional)</li> <li><code>job_cooc</code> (segment optional)</li> <li><code>job_implicit</code> (segment optional)</li> <li><code>job_content_sim</code> (segment optional, requires <code>--input</code>)</li> <li><code>job_session_seq</code> (segment optional)</li> <li><code>job_publish</code> (segment optional)</li> </ul> <p><code>job_content_sim</code> usage:</p> <pre><code>job_content_sim \\\n  --config &lt;path&gt; \\\n  --tenant &lt;tenant&gt; \\\n  --surface &lt;surface&gt; \\\n  --input &lt;catalog.csv|catalog.jsonl&gt; \\\n  --start YYYY-MM-DD \\\n  --end YYYY-MM-DD\n</code></pre>"},{"location":"recsys-pipelines/docs/reference/config/","title":"Config reference","text":"<p>Config is JSON. Example: <code>configs/env/local.json</code>.</p> <p>Top-level fields:</p> <ul> <li><code>out_dir</code>: base output directory (local runs)</li> <li><code>raw_events_dir</code>: input events directory</li> <li><code>canonical_dir</code>: canonical output directory</li> <li><code>checkpoint_dir</code>: checkpoint storage for incremental runs</li> <li><code>raw_source</code>: raw ingestion source configuration</li> <li><code>artifacts_dir</code>: staging directory (job mode and pipeline staging)</li> <li><code>object_store_dir</code>: where published blobs are written (local fs mode)</li> <li><code>object_store</code>: object store configuration (fs or s3/minio)</li> <li><code>registry_dir</code>: where manifests and records are written</li> <li><code>db</code>: optional Postgres connection for DB-backed signals</li> </ul>"},{"location":"recsys-pipelines/docs/reference/config/#object_store","title":"object_store","text":"<pre><code>{\n  \"type\": \"fs | s3 | minio\",\n  \"dir\": \".out/objectstore\",\n  \"s3\": {\n    \"endpoint\": \"localhost:9000\",\n    \"bucket\": \"recsys-artifacts\",\n    \"access_key\": \"minioadmin\",\n    \"secret_key\": \"minioadmin\",\n    \"prefix\": \"recsys\",\n    \"use_ssl\": false\n  }\n}\n```json\n\n## db\n\n```json\n{\n  \"dsn\": \"postgres://user:pass@localhost:5432/db?sslmode=disable\",\n  \"auto_create_tenant\": true,\n  \"statement_timeout_s\": 5\n}\n```json\n\n## limits\n\n- `max_days_backfill`\n- `max_events_per_run`\n- `max_sessions_per_run`\n- `max_items_per_session`\n- `max_distinct_items_per_run`\n- `max_neighbors_per_item`\n- `max_items_per_artifact`\n- `min_cooc_support`\n- `max_users_per_run`\n- `max_items_per_user`\n\nSee `explanation/validation-and-guardrails.md`.\n\n## raw_source\n\n```json\n{\n  \"type\": \"fs | s3 | minio | postgres | kafka\",\n  \"dir\": \"testdata/events\",\n  \"s3\": {\n    \"endpoint\": \"localhost:9000\",\n    \"bucket\": \"recsys-raw\",\n    \"access_key\": \"minioadmin\",\n    \"secret_key\": \"minioadmin\",\n    \"prefix\": \"raw/events\",\n    \"use_ssl\": false\n  },\n  \"postgres\": {\n    \"dsn\": \"postgres://user:pass@localhost:5432/db?sslmode=disable\",\n    \"tenant_table\": \"tenants\",\n    \"exposure_table\": \"exposure_events\"\n  },\n  \"kafka\": {\n    \"brokers\": [\"localhost:9092\"],\n    \"topic\": \"recsys-exposures\",\n    \"group_id\": \"recsys-pipelines\"\n  }\n}\n</code></pre> <p>Note: the Kafka connector is scaffolded and returns a clear error until it is implemented with a streaming consumer.</p>"},{"location":"recsys-pipelines/docs/reference/exit-codes/","title":"Exit codes","text":"<p>This repo uses conventional exit codes:</p> <ul> <li>0: success</li> <li>1: runtime failure (pipeline step failed)</li> <li>2: usage/config error (missing flags, invalid config)</li> </ul> <p>Job binaries follow the same pattern.</p>"},{"location":"recsys-pipelines/docs/reference/output-layout/","title":"Output layout (local filesystem)","text":"<p>With default local config, outputs go under <code>.out/</code>.</p>"},{"location":"recsys-pipelines/docs/reference/output-layout/#canonical","title":"Canonical","text":"<p><code>.out/canonical/&lt;tenant&gt;/&lt;surface&gt;/exposures/YYYY-MM-DD.jsonl</code></p>"},{"location":"recsys-pipelines/docs/reference/output-layout/#staged-artifacts","title":"Staged artifacts","text":"<p><code>.out/artifacts/&lt;tenant&gt;/&lt;surface&gt;/&lt;segment&gt;/&lt;type&gt;/&lt;start&gt;_&lt;end&gt;/</code></p> <ul> <li><code>&lt;version&gt;.json</code></li> <li><code>current.version</code></li> </ul>"},{"location":"recsys-pipelines/docs/reference/output-layout/#object-store","title":"Object store","text":"<p><code>.out/objectstore/&lt;tenant&gt;/&lt;surface&gt;/&lt;kind&gt;/&lt;version&gt;.json</code></p>"},{"location":"recsys-pipelines/docs/reference/output-layout/#registry","title":"Registry","text":"<p>Current manifest:</p> <ul> <li><code>.out/registry/current/&lt;tenant&gt;/&lt;surface&gt;/manifest.json</code></li> </ul> <p>Version records:</p> <ul> <li><code>.out/registry/records/&lt;tenant&gt;/&lt;surface&gt;/&lt;type&gt;/&lt;version&gt;.json</code></li> </ul>"},{"location":"recsys-pipelines/docs/reference/output-layout/#notes","title":"Notes","text":"<ul> <li>Records are append-only and version-addressed.</li> <li>Manifest points to URIs (<code>file://...</code> in local mode).</li> </ul>"},{"location":"recsys-pipelines/docs/reference/schemas-artifacts/","title":"Artifact schemas","text":"<p>Artifacts are JSON documents intended for serving systems.</p> <p>Currently:</p> <ul> <li>Popularity artifact v1</li> <li>Co-occurrence artifact v1</li> <li>Implicit artifact v1 (collaborative)</li> <li>Content similarity artifact v1</li> <li>Session sequence artifact v1</li> <li>Manifest v1</li> </ul> <p>Schemas:</p> <ul> <li><code>schemas/artifacts/manifest.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/popularity.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/cooc.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/implicit.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/content_sim.v1.json</code></li> <li>(recommended) <code>schemas/artifacts/session_seq.v1.json</code></li> </ul> <p>The builtin validator enforces structural rules. See <code>explanation/artifacts-and-versioning.md</code>.</p>"},{"location":"recsys-pipelines/docs/reference/schemas-events/","title":"Event schemas","text":""},{"location":"recsys-pipelines/docs/reference/schemas-events/#exposureeventv1","title":"ExposureEventV1","text":"<p>Schema file:</p> <ul> <li><code>schemas/events/exposure.v1.json</code></li> </ul> <p>Format:</p> <ul> <li>JSON Lines (one JSON object per line)</li> </ul> <p>Required fields:</p> <ul> <li><code>v</code>: must be 1</li> <li><code>ts</code>: RFC3339 timestamp</li> <li><code>tenant</code>: string</li> <li><code>surface</code>: string</li> <li><code>session_id</code>: string</li> <li><code>item_id</code>: string</li> </ul> <p>Optional fields:</p> <ul> <li><code>user_id</code></li> <li><code>request_id</code></li> <li><code>rank</code></li> </ul> <p>See also: <code>testdata/events/</code>.</p>"},{"location":"recsys-pipelines/docs/tutorials/job-mode/","title":"Tutorial: Run in job-per-step mode","text":"<p>Some teams prefer orchestration where each step runs as a separate job (Airflow, K8s CronJobs, etc.). This repo includes job binaries:</p> <ul> <li><code>job_ingest</code></li> <li><code>job_validate</code></li> <li><code>job_popularity</code></li> <li><code>job_cooc</code></li> <li><code>job_publish</code></li> </ul>"},{"location":"recsys-pipelines/docs/tutorials/job-mode/#example-one-day","title":"Example: one day","text":"<pre><code>make build\n\n./bin/job_ingest --config configs/env/local.json --tenant demo --surface home \\\n  --start 2026-01-01 --end 2026-01-01\n\n./bin/job_validate --config configs/env/local.json --tenant demo --surface home \\\n  --start 2026-01-01 --end 2026-01-01\n\n./bin/job_popularity --config configs/env/local.json --tenant demo --surface home \\\n  --segment '' --start 2026-01-01 --end 2026-01-01\n\n./bin/job_cooc --config configs/env/local.json --tenant demo --surface home \\\n  --segment '' --start 2026-01-01 --end 2026-01-01\n\n./bin/job_publish --config configs/env/local.json --tenant demo --surface home \\\n  --segment '' --start 2026-01-01 --end 2026-01-01\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/job-mode/#why-split-jobs","title":"Why split jobs?","text":"<ul> <li>Different compute profiles per step</li> <li>Independent retries</li> <li>Separate scaling policies</li> </ul> <p>Next: <code>operations/slos-and-freshness.md</code>.</p>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/","title":"Tutorial: Run locally (filesystem mode)","text":"<p>This tutorial assumes you want to run the pipeline on the included tiny dataset.</p>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#1-build","title":"1) Build","text":"<pre><code>make test\nmake build\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#2-run-one-day","title":"2) Run one day","text":"<pre><code>./bin/recsys-pipelines run \\\n  --config configs/env/local.json \\\n  --tenant demo \\\n  --surface home \\\n  --start 2026-01-01 \\\n  --end 2026-01-01\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#3-inspect-outputs","title":"3) Inspect outputs","text":"<pre><code>find .out -type f | sort\ncat .out/registry/current/demo/home/manifest.json\n</code></pre> <p>You should see:</p> <ul> <li>canonical events under <code>.out/canonical/demo/home/exposures/</code></li> <li>versioned blobs under <code>.out/objectstore/demo/home/...</code></li> <li>a manifest pointer under <code>.out/registry/current/demo/home/manifest.json</code></li> </ul>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#4-prove-idempotency","title":"4) Prove idempotency","text":"<p>Run the same command again. Output should not change.</p> <p>A smoke script exists:</p> <pre><code>make smoke\n</code></pre>"},{"location":"recsys-pipelines/docs/tutorials/local-quickstart/#what-you-learned","title":"What you learned","text":"<ul> <li>How to build and run the pipeline locally</li> <li>Where the outputs land</li> <li>Why reruns are safe</li> </ul> <p>Next: <code>tutorials/job-mode.md</code> or <code>explanation/artifacts-and-versioning.md</code>.</p>"},{"location":"reference/api/admin/","title":"Admin API + local bootstrap (recsys-service)","text":"<p>This page documents the admin/control-plane endpoints and the minimum bootstrap steps required to call <code>/v1/recommend</code> and <code>/v1/similar</code>.</p> <p>Why this exists:</p> <ul> <li>The OpenAPI file (<code>reference/api/openapi.yaml</code>) documents the HTTP surface.</li> <li>This page adds bootstrap guidance, examples, and operational notes for admin/control-plane usage.</li> </ul>"},{"location":"reference/api/admin/#0-prereqs","title":"0) Prereqs","text":"<ul> <li>Postgres is running and migrations are applied.</li> <li>recsys-service is running and reachable (e.g. <code>http://localhost:8000</code>).</li> </ul>"},{"location":"reference/api/admin/#1-create-a-tenant-row-db-bootstrap","title":"1) Create a tenant row (DB bootstrap)","text":"<p>Admin endpoints require a tenant record in <code>tenants</code>. There is no admin API to create tenants yet, so insert directly in Postgres:</p> <pre><code>insert into tenants (external_id, name)\nvalues ('demo', 'Demo Tenant')\non conflict (external_id) do nothing;\n</code></pre> <p>Notes:</p> <ul> <li><code>external_id</code> should match the tenant/org claim in your JWT, or the dev tenant</li> </ul> <p>header value (see below).</p> <ul> <li>You can also use the tenant UUID in admin paths; <code>external_id</code> is preferred.</li> </ul>"},{"location":"reference/api/admin/#2-auth-tenancy-local-dev","title":"2) Auth + tenancy (local dev)","text":"<p>Local dev can use dev headers instead of JWT:</p> <p>Set in <code>.env</code>:</p> <pre><code>AUTH_REQUIRED=true\nAUTH_REQUIRE_TENANT_CLAIM=false\nDEV_AUTH_ENABLED=true\nDEV_AUTH_USER_ID_HEADER=X-Dev-User-Id\nDEV_AUTH_TENANT_HEADER=X-Dev-Org-Id\nAUTH_ADMIN_ROLE=   # empty to disable admin role checks locally\n</code></pre> <p>Then send headers on every request:</p> <pre><code>X-Dev-User-Id: dev-user-1\nX-Dev-Org-Id: demo\nX-Org-Id: demo   # must match tenant scope\n</code></pre> <p>Why two tenant headers?</p> <ul> <li><code>X-Dev-Org-Id</code> is used to derive tenant context in local/dev mode.</li> <li><code>X-Org-Id</code> is the tenant header enforced by the tenant middleware.</li> </ul> <p>Tip (single header in local dev):</p> <ul> <li>Set <code>DEV_AUTH_TENANT_HEADER=X-Org-Id</code> to use one header for both dev auth</li> </ul> <p>and tenant scope.</p> <p>If you prefer JWT:</p> <ul> <li>Provide a bearer token with a tenant claim (see <code>AUTH_TENANT_CLAIMS</code>).</li> <li>Include an admin role (default <code>admin</code>) under a role claim (see</li> </ul> <p><code>AUTH_ROLE_CLAIMS</code>) to access admin endpoints.</p> <p>RBAC roles (JWT or API keys):</p> <ul> <li><code>viewer</code>: read-only admin access (GET config/rules/audit).</li> <li><code>operator</code>: config/rules updates + cache invalidation.</li> <li><code>admin</code>: full admin access (includes operator + viewer).</li> </ul>"},{"location":"reference/api/admin/#3-admin-endpoints","title":"3) Admin endpoints","text":"<p>All admin endpoints are under <code>/v1/admin</code>.</p> <p>The <code>tenant_id</code> path parameter accepts external_id or UUID.</p>"},{"location":"reference/api/admin/#get-v1admintenantstenant_idconfig","title":"GET /v1/admin/tenants/{tenant_id}/config","text":"<p>Returns current tenant config and <code>config_version</code>.</p>"},{"location":"reference/api/admin/#put-v1admintenantstenant_idconfig","title":"PUT /v1/admin/tenants/{tenant_id}/config","text":"<p>Updates tenant config (optimistic concurrency).</p> <p>Headers:</p> <ul> <li><code>If-Match</code>: optional. Use the <code>config_version</code> from the latest GET response.</li> </ul> <p>Omit for the first insert.</p> <p>Payload (minimal example):</p> <pre><code>{\n  \"weights\": { \"pop\": 0.7, \"cooc\": 0.2, \"emb\": 0.1 },\n  \"flags\": { \"enable_rules\": true },\n  \"limits\": { \"max_k\": 50, \"max_exclude_ids\": 200 }\n}\n</code></pre> <p>Validation notes:</p> <ul> <li>weights must be non\u2011negative</li> <li>limits must be non\u2011negative</li> </ul> <p>Common config keys (current behavior):</p> <ul> <li><code>weights.pop</code>, <code>weights.cooc</code>, <code>weights.emb</code></li> <li><code>flags</code> (boolean map, free-form)</li> <li><code>limits.max_k</code>, <code>limits.max_exclude_ids</code></li> </ul>"},{"location":"reference/api/admin/#get-v1admintenantstenant_idrules","title":"GET /v1/admin/tenants/{tenant_id}/rules","text":"<p>Returns current tenant rules and <code>rules_version</code>.</p>"},{"location":"reference/api/admin/#put-v1admintenantstenant_idrules","title":"PUT /v1/admin/tenants/{tenant_id}/rules","text":"<p>Updates tenant rules (optimistic concurrency).</p> <p>Headers:</p> <ul> <li><code>If-Match</code>: optional. Use the <code>rules_version</code> from the latest GET response.</li> </ul> <p>Omit for the first insert.</p> <p>Payload (minimal example array):</p> <pre><code>[\n  {\n    \"action\": \"pin\",\n    \"target_type\": \"item\",\n    \"item_ids\": [\"item_1\", \"item_2\"],\n    \"surface\": \"home\",\n    \"priority\": 10\n  },\n  {\n    \"action\": \"block\",\n    \"target_type\": \"tag\",\n    \"target_key\": \"brand:nike\"\n  }\n]\n</code></pre> <p>Supported actions: <code>pin</code>, <code>boost</code>, <code>block</code> (aliases allowed: <code>promote</code>, <code>exclude</code>, etc). Supported targets: <code>item</code>, <code>tag</code>, <code>brand</code>, <code>category</code>.</p> <p>Common rule keys (current parser):</p> <ul> <li><code>action</code>: <code>pin</code> | <code>boost</code> | <code>block</code></li> <li><code>target_type</code>: <code>item</code> | <code>tag</code> | <code>brand</code> | <code>category</code></li> <li><code>target_key</code>: string (for tag/brand/category)</li> <li><code>item_ids</code>: array of item ids (for item targeting)</li> <li><code>namespace</code> (optional), <code>surface</code> (optional), <code>segment</code> (optional)</li> <li><code>priority</code> (int), <code>enabled</code> (bool)</li> <li><code>valid_from</code>, <code>valid_until</code> (RFC3339 timestamps)</li> <li><code>boost_value</code> (number, when <code>action=boost</code>)</li> <li><code>max_pins</code> (int, when <code>action=pin</code>)</li> </ul>"},{"location":"reference/api/admin/#post-v1admintenantstenant_idcacheinvalidate","title":"POST /v1/admin/tenants/{tenant_id}/cache/invalidate","text":"<p>Payload:</p> <pre><code>{ \"targets\": [\"config\", \"rules\"], \"surface\": \"home\" }\n</code></pre> <p>Valid targets: <code>config</code>, <code>rules</code>, <code>popularity</code>.</p> <p>Notes:</p> <ul> <li><code>surface</code> is optional. If provided, invalidation is scoped to that surface.</li> <li><code>popularity</code> invalidates artifact/manifest caches (no\u2011op in DB\u2011only mode).</li> </ul>"},{"location":"reference/api/admin/#get-v1admintenantstenant_idaudit","title":"GET /v1/admin/tenants/{tenant_id}/audit","text":"<p>Returns recent audit log entries for admin actions (write operations).</p> <p>Query parameters:</p> <ul> <li><code>limit</code> (optional, default 100, max 200)</li> <li><code>before</code> (optional, RFC3339 timestamp for pagination)</li> <li><code>before_id</code> (optional, numeric id for pagination tie\u2011break)</li> </ul> <p>Example:</p> <pre><code>GET /v1/admin/tenants/demo/audit?limit=50\n</code></pre> <p>Response includes <code>entries</code> and optional <code>next_before</code>/<code>next_before_id</code> cursor.</p>"},{"location":"reference/api/admin/#4-call-the-api","title":"4) Call the API","text":"<p>Once config and rules exist, you can call <code>/v1/recommend</code> or <code>/v1/similar</code> using the same tenant headers/token.</p> <p>See also:</p> <ul> <li><code>reference/api/examples/admin-config.http</code></li> <li><code>tutorials/local-end-to-end.md</code></li> </ul>"},{"location":"reference/cli/","title":"CLI reference","text":"<ul> <li><code>recsys-eval</code></li> <li><code>recsys-pipelines</code></li> </ul>"},{"location":"reference/cli/recsys-eval/","title":"CLI: recsys-eval","text":"<p>Commands:</p> <ul> <li>offline</li> <li>experiment</li> <li>ope (optional)</li> </ul>"},{"location":"reference/cli/recsys-pipelines/","title":"CLI: recsys-pipelines","text":"<p>Suggested commands:</p> <ul> <li>ingest</li> <li>canonicalize</li> <li>popularity</li> <li>publish</li> <li>validate</li> <li>backfill</li> </ul> <p>Note:</p> <ul> <li>The CLI currently expects JSON config files.</li> </ul>"},{"location":"reference/config/","title":"Configuration reference","text":"<ul> <li><code>recsys-service</code></li> <li><code>recsys-eval</code></li> <li><code>recsys-pipelines</code></li> </ul>"},{"location":"reference/config/recsys-eval/","title":"recsys-eval configuration","text":"<ul> <li>offline.primary_metric: e.g. ndcg@20</li> <li>offline.fail_threshold: relative drop threshold</li> <li>experiment.primary_kpi: e.g. ctr</li> <li>output.format: json|md|html</li> </ul>"},{"location":"reference/config/recsys-pipelines/","title":"recsys-pipelines configuration","text":"<p>Note: the current CLI expects JSON configs.</p> <p>Core knobs you will likely set:</p> <ul> <li>raw_source.type: fs|s3|minio|postgres|kafka</li> <li>object_store.type: fs|s3|minio</li> <li>registry_dir: manifest registry location (fs)</li> <li>db.dsn: Postgres DSN (optional, for DB-backed signals)</li> <li>limits.max_users_per_run, limits.max_items_per_user (implicit/session jobs)</li> <li>limits.max_items_per_artifact, limits.max_neighbors_per_item</li> </ul> <p>Artifacts produced (v1):</p> <ul> <li>popularity</li> <li>cooc</li> <li>implicit (collaborative)</li> <li>content_sim</li> <li>session_seq</li> </ul>"},{"location":"reference/config/recsys-service/","title":"recsys-service configuration","text":"<p>Canonical env var list: <code>recsys/api/.env.example</code>.</p> <ul> <li>db.dsn: Postgres DSN</li> <li>auth.required: enable auth on protected routes</li> <li>auth.tenant_claim: claim used for tenant id (JWT mode)</li> <li>auth.viewer_role: role that can read admin resources (default: viewer)</li> <li>auth.operator_role: role that can mutate admin resources (default: operator)</li> <li>auth.admin_role: role with full admin access (default: admin)</li> <li>auth.dev_headers: enable dev headers (local)</li> <li>auth.dev_tenant_header: tenant header used with dev auth</li> <li>limits.rps_per_tenant: per-tenant rate limit</li> <li>audit.log_path: file path for optional audit JSONL log</li> <li>audit.log_fsync: fsync on each audit write (default: false)</li> <li>cache.config_ttl_seconds: config cache TTL</li> <li>cache.rules_ttl_seconds: rules cache TTL</li> <li>exposure.log_path: file path (JSONL)</li> <li>exposure.log_format: service_v1 | eval_v1</li> <li>algo.mode: blend | popularity | cooc | implicit | content_sim | session_seq (default: blend)</li> <li>algo.plugin_enabled: enable Go plugin loading (dev only)</li> <li>algo.plugin_path: filesystem path to .so plugin (dev only)</li> <li>artifacts.enabled: enable artifact/manifest mode</li> <li>artifacts.manifest_template: manifest URI template (supports {tenant} and {surface})</li> <li>artifacts.manifest_ttl_seconds: manifest cache TTL</li> <li>artifacts.cache_ttl_seconds: artifact cache TTL</li> <li>artifacts.max_bytes: max artifact size in bytes</li> <li>artifacts.s3.endpoint: S3/MinIO endpoint (host:port)</li> <li>artifacts.s3.access_key: S3 access key</li> <li>artifacts.s3.secret_key: S3 secret key</li> <li>artifacts.s3.region: S3 region</li> <li>artifacts.s3.use_ssl: use TLS for S3 (true/false)</li> </ul> <p>Notes:</p> <ul> <li>content_sim and session_seq modes require corresponding artifacts in the manifest.</li> <li>auth.tenant_claim and auth.role_claims support dotted keys (e.g., realm_access.roles).</li> </ul>"},{"location":"reference/data-contracts/","title":"Data contracts","text":"<ul> <li><code>Eval events</code></li> <li><code>Field catalog</code></li> </ul>"},{"location":"reference/data-contracts/eval-events/","title":"recsys-eval event schemas (v1)","text":"<p><code>recsys-eval validate</code> uses strict JSON schemas with <code>additionalProperties: false</code>. If your JSONL includes extra keys or misses required fields, validation fails even if <code>recsys-eval run</code> produced a report.</p> <p>Schema sources (repo):</p> <ul> <li><code>recsys/recsys-eval/schemas/exposure.v1.json</code></li> <li><code>recsys/recsys-eval/schemas/outcome.v1.json</code></li> <li><code>recsys/recsys-eval/schemas/assignment.v1.json</code></li> </ul>"},{"location":"reference/data-contracts/eval-events/#exposurev1-required-fields","title":"exposure.v1 (required fields)","text":"<p>Required:</p> <ul> <li><code>request_id</code> (string, non-empty)</li> <li><code>user_id</code> (string, non-empty)</li> <li><code>ts</code> (RFC3339 date-time)</li> <li><code>items</code> (array of <code>{ item_id, rank }</code>)</li> </ul> <p>Allowed optional fields:</p> <ul> <li><code>context</code> (object of string values)</li> <li><code>latency_ms</code> (number &gt;= 0)</li> <li><code>error</code> (boolean)</li> <li><code>items[].propensity</code>, <code>items[].logging_propensity</code>, <code>items[].target_propensity</code></li> </ul> <p>Examples (JSONL; one object per line):</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"ts\":\"2026-01-30T12:00:00Z\",\"items\":[{\"item_id\":\"item-1\",\"rank\":1},{\"item_id\":\"item-2\",\"rank\":2}],\"context\":{\"surface\":\"home\",\"tenant_id\":\"demo\"}}\n{\"request_id\":\"req-2\",\"user_id\":\"user-2\",\"ts\":\"2026-01-30T12:05:00Z\",\"items\":[{\"item_id\":\"sku-9\",\"rank\":1,\"propensity\":0.42,\"logging_propensity\":0.5,\"target_propensity\":0.6},{\"item_id\":\"sku-3\",\"rank\":2}],\"context\":{\"surface\":\"home\",\"segment\":\"default\",\"tenant_id\":\"demo\",\"locale\":\"en-US\"},\"latency_ms\":12.4,\"error\":false}\n</code></pre>"},{"location":"reference/data-contracts/eval-events/#outcomev1-required-fields","title":"outcome.v1 (required fields)","text":"<p>Required:</p> <ul> <li><code>request_id</code> (string, non-empty)</li> <li><code>user_id</code> (string, non-empty)</li> <li><code>item_id</code> (string, non-empty)</li> <li><code>event_type</code> (<code>click</code> or <code>conversion</code>)</li> <li><code>ts</code> (RFC3339 date-time)</li> </ul> <p>Allowed optional fields:</p> <ul> <li><code>value</code> (number)</li> </ul> <p>Examples (JSONL; one object per line):</p> <pre><code>{\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"item_id\":\"item-2\",\"event_type\":\"click\",\"ts\":\"2026-01-30T12:00:03Z\"}\n{\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"item_id\":\"item-2\",\"event_type\":\"conversion\",\"value\":49.90,\"ts\":\"2026-01-30T12:00:20Z\"}\n{\"request_id\":\"req-2\",\"user_id\":\"user-2\",\"item_id\":\"sku-9\",\"event_type\":\"click\",\"ts\":\"2026-01-30T12:05:02Z\"}\n</code></pre>"},{"location":"reference/data-contracts/eval-events/#assignmentv1-required-fields","title":"assignment.v1 (required fields)","text":"<p>Required:</p> <ul> <li><code>experiment_id</code> (string, non-empty)</li> <li><code>variant</code> (string, non-empty)</li> <li><code>request_id</code> (string, non-empty)</li> <li><code>user_id</code> (string, non-empty)</li> <li><code>ts</code> (RFC3339 date-time)</li> </ul> <p>Allowed optional fields:</p> <ul> <li><code>context</code> (object of string values)</li> </ul> <p>Examples (JSONL; one object per line):</p> <pre><code>{\"experiment_id\":\"exp-1\",\"variant\":\"A\",\"request_id\":\"req-1\",\"user_id\":\"user-1\",\"ts\":\"2026-01-30T12:00:00Z\",\"context\":{\"surface\":\"home\"}}\n{\"experiment_id\":\"exp-1\",\"variant\":\"B\",\"request_id\":\"req-2\",\"user_id\":\"user-2\",\"ts\":\"2026-01-30T12:05:00Z\",\"context\":{\"surface\":\"home\",\"tenant_id\":\"demo\"}}\n</code></pre>"},{"location":"reference/data-contracts/eval-events/#how-to-avoid-validation-failures","title":"How to avoid validation failures","text":"<ul> <li>Ensure every record contains exactly the required fields (no extras).</li> <li>Use RFC3339 timestamps for <code>ts</code>.</li> <li><code>user_id</code> must be non-empty (use a stable pseudonymous ID if needed).</li> <li>Join key is request_id: outcomes and assignments must use the same</li> </ul> <p><code>request_id</code> as the exposure.</p>"},{"location":"reference/data-contracts/eval-events/#service-exposure-logs-vs-eval-schema","title":"Service exposure logs vs eval schema","text":"<p><code>recsys-service</code> logs exposures in its native format by default. To emit <code>exposure.v1</code> directly for recsys-eval, set:</p> <pre><code>EXPOSURE_LOG_FORMAT=eval_v1\n</code></pre> <p>If you keep <code>service_v1</code>, you must transform logs before running <code>recsys-eval validate</code>.</p>"},{"location":"reference/data-contracts/field-catalog/","title":"Field catalog","text":"<p>exposure.v1:</p> <ul> <li>request_id: join key for outcomes</li> <li>served[].rank: 1-based ranking position</li> </ul> <p>interaction.v1:</p> <ul> <li>request_id: recommended when available</li> <li>event_type: click/purchase/etc.</li> </ul> <p>recsys-eval datasets (strict schemas):</p> <ul> <li>exposure.v1 / outcome.v1 / assignment.v1 required fields and examples:</li> </ul> <p><code>reference/data-contracts/eval-events.md</code></p>"},{"location":"reference/database/","title":"Database reference","text":"<ul> <li><code>Schema</code></li> <li><code>Migrations</code></li> <li><code>DB-only seeding</code></li> </ul>"},{"location":"reference/database/db-only-seeding/","title":"DB-only signals: schema + seed examples","text":"<p>Use these tables when running recsys-service in DB-only mode (no artifacts).</p>"},{"location":"reference/database/db-only-seeding/#1-resolve-tenant-uuid","title":"1) Resolve tenant UUID","text":"<p><code>external_id</code> should match your tenant claim or dev header value.</p> <pre><code>select id from tenants where external_id = 'demo';\n</code></pre> <p>Assume the result is <code>:tenant_id</code>.</p>"},{"location":"reference/database/db-only-seeding/#2-item_tags","title":"2) item_tags","text":"<p>Columns:</p> <ul> <li>tenant_id (uuid)</li> <li>namespace (surface, text)</li> <li>item_id (text)</li> <li>tags (text[])</li> <li>price (numeric, optional)</li> <li>created_at (timestamptz)</li> </ul> <pre><code>insert into item_tags (tenant_id, namespace, item_id, tags, price, created_at)\nvalues\n  (:tenant_id, 'home', 'item-1', array['brand:nike','category:shoes'], 99.90, now()),\n  (:tenant_id, 'home', 'item-2', array['brand:nike','category:shoes'], 79.00, now())\non conflict (tenant_id, namespace, item_id)\ndo update set tags = excluded.tags,\n              price = excluded.price,\n              created_at = excluded.created_at;\n</code></pre>"},{"location":"reference/database/db-only-seeding/#3-item_popularity_daily","title":"3) item_popularity_daily","text":"<p>Columns:</p> <ul> <li>tenant_id (uuid)</li> <li>namespace (surface, text)</li> <li>item_id (text)</li> <li>day (date)</li> <li>score (numeric)</li> </ul> <pre><code>insert into item_popularity_daily (tenant_id, namespace, item_id, day, score)\nvalues\n  (:tenant_id, 'home', 'item-1', '2026-01-30', 10),\n  (:tenant_id, 'home', 'item-2', '2026-01-30', 8)\non conflict (tenant_id, namespace, item_id, day)\ndo update set score = excluded.score;\n</code></pre> <p>Note: popularity is a decayed sum across days, so newer days dominate when multiple days are present.</p>"},{"location":"reference/database/db-only-seeding/#4-item_covisit_daily-for-v1similar","title":"4) item_covisit_daily (for /v1/similar)","text":"<p>Columns:</p> <ul> <li>tenant_id (uuid)</li> <li>namespace (surface, text)</li> <li>item_id (anchor)</li> <li>neighbor_id</li> <li>day (date)</li> <li>score (numeric)</li> </ul> <pre><code>insert into item_covisit_daily (tenant_id, namespace, item_id, neighbor_id, day, score)\nvalues\n  (:tenant_id, 'home', 'item-1', 'item-2', '2026-01-30', 3),\n  (:tenant_id, 'home', 'item-1', 'item-3', '2026-01-30', 1)\non conflict (tenant_id, namespace, item_id, neighbor_id, day)\ndo update set score = excluded.score;\n</code></pre> <p>If <code>/v1/similar</code> returns empty:</p> <ul> <li>ensure co-vis rows exist for the same surface (namespace)</li> <li>ensure the anchor item exists in <code>item_covisit_daily</code></li> </ul>"},{"location":"reference/database/migrations/","title":"Migrations (safe upgrade)","text":""},{"location":"reference/database/migrations/#policy","title":"Policy","text":"<ul> <li>Migrations are versioned, append-only. Never edit a migration after it has</li> </ul> <p>shipped; create a new one instead.</p> <ul> <li><code>down</code> migrations are disabled by default in production. Use only in</li> </ul> <p>controlled rollback scenarios.</p>"},{"location":"reference/database/migrations/#preflight-checks","title":"Preflight checks","text":"<p>Before upgrading from N\u20111 to N, run:</p> <pre><code>cd recsys/api\ngo run ./cmd/migrate preflight\n</code></pre> <p>Docker/compose shortcut:</p> <pre><code>cd recsys/api\nmake migrate-preflight\n</code></pre> <p>This verifies:</p> <ul> <li>DB connectivity</li> <li>No failed migrations in <code>schema_migrations</code></li> <li>Checksums match the local migration files</li> </ul>"},{"location":"reference/database/migrations/#upgrade-steps-n1-n","title":"Upgrade steps (N\u20111 \u2192 N)","text":"<ol> <li>Take a DB snapshot/backup.</li> <li>Run preflight checks.</li> <li>Apply migrations:</li> </ol> <pre><code>go run ./cmd/migrate up\n</code></pre> <ol> <li>Verify status:</li> </ol> <pre><code>go run ./cmd/migrate status\n</code></pre> <ol> <li>Roll forward with application deploy.</li> </ol>"},{"location":"reference/database/migrations/#rollback-story","title":"Rollback story","text":"<p>If a migration introduces issues:</p> <ol> <li>Roll back the application to N\u20111.</li> <li>Use the config/rules rollback runbook:</li> </ol> <p><code>docs/operations/runbooks/rollback-config-rules.md</code></p> <ol> <li>Only if absolutely required, apply a controlled <code>down</code> migration:</li> </ol> <pre><code>go run ./cmd/migrate --allow-down down\n</code></pre>"},{"location":"reference/database/migrations/#recommended-order-fresh-install","title":"Recommended order (fresh install)","text":"<ol> <li>extensions</li> <li>tenants</li> <li>config/rules version tables + current pointers</li> <li>audit log</li> <li>exposure_events (partitioned)</li> </ol>"},{"location":"reference/database/schema/","title":"Database schema","text":"<p>Use Postgres for:</p> <ul> <li>tenant config/rules (versioned + current pointers)</li> <li>exposure logging</li> <li>audit log</li> <li>signal tables (DB-only mode): item_tags, item_popularity_daily, item_covisit_daily</li> </ul> <p>Partition high-volume exposure tables by time.</p> <p>DB-only seed examples:</p> <ul> <li><code>reference/database/db-only-seeding.md</code></li> </ul>"},{"location":"start-here/","title":"Start here","text":"<p>This site documents the RecSys suite: a production-ready set of modules for building, shipping, and operating a recommendation system.</p>"},{"location":"start-here/#recommended-path","title":"Recommended path","text":"<ol> <li>Run the suite locally end-to-end</li> <li> <p>Tutorial: <code>tutorials/local-end-to-end.md</code></p> </li> <li> <p>Understand the architecture and data flow</p> </li> <li>Diagram: <code>start-here/diagrams/suite-context.md</code></li> <li> <p>Explanation: <code>explanation/suite-architecture.md</code></p> </li> <li> <p>Integrate, operate, and validate</p> </li> <li>Integrate the API: <code>how-to/integrate-recsys-service.md</code></li> <li>Operate pipelines: <code>how-to/operate-pipelines.md</code></li> <li>Run evaluation and ship decisions: <code>how-to/run-eval-and-ship.md</code></li> </ol>"},{"location":"start-here/#role-based-entry-points","title":"Role-based entry points","text":""},{"location":"start-here/#lead-developer-platform-engineer","title":"Lead developer / platform engineer","text":"<ul> <li>Suite architecture and contracts:</li> <li><code>explanation/suite-architecture.md</code></li> <li><code>reference/data-contracts/</code></li> <li><code>reference/config/</code></li> <li><code>reference/api/openapi.yaml</code></li> </ul>"},{"location":"start-here/#recommendation-engineer-ml-engineer","title":"Recommendation engineer / ML engineer","text":"<ul> <li>Ranking core:</li> <li><code>recsys-algo/</code></li> <li>Pipelines outputs:</li> <li><code>recsys-pipelines/docs/reference/output-layout.md</code></li> </ul>"},{"location":"start-here/#product-business-stakeholder","title":"Product / business stakeholder","text":"<ul> <li>What to expect from evaluation and decisions:</li> <li><code>recsys-eval/docs/interpreting_results.md</code></li> <li><code>recsys-eval/docs/metrics.md</code></li> </ul>"},{"location":"start-here/#sre-on-call","title":"SRE / on-call","text":"<ul> <li>Operational runbooks:</li> <li><code>operations/runbooks/</code></li> <li><code>recsys-pipelines/docs/operations/runbooks/</code></li> </ul>"},{"location":"start-here/diagrams/suite-context/","title":"Suite Context","text":"<p><code>mermaid flowchart LR   C[Client] --&gt; S[recsys-service]   S --&gt; A[recsys-algo]   S --&gt; E[(Exposures)]   C --&gt; O[(Outcomes)]   E --&gt; P[recsys-pipelines]   O --&gt; P   P --&gt; M[(Manifest)]   M --&gt; S   E --&gt; V[recsys-eval]   O --&gt; V   V --&gt; D[Decision]   D --&gt; S</code></p>"},{"location":"tutorials/local-end-to-end/","title":"Tutorial: local end-to-end (pipelines -&gt; service -&gt; eval)","text":"<p>Goal: run a tiny dataset through pipelines, serve recommendations, and generate an evaluation report.</p> <p>Prereqs:</p> <ul> <li>Docker + docker compose</li> <li>curl</li> <li>POSIX shell</li> </ul>"},{"location":"tutorials/local-end-to-end/#1-start-local-dependencies","title":"1. Start local dependencies","text":"<p>Bring up Postgres and recsys-service. Ensure migrations are applied.</p>"},{"location":"tutorials/local-end-to-end/#2-load-demo-tenant-config-rules","title":"2. Load demo tenant + config + rules","text":"<p>Create:</p> <ul> <li>tenant: demo</li> <li>config and rules (versioned, current pointer updated)</li> </ul> <p>See: <code>reference/api/examples/admin-config.http</code> See also: <code>reference/api/admin.md</code> (auth + bootstrap details, tenant insert SQL)</p>"},{"location":"tutorials/local-end-to-end/#3-load-a-tiny-dataset","title":"3. Load a tiny dataset","text":"<p>Use <code>tutorials/datasets/tiny/</code>:</p> <ul> <li>catalog.csv</li> <li>exposures.jsonl</li> <li>interactions.jsonl</li> </ul> <p>In production, pipelines ingest raw events. For this tutorial you can import the files into your canonical store.</p>"},{"location":"tutorials/local-end-to-end/#4-run-pipelines-to-publish-artifacts","title":"4. Run pipelines to publish artifacts","text":""},{"location":"tutorials/local-end-to-end/#local-artifact-bootstrap-minio","title":"Local artifact bootstrap (MinIO)","text":"<p>If you want artifact/manifest mode locally, use the bundled MinIO in <code>docker-compose</code> and publish manifests to the default bucket:</p> <ul> <li>Bucket: <code>recsys-artifacts</code></li> <li>Manifest path: <code>registry/current/{tenant}/{surface}/manifest.json</code></li> <li>Example URI: <code>s3://recsys-artifacts/registry/current/demo/home/manifest.json</code></li> </ul> <p>Service env (local):</p> <pre><code>RECSYS_ARTIFACT_MODE_ENABLED=true\nRECSYS_ARTIFACT_MANIFEST_TEMPLATE=s3://recsys-artifacts/registry/current/{tenant}/{surface}/manifest.json\nRECSYS_ARTIFACT_S3_ENDPOINT=minio:9000\nRECSYS_ARTIFACT_S3_ACCESS_KEY=minioadmin\nRECSYS_ARTIFACT_S3_SECRET_KEY=minioadmin\nRECSYS_ARTIFACT_S3_REGION=us-east-1\nRECSYS_ARTIFACT_S3_USE_SSL=false\n</code></pre> <p>Run the minimum pipelines jobs to produce non-empty recs (e.g. popularity + manifest), then verify the manifest is present at the expected MinIO path.</p> <p>See: <code>how-to/operate-pipelines.md</code></p>"},{"location":"tutorials/local-end-to-end/#5-call-the-api","title":"5. Call the API","text":"<ul> <li>POST /v1/recommend</li> <li>POST /v1/similar (optional)</li> <li>POST /v1/recommend/validate (lint requests)</li> </ul> <p>See: <code>reference/api/examples/</code></p>"},{"location":"tutorials/local-end-to-end/#6-run-evaluation","title":"6. Run evaluation","text":"<p>Run offline regression and (optionally) experiment analysis.</p> <p>See: <code>how-to/run-eval-and-ship.md</code></p>"},{"location":"tutorials/datasets/tiny/","title":"Tiny dataset","text":"<p>This dataset is intentionally small and human-readable. It is for documentation, smoke tests, and local demo runs.</p>"}]}